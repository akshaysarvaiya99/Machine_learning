{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/sharmasaravanan/Machine_learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 5\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10 #int\n",
    "pi = 3.14 #float\n",
    "name = \"apple\" #string\n",
    "b = True #bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print('hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello apple\n",
      "hello 10\n",
      "--------------------------\n",
      "hello apple\n",
      "hello 10\n",
      "--------------------------\n",
      "hello apple\n",
      "hello 10\n",
      "--------------------------\n",
      "hello apple\n",
      "hello 10\n"
     ]
    }
   ],
   "source": [
    "# hello apple\n",
    "# hell0 10\n",
    "\n",
    "#method 1\n",
    "print(\"hello \"+name)\n",
    "print(\"hello \"+str(a))\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "#method 2\n",
    "print(\"hello\",name)\n",
    "print(\"hello\",a)\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "#method 3\n",
    "print(\"hello %s\"%name)\n",
    "print(\"hello %d\"%a)\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "#method 4\n",
    "print(\"hello {}\".format(name))\n",
    "print(\"hello {}\".format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought 2Kg of apple and 1Kg of mango which cost 75.36\n"
     ]
    }
   ],
   "source": [
    "print(\"I bought %dKg of %s and %dKg of %s which cost %0.2f\"%(2,\"apple\",1,\"mango\",75.360000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought 2Kg of apple and 1Kg of mango which cost 75.36\n"
     ]
    }
   ],
   "source": [
    "print(\"I bought {0}Kg of {3} and {1}Kg of {2} which cost {4}\".format(2,1,\"mango\",\"apple\",75.360000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1\n",
    "\n",
    "assign a numerical value to a variable (n) and print the result in the following way\n",
    "\n",
    "output:-\n",
    "    nnn+nn+n\n",
    "\n",
    "example:-\n",
    "\n",
    "n=5\n",
    "\n",
    "555+55+5 = 615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "int(str(n)+str(n)+str(n))+int(str(n)+str(n))+n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n='5'\n",
    "int(n+n+n)+int(n+n)+int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-c6f28ea08a71>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-c6f28ea08a71>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    + - * / %\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#numeric value\n",
    "+ - * / %\n",
    "#string\n",
    "+ *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(n*3)+int(n*2)+int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditional operation\n",
    "< > <= >= == !=\n",
    "\n",
    "#logical operation\n",
    "and or not ^ \n",
    "\n",
    "#misc operation\n",
    "\n",
    "in, is in , not in ,is , is not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value for num :85\n",
      "Enter your name :mango\n"
     ]
    }
   ],
   "source": [
    "num = int(input(\"Enter the value for num :\"))\n",
    "name = input(\"Enter your name :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task 2\n",
    "calculate the area of triangle ,square and rectangle by getting appropriate input from the user.\n",
    "\n",
    "output:-\n",
    "<br> The area of the triangle is 45 sq.cm whose base is 18 cm and height is 5 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the numerical value :40\n",
      "even\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "#if-else\n",
    "num = int(input(\"Enter the numerical value :\"))\n",
    "if num%2 == 0:\n",
    "    print(\"even\")\n",
    "else:\n",
    "    print(\"odd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the numerical value :5\n",
      "odd\n"
     ]
    }
   ],
   "source": [
    "num = int(input(\"Enter the numerical value :\"))\n",
    "if num%4 == 0:\n",
    "    print(\"divisible by 4 and even\")\n",
    "elif num%2 == 0:\n",
    "    print(\"even\")\n",
    "else:\n",
    "    print(\"odd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task 3\n",
    "make a two player rock-paper-scissor game\n",
    "\n",
    "Remember the rules:\n",
    "\n",
    "    Rock beats scissors\n",
    "    Scissors beats paper\n",
    "    Paper beats rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the numerical value :10\n",
      "even\n",
      "Do you want to continue? y/ny\n",
      "Enter the numerical value :36\n",
      "divisible by 4 and even\n",
      "Do you want to continue? y/ny\n",
      "Enter the numerical value :10\n",
      "even\n",
      "Do you want to continue? y/ny\n",
      "Enter the numerical value :25\n",
      "skipping....\n",
      "Enter the numerical value :10\n",
      "even\n",
      "Do you want to continue? y/nn\n"
     ]
    }
   ],
   "source": [
    "opt = 'y'\n",
    "cnt = 0\n",
    "while opt==\"y\":\n",
    "    num = int(input(\"Enter the numerical value :\"))\n",
    "    if num == 15:\n",
    "        print(\"bye....\")\n",
    "        break\n",
    "    elif num == 25:\n",
    "        print(\"skipping....\")\n",
    "        continue\n",
    "    elif num == 10:\n",
    "        cnt+=1\n",
    "        pass\n",
    "    if num%4 == 0:\n",
    "        print(\"divisible by 4 and even\")\n",
    "    elif num%2 == 0:\n",
    "        print(\"even\")\n",
    "    else:\n",
    "        print(\"odd\")\n",
    "    opt = input(\"Do you want to continue? y/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string operation\n",
    "string  = \"apple is a fruit\"\n",
    "string1 = \"Python Is a Programming Language\"\n",
    "string2 = \" Sunday \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le is \n"
     ]
    }
   ],
   "source": [
    "print(string[3:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiurf a si elppa'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[:6]\n",
    "string[-1]\n",
    "string[-6:-1]\n",
    "string[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e44e39c99965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "string[0]=\"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.capitalize()#to make the first letter of the string into capital case\n",
    "string1.casefold()\n",
    "string.count('p')\n",
    "enc = string.encode(\"utf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple is a fruit'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(\"utf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.endswith(\"iT\")\n",
    "string.startswith(\"pp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.index(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234 56'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"1234 {}\".format(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is a programming language'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APPLE IS A FRUIT'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple Is A Fruit'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pYTHON iS A pROGRAMMING lANGUAGE'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sunda'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2.strip(\"y \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'Is', 'a', 'Programming', 'Language']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = string1.split('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python Is a Programming Language'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a\".join(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python Is ', ' Progr', 'mming L', 'ngu', 'ge']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"5 \".isspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task 4\n",
    "\n",
    "input = \"Elephant is the biggest mammal in the earth .\"\n",
    "\n",
    "convert the above input as follows:-\n",
    "\n",
    "  \". earth the in mammal biggest the is Elephant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Elephant is the biggest mammal in the earth .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eleph', 'nt is the biggest m', 'mm', 'l in the e', 'rth .']\n",
      "['.', 'earth', 'the', 'in', 'mammal', 'biggest', 'the', 'is', 'Elephant']\n"
     ]
    }
   ],
   "source": [
    "print(text.split('a'))\n",
    "\" \".join(text.split('a')[::-1])\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = text.split()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. earth the in mammal biggest the is Elephant'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \" \"\n",
    "t.join(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.count(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task 5 - Guess game \n",
    "\n",
    "Use the following two lines to generate the random numbers (Explanation will be given later in the course)\n",
    "\n",
    "import random\n",
    "\n",
    "comp = random.randint(0,100) -> to generate a random number between  0 and 100\n",
    "\n",
    "the computer will generate a random number and you have to guess the number...\n",
    "\n",
    "everytime when you enter the number, computer should the following outputs as a validation result,\n",
    "\n",
    "high -> if a entered number is greater than generated one\n",
    "\n",
    "low -> if a entered number is lesser than generated one\n",
    "\n",
    "bingo -> if a entered number is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list\n",
    "a = []\n",
    "a = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [\"high\",\"low\",\"tall\",\"short\",4,1,2,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'low'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple is A fruit'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.replace(\"a\",\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tall'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.index(\"tall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[2] = \"large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'large', 'short', 4, 1, 2, 3, 5]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "del b[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 1, 4, 'large', 'low', 'high']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'large', 4, 1, 2, 3, 5]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.append(\"mango\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'large', 4, 1, 2, 3, 5, 'mango']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.insert(3,\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'large', 'small', 4, 1, 2, 3, 5, 'mango']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mango'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'large', 'small', 4, 1, 2, 3, 5]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.remove(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'large', 'small', 4, 1, 3, 5]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.count('large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 1, 4, 'small', 'large', 'low', 'high']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 1, 4, 'small', 'large', 'low', 'high']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'large', 'small', 4, 1, 3, 5]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 1, 4, 'small', 'large', 'low', 'high']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-b8c00efa69e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "b.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'orange']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'orange', 1, 3, 4, 5, 'small', 'large', 'low', 'high']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5, 'small', 'large', 'low', 'high', 'apple', 'orange']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuple\n",
    "\n",
    "t = (5, 3, 1, 4, 'small', 'large', 'low', 'high')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 1, 4, 'small', 'large', 'low', 'high')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 'small')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object doesn't support item deletion",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-2d0f41a77003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object doesn't support item deletion"
     ]
    }
   ],
   "source": [
    "del t[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-b9373972991e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "t[2] =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local to github\n",
    "git add .\n",
    "git commit -am \"commit message\"\n",
    "git push origin master\n",
    "\n",
    "#github to local\n",
    "git clone https://github.com/sharmasaravanan/Machine_learning.git\n",
    "\n",
    "#updating the local from github (probably every weekend)\n",
    "git pull https://github.com/sharmasaravanan/Machine_learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "dictionary = {'a':'apple','b':'ball','c':'cat',1:'dog','e':6,1:\"elephant\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a', 'b', 'c', 1, 'e'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['apple', 'ball', 'cat', 'elephant', 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 'apple'), ('b', 'ball'), ('c', 'cat'), (1, 'elephant'), ('e', 6)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elephant'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.popitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.update({'d':'donkey','e':'elephant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'apple', 'b': 'ball', 'c': 'cat', 'd': 'donkey', 'e': 'elephant'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= {'dict':dictionary,'list':b,'tuple':t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dict': {'a': 'apple',\n",
       "  'b': 'ball',\n",
       "  'c': 'cat',\n",
       "  'd': 'donkey',\n",
       "  'e': 'elephant'},\n",
       " 'list': ['high', 'low', 'tall', 'short', 4, 1, 2, 3, 5],\n",
       " 'tuple': (5, 3, 1, 4, 'small', 'large', 'low', 'high')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 1, 4, 'small', 'large', 'low', 'high')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['tuple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'tall', 'short', 4, 1, 2, 3, 5]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 1, 4, 'small', 'large', 'low', 'high')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'apple', 'b': 'ball', 'c': 'cat', 'd': 'donkey', 'e': 'elephant'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "https://github.com/sharmasaravanan/Machine_learning.gitdictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high\n",
      "low\n",
      "tall\n",
      "short\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"apple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'tall', 'short', 4, 1, 2, 3, 5]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "#error handling\n",
    "#visualization\n",
    "\n",
    "#file handling -> tsv,csv,txt,excel,json,db, mysqldb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Generic Error!!!\n",
      "hello\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(8)\n",
    "    raise SystemError(\"Maually raised error\")\n",
    "except NameError  as e:\n",
    "    print(\"Error:\",e)\n",
    "except TypeError:\n",
    "    pass\n",
    "except:\n",
    "    print(\"Generic Error!!!\")\n",
    "finally:\n",
    "    print('hello')\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the two digit number :254\n",
      "Please enter two digit\n",
      "Enter the two digit number :12\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    num = input(\"Enter the two digit number :\")\n",
    "    if len(num)>2:\n",
    "        raise ValueError(\"Please enter two digit\")\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    num = input(\"Enter the two digit number :\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first number10\n",
      "Enter the second number20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-52d24de4bc71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the second number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a = int(input(\"Enter the first number\"))\n",
    "    b = int(input(\"Enter the second number\"))\n",
    "    if (b-a) < 10:\n",
    "        raise ValueError(\"Enter the numbers with the difference of 10 atleast \")\n",
    "except ValueError:\n",
    "    a = int(input(\"Enter the first number\"))\n",
    "    b = int(input(\"Enter the second number\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a=10,b=100):\n",
    "    return a+b,a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = int(input(\"Enter the first number :\"))\n",
    "#d = int(input(\"Enter the second number :\"))\n",
    "s, m = add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettingInput():\n",
    "    a = int(input(\"a :\"))\n",
    "    b = int(input(\"b :\"))\n",
    "    return a,b\n",
    "\n",
    "def prime(i):+\n",
    "    flag = True\n",
    "    for j in range(2,int(i/2)):\n",
    "        if i%j == 0:\n",
    "            flag = False\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :10\n",
      "b :20\n",
      "[11, 13]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a,b = gettingInput()\n",
    "    if (b-a) <10 or len(str(a))!=2 or len(str(b))!=2 :\n",
    "        raise ValueError(\"Condition not satisfied\")\n",
    "except ValueError:\n",
    "    a,b = gettingInput()\n",
    "    \n",
    "ans = []\n",
    "for i in range(a,b):\n",
    "    flag = prime(i)\n",
    "    if flag:\n",
    "        if int(str(i)[0])+int(str(i)[1]) <=7:\n",
    "            ans.append(i)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://w3resource.com/python-exercises/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "    def __init__(self,name,number):\n",
    "        self.name = name\n",
    "        self.number = number\n",
    "        \n",
    "    def show(self,):\n",
    "        print(self.name)\n",
    "        \n",
    "    def display(self,):\n",
    "        print(self.number)\n",
    "        print(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test('berry',105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"apple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berry\n"
     ]
    }
   ],
   "source": [
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "berry\n"
     ]
    }
   ],
   "source": [
    "t.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(name1):\n",
    "    print(name1)\n",
    "        \n",
    "def display(number):\n",
    "    print(number)\n",
    "    print(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango\n"
     ]
    }
   ],
   "source": [
    "show('mango')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'name1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-c0475e68cccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-112-a85d8c56f89c>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(number)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'name1' is not defined"
     ]
    }
   ],
   "source": [
    "display(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    _a = 10\n",
    "    def add(self,):\n",
    "        self._b = int(input(\"enter the b value\"))\n",
    "        print(self._b + C._a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the b value1000\n",
      "1010\n"
     ]
    }
   ],
   "source": [
    "c.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a,b,c=None):\n",
    "    if c:\n",
    "        print(a+b+c)\n",
    "    else:\n",
    "        print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "add(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parent:       \n",
    "    def show(self,):\n",
    "        print(self.name)\n",
    "        print(self.number)\n",
    "    \n",
    "    def fruit(self,):\n",
    "        print(self.fruitName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class child(parent):\n",
    "    def __init__(self,name1,number1,address1,fruitName):\n",
    "        self.name = name1\n",
    "        self.number = number1\n",
    "        self.address = address1\n",
    "        self.fruitName = fruitName\n",
    "    \n",
    "    def display(self,):\n",
    "        parent.show(self,)\n",
    "        print(self.address)\n",
    "        parent.fruit(self,)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = child(\"sharma saravanan\",7418490015,\"chennai\",\"watermelon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharma saravanan\n",
      "7418490015\n",
      "chennai\n",
      "watermelon\n"
     ]
    }
   ],
   "source": [
    "child.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: apple\n",
      "desc: mango\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def show(self):\n",
    "        print('name: %s' % (self.name,))\n",
    "\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self, name, desc):\n",
    "        A.__init__(self, name)\n",
    "        self.desc = desc\n",
    "\n",
    "    def show(self):\n",
    "        A.show(self)\n",
    "        print('desc: %s' % (self.desc,))\n",
    "\n",
    "\n",
    "f = B(\"apple\", \"mango\")\n",
    "f.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling child method\n"
     ]
    }
   ],
   "source": [
    "class Parent:\n",
    "    def myMethod(self):\n",
    "        print('Calling parent method')\n",
    "\n",
    "class Child(Parent):\n",
    "    def myMethod(self):\n",
    "        print('Calling child method')\n",
    "\n",
    "\n",
    "c = Child()\n",
    "c.myMethod()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling parent method\n"
     ]
    }
   ],
   "source": [
    "p.myMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(Parent,parent):\n",
    "    def __init__(self,name1,number1,address1,fruitName):\n",
    "        self.name = name1\n",
    "        self.number = number1\n",
    "        self.address = address1\n",
    "        self.fruitName = fruitName\n",
    "    \n",
    "    def display(self,):\n",
    "        parent.show(self,)\n",
    "        print(self.address)\n",
    "        parent.fruit(self,)\n",
    "        Parent.myMethod(self,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = D(\"sharma saravanan\",7418490015,\"chennai\",\"watermelon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharma saravanan\n",
      "7418490015\n",
      "chennai\n",
      "watermelon\n",
      "Calling parent method\n"
     ]
    }
   ],
   "source": [
    "ch.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file handling -> docx,xlsx,pdf,csv,binary,json,txt,tsv,mysqldb\n",
    "# tsv,csv,xlsx,json,txt -> pandas\n",
    "# docx,doc -> docx\n",
    "# pdf -> pdfminer\n",
    "# mysqldb -> mysqldb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./AI-Dutch.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.write(\"Hello how are you?\\n\")\n",
    "file.write(\"i am fine\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./AI-Dutch.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello how are you?\\ni am fine\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello how are you?\\n', 'i am fine\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./AI-Dutch.txt\",\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.write(\"hdjkhkdshfdasjhfhsdajkhkj\")\n",
    "file.write(\"1234567890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvData = pd.read_csv(\"./fruits_vege.csv\",index_col=0,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>fruits 2</th>\n",
       "      <th>vegetable 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>apple</td>\n",
       "      <td>onion</td>\n",
       "      <td>apple</td>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>mango</td>\n",
       "      <td>potato</td>\n",
       "      <td>mango</td>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>orange</td>\n",
       "      <td>beans</td>\n",
       "      <td>pine apple</td>\n",
       "      <td>carrot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit vegetable    fruits 2 vegetable 2\n",
       "a   apple     onion       apple       onion\n",
       "b   mango    potato       mango      potato\n",
       "c  orange     beans  pine apple      carrot"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvData = pd.read_csv(\"./fruits_vege.tsv\",delimiter=\"\\t\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>fruits 2</th>\n",
       "      <th>vegetable 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>apple</td>\n",
       "      <td>onion</td>\n",
       "      <td>apple</td>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>mango</td>\n",
       "      <td>potato</td>\n",
       "      <td>mango</td>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>orange</td>\n",
       "      <td>beans</td>\n",
       "      <td>pine apple</td>\n",
       "      <td>carrot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit vegetable    fruits 2 vegetable 2\n",
       "a   apple     onion       apple       onion\n",
       "b   mango    potato       mango      potato\n",
       "c  orange     beans  pine apple      carrot"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(csvData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tsvData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlData = pd.read_excel(\"./Course Syllabus.xlsx\",sheet_name=\"Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Syllabus</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Introduction to Deep Learning (DL)</td>\n",
       "      <td>90 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Neural Network (NN) introduction</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neurons and the Brain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-linear Hypothesis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perceptron</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multilayer perceptron</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Training a neural network</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Backpropagation primer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradients &amp; optimization</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3. Deep Learning for images</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CNN architecture</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overview of modern CNN architectures</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pre-trained CNNs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alexnet/Googlenet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OpenCV + NN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3. Deep Learning for Text</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GRU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.preprocessing Techniques for DL</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.Tools for DL</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.Practise</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Total</td>\n",
       "      <td>18.5 hours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Syllabus    Duration\n",
       "0   1. Introduction to Deep Learning (DL)     90 mins\n",
       "1     2. Neural Network (NN) introduction    240 mins\n",
       "2                   Neurons and the Brain         NaN\n",
       "3                   Non-linear Hypothesis         NaN\n",
       "4                              perceptron         NaN\n",
       "5                   Multilayer perceptron         NaN\n",
       "6               Training a neural network         NaN\n",
       "7                  Backpropagation primer         NaN\n",
       "8                Gradients & optimization         NaN\n",
       "9             3. Deep Learning for images    180 mins\n",
       "10                       CNN architecture         NaN\n",
       "11   Overview of modern CNN architectures         NaN\n",
       "12                       pre-trained CNNs         NaN\n",
       "13                      Alexnet/Googlenet         NaN\n",
       "14                            OpenCV + NN         NaN\n",
       "15              3. Deep Learning for Text    150 mins\n",
       "16                                    RNN         NaN\n",
       "17                                   LSTM         NaN\n",
       "18                                    GRU         NaN\n",
       "19      4.preprocessing Techniques for DL    120 mins\n",
       "20                         5.Tools for DL    150 mins\n",
       "21                             6.Practise    180 mins\n",
       "22                                    NaN         NaN\n",
       "23                                  Total  18.5 hours"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlFile = pd.ExcelFile(\"./Course Syllabus.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Basic Python',\n",
       " 'Advanced Python',\n",
       " 'Datascience with Python',\n",
       " 'Machine Learning',\n",
       " 'Deep Learning']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlFile.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlData = pd.read_excel(xlFile,sheet_name= 'Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Syllabus</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Introduction to Machine learning</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.a  Introduction to Data Operation</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basic Operations</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moving Data Around</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computing on Data</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plotting Data</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control Statements: for, while, if statement</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vectorization</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.Types of ML algorithm- an overview</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Supervisied learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unsupervisied Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Reinforcement Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.Linear Algebra</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Matrices and Vectors</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Addition and Scalar Multiplication</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Matrix Vector Multiplication</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Matrix Matrix Multiplication</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Matrix Multiplication Properties</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Inverse and Transpose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Practice Quiz: Linear Algebra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.Linear Regression</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Model Representation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cost Function</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gradient Descent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient Descent For Linear Regression</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Features and Polynomial Regression</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Normal Equation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Normal Equation Noninvertibility</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.Logistic Regression</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Classification</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Multiclass Classification: One-vs-all</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.Regularization</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Problem of Overfitting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Regularized Linear Regression</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Regularized Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.Machine Learning System Design</td>\n",
       "      <td>90 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Prioritizing What to Work On</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Inverse and Transpose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Error Metrics for Skewed Classes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Trading Off Precision and Recall</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Data For Machine Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.Supervised Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SVM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nearest Neighbour</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kernels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>few more</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8.Unsupervised Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>K-Means Algorithm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Optimization Objective</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Random Initialization</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Choosing the Number of Clusters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9.Large Scale Machine Learning</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Learning with large datasets</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Mini-Batch Gradient Descent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Stochastic Gradient Descent Convergence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Map Reduce and Data Parallelism</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10.Practise</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>11.Tools for ML</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>30 hours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Syllabus  Duration\n",
       "0             1.Introduction to Machine learning   60 mins\n",
       "1            1.a  Introduction to Data Operation  150 mins\n",
       "2                               Basic Operations       NaN\n",
       "3                             Moving Data Around       NaN\n",
       "4                              Computing on Data       NaN\n",
       "5                                  Plotting Data       NaN\n",
       "6   Control Statements: for, while, if statement       NaN\n",
       "7                                  Vectorization       NaN\n",
       "8           2.Types of ML algorithm- an overview   60 mins\n",
       "9                           Supervisied learning       NaN\n",
       "10                        Unsupervisied Learning       NaN\n",
       "11                        Reinforcement Learning       NaN\n",
       "12                             3.Linear Algebra   180 mins\n",
       "13                          Matrices and Vectors       NaN\n",
       "14            Addition and Scalar Multiplication       NaN\n",
       "15                  Matrix Vector Multiplication       NaN\n",
       "16                  Matrix Matrix Multiplication       NaN\n",
       "17              Matrix Multiplication Properties       NaN\n",
       "18                         Inverse and Transpose       NaN\n",
       "19                 Practice Quiz: Linear Algebra       NaN\n",
       "20                           4.Linear Regression  240 mins\n",
       "21                          Model Representation       NaN\n",
       "22                                 Cost Function       NaN\n",
       "23                              Gradient Descent       NaN\n",
       "24        Gradient Descent For Linear Regression       NaN\n",
       "25            Features and Polynomial Regression       NaN\n",
       "26                               Normal Equation       NaN\n",
       "27              Normal Equation Noninvertibility       NaN\n",
       "28                         5.Logistic Regression  150 mins\n",
       "29                                Classification       NaN\n",
       "..                                           ...       ...\n",
       "34         Multiclass Classification: One-vs-all       NaN\n",
       "35                              5.Regularization   60 mins\n",
       "36                    The Problem of Overfitting       NaN\n",
       "37                 Regularized Linear Regression       NaN\n",
       "38               Regularized Logistic Regression       NaN\n",
       "39              6.Machine Learning System Design   90 mins\n",
       "40                  Prioritizing What to Work On       NaN\n",
       "41                         Inverse and Transpose       NaN\n",
       "42              Error Metrics for Skewed Classes       NaN\n",
       "43              Trading Off Precision and Recall       NaN\n",
       "44                     Data For Machine Learning       NaN\n",
       "45                         7.Supervised Learning  180 mins\n",
       "46                                           SVM       NaN\n",
       "47                             Nearest Neighbour       NaN\n",
       "48                                       Kernels       NaN\n",
       "49                                      few more       NaN\n",
       "50                       8.Unsupervised Learning  180 mins\n",
       "51                             K-Means Algorithm       NaN\n",
       "52                        Optimization Objective       NaN\n",
       "53                         Random Initialization       NaN\n",
       "54               Choosing the Number of Clusters       NaN\n",
       "55                9.Large Scale Machine Learning  120 mins\n",
       "56                  Learning with large datasets       NaN\n",
       "57                   Stochastic Gradient Descent       NaN\n",
       "58                   Mini-Batch Gradient Descent       NaN\n",
       "59       Stochastic Gradient Descent Convergence       NaN\n",
       "60               Map Reduce and Data Parallelism       NaN\n",
       "61                                   10.Practise  180 mins\n",
       "62                               11.Tools for ML  150 mins\n",
       "63                                         TOTAL  30 hours\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"States\"] =[\"Tamil Nadu\",\"Andhra Pradesh\",\"Karnataka\",\"kerala\"]\n",
    "df[\"Language\"]=[\"Tamil\",\"Telugu\",\"kannada\",\"Malayalam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'States': ['Tamil Nadu', 'Andhra Pradesh', 'Karnataka', 'kerala'],\n",
       " 'Language': ['Tamil', 'Telugu', 'kannada', 'Malayalam']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\"TN\",\"AP\",\"KA\",\"KL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.DataFrame(df,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Telugu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KA</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL</th>\n",
       "      <td>kerala</td>\n",
       "      <td>Malayalam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            States   Language\n",
       "TN      Tamil Nadu      Tamil\n",
       "AP  Andhra Pradesh     Telugu\n",
       "KA       Karnataka    kannada\n",
       "KL          kerala  Malayalam"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[\"Population\"]=[\"70M\",\"50M\",\"70M\",\"40M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Language</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>70M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>50M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KA</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>kannada</td>\n",
       "      <td>70M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL</th>\n",
       "      <td>kerala</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>40M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            States   Language Population\n",
       "TN      Tamil Nadu      Tamil        70M\n",
       "AP  Andhra Pradesh     Telugu        50M\n",
       "KA       Karnataka    kannada        70M\n",
       "KL          kerala  Malayalam        40M"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_csv(\"./Dutch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_csv(\"./Dutch.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'States': {'TN': 'Tamil Nadu',\n",
       "  'AP': 'Andhra Pradesh',\n",
       "  'KA': 'Karnataka',\n",
       "  'KL': 'kerala'},\n",
       " 'Language': {'TN': 'Tamil',\n",
       "  'AP': 'Telugu',\n",
       "  'KA': 'kannada',\n",
       "  'KL': 'Malayalam'},\n",
       " 'Population': {'TN': '70M', 'AP': '50M', 'KA': '70M', 'KL': '40M'}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>fruits 2</th>\n",
       "      <th>vegetable 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>apple</td>\n",
       "      <td>onion</td>\n",
       "      <td>apple</td>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>mango</td>\n",
       "      <td>potato</td>\n",
       "      <td>mango</td>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>orange</td>\n",
       "      <td>beans</td>\n",
       "      <td>pine apple</td>\n",
       "      <td>carrot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit vegetable    fruits 2 vegetable 2\n",
       "a   apple     onion       apple       onion\n",
       "b   mango    potato       mango      potato\n",
       "c  orange     beans  pine apple      carrot"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     apple\n",
       "b     mango\n",
       "c    orange\n",
       "Name: fruit, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData[\"fruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>fruits 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>apple</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>mango</td>\n",
       "      <td>mango</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>orange</td>\n",
       "      <td>pine apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit    fruits 2\n",
       "a   apple       apple\n",
       "b   mango       mango\n",
       "c  orange  pine apple"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData[[\"fruit\",\"fruits 2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fruit          apple\n",
       "vegetable      onion\n",
       "fruits 2       apple\n",
       "vegetable 2    onion\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fruit', 'vegetable', 'fruits 2', 'vegetable 2'], dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>fruits 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>apple</td>\n",
       "      <td>onion</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>mango</td>\n",
       "      <td>potato</td>\n",
       "      <td>mango</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>orange</td>\n",
       "      <td>beans</td>\n",
       "      <td>pine apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit vegetable    fruits 2\n",
       "a   apple     onion       apple\n",
       "b   mango    potato       mango\n",
       "c  orange     beans  pine apple"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData.loc[:,\"fruit\":\"fruits 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlData.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Syllabus</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Introduction to Machine learning</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.a  Introduction to Data Operation</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.Types of ML algorithm- an overview</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.Linear Algebra</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.Linear Regression</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.Logistic Regression</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.Regularization</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.Machine Learning System Design</td>\n",
       "      <td>90 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.Supervised Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8.Unsupervised Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9.Large Scale Machine Learning</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10.Practise</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>11.Tools for ML</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>30 hours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Syllabus  Duration\n",
       "0     1.Introduction to Machine learning   60 mins\n",
       "1    1.a  Introduction to Data Operation  150 mins\n",
       "8   2.Types of ML algorithm- an overview   60 mins\n",
       "12                     3.Linear Algebra   180 mins\n",
       "20                   4.Linear Regression  240 mins\n",
       "28                 5.Logistic Regression  150 mins\n",
       "35                      5.Regularization   60 mins\n",
       "39      6.Machine Learning System Design   90 mins\n",
       "45                 7.Supervised Learning  180 mins\n",
       "50               8.Unsupervised Learning  180 mins\n",
       "55        9.Large Scale Machine Learning  120 mins\n",
       "61                           10.Practise  180 mins\n",
       "62                       11.Tools for ML  150 mins\n",
       "63                                 TOTAL  30 hours"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateData = pd.DataFrame(data={1:['a','b','a','c','b'],2:[2,3,4,5,6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2\n",
       "0  a  2\n",
       "1  b  3\n",
       "2  a  4\n",
       "3  c  5\n",
       "4  b  6"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateData.drop_duplicates(inplace=True,subset=1,keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2\n",
       "2  a  4\n",
       "3  c  5\n",
       "4  b  6"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            class  petal_length  petal_width  sepal_length  sepal_width\n",
       "0  Iris-virginica           5.5          1.8           6.4          3.1\n",
       "1  Iris-virginica           5.9          2.3           6.8          3.2\n",
       "2  Iris-virginica           5.4          2.3           6.2          3.4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class  petal_length  petal_width  sepal_length  sepal_width\n",
       "100  Iris-setosa           1.5          0.2           5.0          3.4\n",
       "101  Iris-setosa           1.7          0.3           5.7          3.8\n",
       "102  Iris-setosa           1.3          0.4           5.4          3.9\n",
       "103  Iris-setosa           1.9          0.4           5.1          3.8\n",
       "104  Iris-setosa           1.6          0.2           5.0          3.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>1.477143</td>\n",
       "      <td>0.245714</td>\n",
       "      <td>5.028571</td>\n",
       "      <td>3.465714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>4.240000</td>\n",
       "      <td>1.322857</td>\n",
       "      <td>5.925714</td>\n",
       "      <td>2.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>5.528571</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>6.537143</td>\n",
       "      <td>2.934286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 petal_length  petal_width  sepal_length  sepal_width\n",
       "class                                                                \n",
       "Iris-setosa          1.477143     0.245714      5.028571     3.465714\n",
       "Iris-versicolor      4.240000     1.322857      5.925714     2.771429\n",
       "Iris-virginica       5.528571     2.020000      6.537143     2.934286"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(\"class\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Syllabus</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Introduction to Machine learning</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.a  Introduction to Data Operation</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basic Operations</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moving Data Around</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computing on Data</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plotting Data</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control Statements: for, while, if statement</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vectorization</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.Types of ML algorithm- an overview</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Supervisied learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unsupervisied Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Reinforcement Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.Linear Algebra</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Matrices and Vectors</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Addition and Scalar Multiplication</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Matrix Vector Multiplication</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Matrix Matrix Multiplication</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Matrix Multiplication Properties</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Inverse and Transpose</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Practice Quiz: Linear Algebra</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.Linear Regression</td>\n",
       "      <td>240 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Model Representation</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cost Function</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gradient Descent</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient Descent For Linear Regression</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Features and Polynomial Regression</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Normal Equation</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Normal Equation Noninvertibility</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.Logistic Regression</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Classification</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Multiclass Classification: One-vs-all</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.Regularization</td>\n",
       "      <td>60 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Problem of Overfitting</td>\n",
       "      <td>90 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Regularized Linear Regression</td>\n",
       "      <td>90 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Regularized Logistic Regression</td>\n",
       "      <td>90 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.Machine Learning System Design</td>\n",
       "      <td>90 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Prioritizing What to Work On</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Inverse and Transpose</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Error Metrics for Skewed Classes</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Trading Off Precision and Recall</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Data For Machine Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.Supervised Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SVM</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nearest Neighbour</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kernels</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>few more</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8.Unsupervised Learning</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>K-Means Algorithm</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Optimization Objective</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Random Initialization</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Choosing the Number of Clusters</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9.Large Scale Machine Learning</td>\n",
       "      <td>120 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Learning with large datasets</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Mini-Batch Gradient Descent</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Stochastic Gradient Descent Convergence</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Map Reduce and Data Parallelism</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10.Practise</td>\n",
       "      <td>180 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>11.Tools for ML</td>\n",
       "      <td>150 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>30 hours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Syllabus  Duration\n",
       "0             1.Introduction to Machine learning   60 mins\n",
       "1            1.a  Introduction to Data Operation  150 mins\n",
       "2                               Basic Operations   60 mins\n",
       "3                             Moving Data Around   60 mins\n",
       "4                              Computing on Data   60 mins\n",
       "5                                  Plotting Data   60 mins\n",
       "6   Control Statements: for, while, if statement   60 mins\n",
       "7                                  Vectorization   60 mins\n",
       "8           2.Types of ML algorithm- an overview   60 mins\n",
       "9                           Supervisied learning  180 mins\n",
       "10                        Unsupervisied Learning  180 mins\n",
       "11                        Reinforcement Learning  180 mins\n",
       "12                             3.Linear Algebra   180 mins\n",
       "13                          Matrices and Vectors  240 mins\n",
       "14            Addition and Scalar Multiplication  240 mins\n",
       "15                  Matrix Vector Multiplication  240 mins\n",
       "16                  Matrix Matrix Multiplication  240 mins\n",
       "17              Matrix Multiplication Properties  240 mins\n",
       "18                         Inverse and Transpose  240 mins\n",
       "19                 Practice Quiz: Linear Algebra  240 mins\n",
       "20                           4.Linear Regression  240 mins\n",
       "21                          Model Representation  150 mins\n",
       "22                                 Cost Function  150 mins\n",
       "23                              Gradient Descent  150 mins\n",
       "24        Gradient Descent For Linear Regression  150 mins\n",
       "25            Features and Polynomial Regression  150 mins\n",
       "26                               Normal Equation  150 mins\n",
       "27              Normal Equation Noninvertibility  150 mins\n",
       "28                         5.Logistic Regression  150 mins\n",
       "29                                Classification   60 mins\n",
       "..                                           ...       ...\n",
       "34         Multiclass Classification: One-vs-all   60 mins\n",
       "35                              5.Regularization   60 mins\n",
       "36                    The Problem of Overfitting   90 mins\n",
       "37                 Regularized Linear Regression   90 mins\n",
       "38               Regularized Logistic Regression   90 mins\n",
       "39              6.Machine Learning System Design   90 mins\n",
       "40                  Prioritizing What to Work On  180 mins\n",
       "41                         Inverse and Transpose  180 mins\n",
       "42              Error Metrics for Skewed Classes  180 mins\n",
       "43              Trading Off Precision and Recall  180 mins\n",
       "44                     Data For Machine Learning  180 mins\n",
       "45                         7.Supervised Learning  180 mins\n",
       "46                                           SVM  180 mins\n",
       "47                             Nearest Neighbour  180 mins\n",
       "48                                       Kernels  180 mins\n",
       "49                                      few more  180 mins\n",
       "50                       8.Unsupervised Learning  180 mins\n",
       "51                             K-Means Algorithm  120 mins\n",
       "52                        Optimization Objective  120 mins\n",
       "53                         Random Initialization  120 mins\n",
       "54               Choosing the Number of Clusters  120 mins\n",
       "55                9.Large Scale Machine Learning  120 mins\n",
       "56                  Learning with large datasets  180 mins\n",
       "57                   Stochastic Gradient Descent  180 mins\n",
       "58                   Mini-Batch Gradient Descent  180 mins\n",
       "59       Stochastic Gradient Descent Convergence  180 mins\n",
       "60               Map Reduce and Data Parallelism  180 mins\n",
       "61                                   10.Practise  180 mins\n",
       "62                               11.Tools for ML  150 mins\n",
       "63                                         TOTAL  30 hours\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlData.fillna(method=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDict[\"a\"]=\"apple\"\n",
    "jsonDict[\"b\"]=\"ball\"\n",
    "jsonDict[\"c\"]=\"cat\"\n",
    "jsonDict[\"d\"]=5\n",
    "jsonDict[2]=\"dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'apple', 'b': 'ball', 'c': 'cat', 'd': 5, 2: 'dog'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": \"apple\", \"b\": \"ball\", \"c\": \"cat\", \"d\": 5, \"2\": \"dog\"}'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(jsonDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-3533d09cf640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjsonData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid file path or buffer object type: {_type}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "jsonData = pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'mango', 'orange']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(csvData.fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a):\n",
    "    return a*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[2,4,3,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 6, 10, 12]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(add,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dif(a,b):\n",
    "    return a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lambda x,y:x-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif(40,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(40,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ---  ---   ---\n",
      "  |    |    |    | \n",
      "   ---  ---   ---\n",
      "  |    |    |    | \n",
      "   ---  ---   ---\n",
      "  |    |    |    | \n",
      "   ---  ---   ---\n"
     ]
    }
   ],
   "source": [
    "a=[' ',' ',' ',' ',' ',' ',' ',' ',' ']\n",
    "\n",
    "print (\"   ---  ---   ---\")\n",
    "print ('  | ' +'' +a[0]+ '  | ' +a[1]+ '  | ' +a[2]+'  | ' )\n",
    "print (\"   ---  ---   ---\")\n",
    "print ('  | ' +'' +a[3]+ '  | ' +a[4]+ '  | ' +a[5]+'  | ' )\n",
    "print (\"   ---  ---   ---\")\n",
    "print ('  | ' +'' +a[6]+ '  | ' +a[7]+ '  | ' +a[8]+'  | ' )\n",
    "print (\"   ---  ---   ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7f6448480160>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [1,2,3,4,5,6,7,8,9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(map(str,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.reshape(a,[3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[' ', ' ', ' '],\n",
       "       [' ', ' ', ' '],\n",
       "       [' ', ' ', ' ']], dtype='<U1')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "userInput = {0:(0,0),1:(0,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', ' ', ' '], dtype='<U1')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[2] #--> row value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', ' ', ' '], dtype='<U1')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[:,0] #--> column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " B[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(a):\n",
    "    print (\"   ---  ---   ---\")\n",
    "    print ('  | ' +'' +a[0][0]+ '  | ' +a[0][1]+ '  | ' +a[0][2]+'  | ' )\n",
    "    print (\"   ---  ---   ---\")\n",
    "    print ('  | ' +'' +a[1][0]+ '  | ' +a[1][1]+ '  | ' +a[1][2]+'  | ' )\n",
    "    print (\"   ---  ---   ---\")\n",
    "    print ('  | ' +'' +a[2][0]+ '  | ' +a[2][1]+ '  | ' +a[2][2]+'  | ' )\n",
    "    print (\"   ---  ---   ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ---  ---   ---\n",
      "  |    |    |    | \n",
      "   ---  ---   ---\n",
      "  |    |    |    | \n",
      "   ---  ---   ---\n",
      "  |    |    |    | \n",
      "   ---  ---   ---\n"
     ]
    }
   ],
   "source": [
    "display(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib \n",
    "plotly\n",
    "seaborn\n",
    "bokeh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7]\n",
    "y = [1,4,9,16,25,36,49]\n",
    "plt.plot(x,y,color=\"black\",linewidth=2)\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"n**2\")\n",
    "plt.title(\"Line graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7]\n",
    "y = [1,4,9,16,25,36,49]\n",
    "plt.scatter(x,y,color=\"black\",linewidth=2,marker='x')\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"n**2\")\n",
    "plt.legend([\"data\"],loc=\"upper left\")\n",
    "plt.title(\"Line graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7]\n",
    "y = [1,4,9,16,25,36,49]\n",
    "plt.plot(x,y,color=\"black\",linewidth=2)\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"n**2\")\n",
    "plt.title(\"Line graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = np.arange(0., 5., 0.2)\n",
    "plt.plot(t, t, 'r--', t, t ** 2, 'bs', t, t ** 3, 'g^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4,\n",
       "       2.6, 2.8, 3. , 3.2, 3.4, 3.6, 3.8, 4. , 4.2, 4.4, 4.6, 4.8])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.,5.,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXl4VNX5+D8nGwkQFNklEBBREUWK+SkBxAKCCFRFRfQLIlXEpbW1VnHBtiqitrUura0VUVGhCuIKVSwCAiLIoqDsskUQBUR2CCHk/f3xzpCFLJPM3SZzPs8zTzI3957zntyZ957znncxIoLFYrFY4osEvwWwWCwWi/dY5W+xWCxxiFX+FovFEodY5W+xWCxxiFX+FovFEodY5W+xWCxxiFX+FovFEodY5W+xWCxxiFX+FovFEock+S1AWdSvX19atGjhtxgWi8USUyxZsuRHEWlQ0XmOKH9jzEtAP2C7iJxVyt8N8AzQBzgIDBWRL8prs0WLFixevNgJ8SwWiyVuMMbkRHKeU2afcUDvcv5+CdA69BoOPOdQv8cxYQK0aAEJCfpzwgS3erJYLJbYxRHlLyJzgJ/KOeUy4FVRFgAnGmOaONF3USZMgOHDISfnACKQk6Pv7QPAYrFYiuPVhm9TYHOR91tCxxxl5Eg4eHA9cAbwOgAHD+pxi8VisRQSqA1fY8xw1CxE8+bNK339t98CNAdaAjcCbYD2oeMWi8VPjhw5wpYtW8jNzfVblGpBamoqGRkZJCcnV+l6r5T/d0CzIu8zQseKISJjgDEAWVlZlS400Lw55OQkA28CPwOGAYto3txURWaLxeIgW7ZsIT09nRYtWqA+IJaqIiLs3LmTLVu20LJlyyq14ZXZ531giFE6AntE5HunOxk9GmrWBGgEPAosISXlHUaPdroni8VSWXJzc6lXr55V/A5gjKFevXpRraIcUf7GmNeB+cDpxpgtxpgbjTG3GGNuCZ3yAbABWAe8ANzmRL8lGTQIxoyBzEyAwSQlnUHDhn/i//7PViuzWIKAVfzOEe3/0hGzj4hcW8HfBfiVE31VxKBB+oIkXnzxLoYNG8Znn31G586dvejeYrFYYoJqnd7hmmuuIT09nTFjxvgtisVi8Zndu3fzr3/9q9ix3r17c+KJJ9KvXz/H+zt8+DAXXXQR7du3Z+LEiQBcddVVbNiwAYBHH3202Pk33HADDRs25KyzisfJ3nXXXcycOdNx+aq18q9VqxaDBw9m0qRJ7Nmzx29xLBZLJXA6YLM05X/33Xfz2muvRddwGXz55ZcALF26lIEDB7JixQqOHj3KKaecAhyv/IcOHcq0adOOa+f222/n8ccfd1y+aq38AYYMGUJubi5TpkzxWxSLxRIhhQGbOBawee+997J+/Xrat2/P3XffDUCPHj1IT08v85rVq1dz3nnnHXu/adMmzj777GPtnXnmmbRr14677rqr2HXbt29n8ODBLFq0iPbt27N+/XomTJjAZZddduzaQ4cO0b59ewapnZquXbty0kknHSdDZmYmO3fu5Icffqj64EtDRAL5Ovfcc8UJjh49KhkZGXLppZc60p7FYqkaK1eujPjczEwRVfvFX5mZVe9/48aN0rZt2+OOz5o1S/r27Vvmdeecc45s2LBBREQef/xxGTVqlPz4449y2mmnSUFBgYiI7Nq1q8J2u3btKl999dWx97Vq1YpYxmHDhsnkyZOPO17a/xRYLBHo2Go/809ISODKK6/ko48+Yu/evX6LY7FYIqCswEw/AjavvvrqYzb7iRMnMnDgQE444QRSU1O58cYbefvtt6mpPubl8v3339OgQYXJNkulYcOGbN26tUrXlkW1V/6gmyyHDx/mww8/9FsUi8USAWUF+Fch8D9qBg4cyKRJk1i7di3GGFq3bk1SUhILFy7kqquuYurUqfTuXV5eSyUtLa3Kfvm5ubmkpaVV6dqyiAvln52dzUknnWSVv8USIxQGbBZSsyZRBWymp6ezb9++Sl/XqlUrEhMTGTVqFAMHDgRg//797Nmzhz59+vDUU0+xbNmyCttp06YN69atO/Y+OTmZI0eORCTD2rVrj/MCipa4UP6JiYmcdlovXnttGsYU2FTPFkvAKRqwaYz+HDMmHMNTNerVq0fnzp0566yzjm34XnDBBQwYMIAZM2aQkZHBRx99VOq1AwcOZPz48Vx99dUA7Nu3j379+tGuXTu6dOnCk08+WWH/ffv25ZNPPjn2fvjw4bRr1+7Yhu+1115LdnY2a9asISMjgxdffBHQnEjr1q0jKyur6oMvBaP7A8EjKytLnCrmMmEC3HDDq+TlXQ8sATpQs2b0HyaLxRI5q1atok2bNn6L4RuHDh2iW7duzJs3j8TExIive+edd/jiiy8YNWrUcX8r7X9qjFkiIhU+KeJi5j9yJOTlXRx6p6Yfm+rZYrF4SVpaGg899BDffXdcTstyyc/P5/e//73j8gQqpbNbqIdAI6Ad8Akwsshxi8Vi8YaLL7644pNKMGDAABckiZOZf6GHwIXAZ0BeieMWi8USX8SF8i/0HLgQrR+/OGrPAYvFYoll4kL5hz0HMjK6AnDiibPtZq/FYolr4kL5gyr6zZsb0LZtW84/f7ZV/BaLJa6JG+Uf5sILL+TTTz+NOLjCYrFUD0pm9Vy6dCnZ2dm0bduWdu3aHUvh4BSVSem8efNmunXrxplnnknbtm155plnjv3NrZTOvidwK+vlVGK3kkycOFEAWbBggSvtWyyW0qlMYjc3KJk0bc2aNbJ27VoREfnuu++kcePGpSZoqyrz58+XHj16HHu/fPlyufzyy4+9L5rYbevWrbJkyRIREdm7d6+0bt1aVqxYISIimzZtkp49e5bah03sVgm6dlW7/+zZs32WxGKxeEnJlM6nnXYarVu3BuDkk0+mYcOG7Nixo9g1XqV0btKkCR06dAA0DUWbNm2OxQO4ldI5Lvz8i9K4cWNOP/10Zs+ezYgRI/wWx2KJS+644w6WLl3qaJvt27fn6aefLvPvjz/+OMuXLy+134ULF5KXl0erVq2KHT/jjDPIy8tj48aNtGzZ8lhWz507d/LOO++wevVqjDHs3r272HUNGzZk7NixPPHEE0ydOhWAefPmce211x6T5dlnny1Vlk2bNvHll19y/vnnHzvWoUMH5s2bx5VXXhn5P6QCnCrg3tsYs8YYs84Yc28pfx9qjNlhjFkaeg1zot+qcuGFFzJ37lyOHj3qpxgWiyUAfP/991x33XW8/PLLJCQcrxK9TOm8f/9+rrzySp5++mnq1Klz7LgbKZ2jnvkbYxKBfwI9gS3AImPM+yKyssSpE0Xk19H25wSdO3dmzJgxrFq1yvFMeRaLpWLKm6F7yd69e+nbty+jR4+mY8eOpZ4zcOBABgwYwBVXXHEspTPoamHGjBlMnjyZZ599tsJN2YpSOh85coQrr7ySQYMGccUVVxT7W1BTOp8HrBORDSKSB7wBXOZAu64RvskLFizwWRKLxeIVJVM65+Xl0b9/f4YMGcJVV11V5nVepHQWEW688UbatGnDnXfeedy1QU3p3BTYXOT9ltCxklxpjPnKGDPZGNPMgX6rTOvWralbt65V/hZLHFEypfOkSZOYM2cO48aNo3379rRv377MfQi3UzrPmzeP1157jZkzZx6T5YMPPgACnNLZGHMV0FtEhoXeXwecX9TEY4ypB+wXkcPGmJuBgSLSvZS2hgPDAZo3b35uTk5OVLKVR58+ffj2229Zvny5a31YLJZCbErn6pfS+Tug6Ew+I3TsGCKyU0QOh96OBc4trSERGSMiWSKSVdVal5HSsWNHVq5cyZ49e1ztx2KxWCB4KZ2dUP6LgNbGmJbGmBTgGuD9oicYY5oUeXspsMqBfqOiY8eOiAiLFi3yWxSLxRInXHzxxTSvZDrhAQMGcOKJJzouS9TKX0TygV8DH6FKfZKIrDDGPGyMuTR02m+MMSuMMcuA3wBDo+03WsKBG9bub7F4R7RmZksh0f4vHfHzF5EPROQ0EWklIqNDx/4oIu+Hfr9PRNqKyDki0k1EVjvRbzSceOKJtGnTploo/wkToEULSEjA1ie2BJbU1FR27txpHwAOICLs3LmT1NTUKrcRdxG+RcnOzua9995DRDDG+C1OlZgwAYYP17KUADk5+h5sympLsMjIyGDLli3HpVCwVI3U1FQyMjKqfH1cK/+OHTvy0ksvsX79ek499VS/xamQCRO07vC330KjRkto3foffPbZTI4e3QecDlwFDOfgwTqMHGmVvyVYJCcn07JlS7/FsISIu8RuRYmlYK/wDD8npwCRe/nhh/OYO/ddjh7tBFwLGOBuoA3wsa1PbLFYyiWulf+ZZ55J7dq1Y0L5jxwJBw8eBYYAfwZuAHJITHwD+BcwP/Q6AbiYunXH+iarxWIJPnGt/BMTEznvvPNiQvnrTP4+YAIwGhgDnMDRo+H6xAAdgUUkJPTip59u4uWXX/ZFVovFEnziWvkD1K7dkSVLlmHMwUB7ytSr9xbwV+A24H7UzAOZmVqfODMTjIHMzFq89NJ79OrVi2HDbqJRo+nWC8hisRxHXG/4TpgA06Z1BPKBL8jJ6RJIT5nt27dz+PAtJCScS0FBYTbEmjVh9GiVtbi8KRw5Mpnp07PZvn0wsIycnMaBHJvFYvGHuJ75jxwJeXnhgglq+jl4UI8HibvuuovDh/cyevQ4MjOTQzN8nfGXpcgfeSQdkYnAPuA6oCCQY7NYLP4Q18pf7egNgVPQzdKix4PB559/zmuvvcadd97JvfeexaZNUFAAmzaVP4PXMbQF/g58jG4SB2tsFovFP+Ja+Rem2OgIfF7KcX8REe6++24aNWrE/fffX6lrC8dwI3A18CdgZWDGZrFY/CWulf/o0WFPmY5oItItx+zoQWDGjBnMnTuXP/zhD6Snp1fq2sKxGeBZoA4JCcMZNarABUktFkusEdfKf9AgtZs3bqzBXvXrLyjXju4lIsKDDz5I06ZNGTas8iWPw2NTL6AG1Kv3BAUF8zh0yPr/WyyWOFf+oEoyJ+ccatSowfXXLwiE4p8wAZo0+Yx58+Zx8OA9TJ5co0rtDBrEsT2CHTuu5+c//zkjRozghx9+cFZgH7DJ7CyW6Ih75Q+QkpJChw4d+Pzzzys+2WXCaRy2bfsbUJddu25g+PDolZsxhueff55Dhw4xYsQIR2T1gtKUfGGqCxApTGZnHwAWSyUQkUC+zj33XPGS3/3ud5Kamip5eXme9luSzEwRWCdgBO4XVW963Anuv/9+AaRRozlijLY7frwzbTvN+PEiNWuKQL7AbIEHJCGhjyQmthM4XeBcgWsEnhJYKM2bF8j48TqmoI/NYnELYLFEoGPtzD9Ex44dyc3N5auvvvJVDnXFfAFdlN1W4nj0nHLK/RjTjG3bfoVIfqBnzffdd5CDB/8KtAQuBB6joGALR49mAucADYB5wO+A8/j229P55S9Hk5Pzg10RWCwVYJV/iKBk+GzWLA94GegHND123CkXzVGjaiHyNPA1mhAueIFtIsK7777L5s1nAiOA1sAbwC5gGVoldCLwIfAtsBX9nzXlyJEH0IfFncAPgRubxRIUrPIP0axZM5o0aeK78r/ssveA7cDNx4456X6qK4j+QC/gD8C2Isf9I2zbN2YPtWsPoH///iQn1wZmATOAgYC6u9arVzSZHUATatYcGjp3TejcvwOtgMfJycnzbBxOUNZmdmWPWyzlEoltyI+X1zZ/EZH+/fvLqaee6nm/RenRo4fUr58pzZvnu2K31j0FEVgjkCxwvaN7ClWh0Lb/tUBrgURJTn5chg/PCx0vfNWsqeeXZtsvHJsIrBW4TABJSjpN7rnno8DtBZQ2hsL/RfEx33JLgaSlHRY4Wuz4rbeWfn4QxmfxByK0+TuiqIHe6JRrHXBvKX+vga7T16GhtC0qatMP5f/nP/9ZANmxY4fnfYuIfPPNNwLII4884lofxZXLvQJIjRqf+qosVGl/KFBToLHAnGMPpMps4JamOGvU+EBOOOFUAQSuFNgcCAVZmqxpaXslPf0jgT8LDBLIFmgukBqSP/yqKdBUIFuMuVbgPoFxAl8J5FXpf+cVZcnk9nE/8VpWz5Q/kAisRxPkpKBG2TNLnHMb8O/Q79cAEytq1w/lP3v2bAFk6tSpnvctInLPPfdIYmKibN261dV+CmfJ+yUxsZk0b36OHDlyxNU+ywP+I5Ak0F5g6zFlaEzl2yrtC9W8+SGBUSElWlvgbwJHfF3t6P+/QGCRwMMCF4T+B2EF30ygu8B1AncJ/CE0hj8K/F7gl6G/n1LiuhoCWQK3SkrKOIGVx1YL5a2anKYyq5pbb5XQquY7gdUCX0lq6mLp33+e1KgxS+ATgQUCX0pq6koZNGiDpKX9KOoFFtkqqLwxu/ngKW/Mbq3YvFT+2cBHRd7fB9xX4pyPgOzQ70nAj4Apr10/lP/+/fslMTFRHnjgAc/7zs/Pl6ZNm8ovfvELT/t98803BZB//OMfnvYb5t///reoW+uFAruLfRmcUs7GhNtcL9AnpCTbCczzRRE+/fQmgUdE3VUJjf9cgXsE/iews9j/AUQSE+W4Y4XH80NKfkLowfDz0EMu/ECoI9BD4D5JT39X0tK2ipsK8niFd1hSU78JrWqeExghcJVAR4FWAicUkbWyrxNDD8AsgV6irr+/FviTwN8FJkh6+keSmrpYYKPAXoGCYmOujHIu73haWn6o/a0C6yQ1dZnUqfOZwHSBd0UnOS8IPC3GjBZ15b5L4HcCvxH4ldSufYvcdNNN8uijj1b58xap8jd6btUxxlwF9BaRYaH31wHni8ivi5yzPHTOltD79aFzfiyr3aysLFm8eHFUslWFDh06UK9ePaZPn+5pvzNmzOCiiy5i0qRJDBgwwLN+RYRevXqxaNEi1q5dS8OGDT3re+zYsdx00020b9+XNWsmc+hQ6rG/1axZfsrqytCihbp9KgK8C/wG2EJi4jCOHn0cqOd4v1AYkHbw4F5gMvAqMDv01wvRdNuXAfUB3cw+dEg9sMLUrAnXXw+vvBL5cS35uQa1si4Mvb5Ca1cAZADnA+cB51G3bhtycxty6JAp1s6YMfq7jqGsvvNRj6scUlJySEzcxKFDG4ENodcWoGhOqRSgBdAMzapbH3XbbYBu6tcIvVJCLwFygcOh1yFgL/AT6gH2U+i1s8jPXcffjGL91yM5uR4JCSdw+HC4v9RjfRuThMjR0P/raOiVDxwBDgD7Qz+L/n6onD5LIyHUX2KxV+PGiWRlZTFlypRKtqcYY5aISFaFJ0byhCjvBVwFjC3y/jrg2RLnLAcyirxfD9Qvpa3hwGJgcfPmzav85IuGW2+9VdLT0yU/P9/TfocOHSp16tSRgwcPetqviMiqVaskOTlZhg4d6npfhSancQJG2rXrLbm5ua7OwEu3r++T1NS7BBJDM89RoVlb1VccJcfwyitHpGHDDwSulUK7fWuBUXLiiRsrbaKozPHim9/h10GBeaJBcdeGZsxFZ9GpAqeFVglXCgyV9PTfSJ06d4dmp7cL3BK6tpfoaqV56H9YckbeRKCzwGBRU9U40UC9zVJ007riVU1Vjx8R2C6wSuBTgfcEXhT4i+gKa5hAf1HTWWfRlcPZofE3Fzg59LOlwKkCZwi0FTVNdha4WOAKgSECtwrcLfCgwF9FVzevCkwW3cuaI7AkJMu3AjslISFX1OxXfAxOrHaxZp+q8corrwggy5cv96zPAwcOSHp6utx4442e9VmSESNGCCCNG3/mmgmkUAmPFzV1XCRpaQc92ZQrTUGqOWi5hL2CoJ7oJvimKilgHdvRkJK7VaBBqN2TBG4TtVvrF94Yd23vZZkz6tUrqTR3CHwgaiL5vRSaY9oIZIg+GGuImpHqhsbUSuA8gUtE9yRGCowR+EjUZn+wVOVcr55zJpbKHD9+zIWKtvSHpHMPpMqOOdZs/kno2q4lhRu+bUuc8yuKb/hOqqhdv5T/mjVrBJDnn3/esz7feOMNAWTWrFme9VmSsWP3iTEZoS/9AUc/jGH0izZRIEHULn3AsdlO1eUJvxYKXB6SLUESEnoIPC3qMnq0zC9sWlqBPPXURqlXb7zAUNEZLwJpAldLQsLbArmlKh63qcwGpJMKsiyF59SqprLHyxqz0zZ/p8YcLZ4pf+2LPsDakDlnZOjYw8Clod9TgTdRV8+FwCkVtemX8i8oKJBGjRrJoEGDPOuzX79+kpGRIUePHvWsz5LoF/x/IcV1mytKSpfBiQJdBPYd66MqXj1OUNoXPzU1R9LSRoYegmETRm2B80MPh8GiS/1+oWN1ipxXV3Tm/Hqx8QXND99tBemVR1G0Y67ob7HqZuqp8nfj5ZfyFxG5+uqrJSMjQwoKClzva/v27ZKUlCT33HOP632VR6FHzO9DimyKo4r53XffFXVJzJawbd3LWXBZlG0OEoFvBJ4X9R7pJmoTbilqC24vahu/TeDf0rjxIinqelh0bEFRChXhpIK0+IdV/lHw7LPPCiAbNmxwrY/CTbl/CCCPPfa1a31FQuHSPlfgHIH6At86opinTp0qycnJ0qrVeZKWVtyd0+9ZcGlU1swRVnpBm+Fb4hOr/KPgq6++EkDGjRvnSvvFFcX5Auf4riiKy7RKoI4Y017Gjt1fpbbCs8H69f8jiYnJ0qFDB9m1a1dMzBSrGpgTC2OzVH+s8o+Co0ePykknnSQ33HCDK+0XzizXhkwsf/Xd/CFSXHk1bPiBGJMgPXv2lNzc3Eq1UaggnxRAEhK6yvPP73JPcBewZg5LrGKVf5RcdtllriV5K7Qp/1HU5XGLrxufZfHSSy8JIGeffbE0a7YvIoWnD7Z9oukHEPWFPuT7g81iiRciVf42pXMZ1KrVlXXr1mHMVsfT5GpufgHGAz0I5+13Kme/U/zyl79k2LCxfP31dDZv7oLImmIFUkpLJZyTswTIAsYBI4FJQKrvKaMtFksJInlC+PHyc+Y/frxIjRqLQjPX1x3fvNP254XaHxfozUGdyX8gGgCVKppB8rsSvtwFAl9IYuKQ0ErmZIGZgfHosVjiCezMv+qMHAmHD7dH84zMAZytdjVoEHTpMh5j0oAryMx0Np+Mk+iM/RI0du9K4DGgGTt3duDgwSuAvmielg4cPfomqal3kpa2HOh2rA0ni9FYLBZnsMq/FFThJQFd0CpSRY9HT15eHl9+OZFrrrkckXQ2bQqm4oeipqimqJlqLVoBrD7wDfA9miDs38B3HD78BC+8UJfMTDCGQD/YLJZ4JslvAYJI8+bhLJA90TqxOUCmYzb5Dz/8kJ9++onBgwc706CLjB5dMqNja2rWfJC0NNi58/jzmzdXRW+VvcUSbOzMvxRGjw7XiO0VOjLdUdPF+PHjadCgAT179nSmQRcZNEhn7iVn8s88U7KOrjXvWCyxhJ35l0J41nr//Wfy7bcnU7PmdMaMGebIbHb37t1MmTKFm2++meTk5Ogb9IDyZvIjR6o5rHlzVfx2xm+xxAZ25l8GgwZBTo5h6NBe1KgxnYED8yu+KAImT57M4cOHY8LkUxGDBsGmTVBQQKD3LSwWy/FY5V8Bffv2ZdeuXcyfP9+R9saPH89pp51GVlbFhXYsFovFLazyr4BevXqRnJzM+++/H3Vb33zzDbNnz2bIkCEYYyq+wGKxWFzCKv8KqFOnDt26dXNE+Y8ZM4bExERuuOEGBySzWCyWqmOVfwRceumlrF27ltWrV1e5jdzcXF5++WUuv/xymjRp4qB0FovFUnms8o+A/v37Y4xh4sSJlb42nP8mLe0tdu7cSevWtzgvoMVisVQSq/wj4OSTT+bCCy/k9ddf11SoETJhggZIacDYv4FTeeaZ7o4mibNYLJaqYJV/hFx77bWsWbOGpUuXRnzNyJHhyNjlwKfAzRw6lOBYjiCLxWKpKlEpf2PMScaY6caYb0I/65Zx3lFjzNLQK/qdUx+48sorSUlJYdy4cRFfU5gL6Cm0hv3QEsctFovFH6Kd+d8LzBCR1mgGtHvLOO+QiLQPvS6Nsk9fqFevHldddRWvvPIKBwsT3ZSL5gLaArwG3IgmQwte3n6LxRJ/RKv8LwNeCf3+CnB5lO0FmltuuYU9e/bwxhtvRHT+6NGQlPQEUADcBdj8NxaLJRhEq/wbicj3od9/ABqVcV6qMWaxMWaBMabMB4QxZnjovMU7duyIUjTn6dKlC82anc0tt/wNY45WWOGrc+dNwHPUqnU9xrSw6Y0tFktgqDCxmzHmY6BxKX8qtm0pImKMKcsVJlNEvjPGnALMNMZ8LSLrS54kImOAMQBZWVmRu9V4xH/+Y9i27QGOHBkITCYnZyDDh+vfSlPoI0eOJCkpgdWrHyIjw1NRLRaLpVwqnPmLyEUiclYpr/eAbcaYJgChn9vLaOO70M8NwCfAzxwbgYeMHAl5eVcBZwJ/BHLLrPA1bdo0/vOf/3DXXXeRYTW/xWIJGNGafd4Hrg/9fj3wXskTjDF1jTE1Qr/XBzoDK6Ps1xfUSycB9d5ZCzx87HjRYubNmu1g8ODhtGnThpHWr9NisQSQaJX/40BPY8w3wEWh9xhjsowxY0PntAEWG2OWAbOAx0UkJpV/oZdOL+AG4M/AO5x0UmEwl8hBtmy5nJ07t3PNNa+Qmprqm7wWi8VSFqYyEatekpWVJYsXL/ZbjGKEI3bV03M/WuZxCTVrjuLgwUHAGuAOYAUwkczMAWza5Ju4FoslDjHGLBGRCnPG2wjfSlC8pGFtMjI+oEOHSzh48F6gGbr42QZMAwbYYC6LxRJYbBnHSlK8pGFd4D2aNFnADz8sAxoAvQEtbmuDuSwWS1CxM38HeOKJjtSseTNwBWHFb4O5LBZLkLHK3wGKm4OwwVwWiyXwWLOPQxQ3B1ksFkuwCay3jzFmB5ATRRP1gR8dEidWsGOOD+yY44OqjjlTRBpUdFJglX+0GGMWR+LuVJ2wY44P7JjjA7fHbG3+FovFEodY5W+xWCxxSHVW/mP8FsAH7JjjAzvm+MDVMVdbm7/FYrFYyqY6z/wtFovFUgZW+VssFkscUu2UvzGmtzFmjTFmnTGmrILy1QpjzEt+nlx8AAAgAElEQVTGmO3GmOV+y+IFxphmxphZxpiVxpgVxpjf+i2TFxhjUo0xC40xy0LjfshvmbzAGJNojPnSGDPVb1m8whizyRjztTFmqTHGlfTG1crmb4xJRKus9AS2AIuAa2O1fkCkGGO6ojmmXxWRs/yWx21CVeOaiMgXxph0YAlweRzcZwPUEpH9xphk4FPgtyKywGfRXMUYcyeQBdQRkX5+y+MFxphNQJaIuBbYVt1m/ucB60Rkg4jkAW8Al/ksk+uIyBzgJ7/l8AoR+V5Evgj9vg9YBTT1Vyr3EWV/6G1y6FV9Zm+lYIzJAPoCYys611I5qpvybwpsLvJ+C3GgFOIZY0wLtCb05/5K4g0hE8hStF72dBGp7uN+GhgBFPgtiMcI8D9jzBJjzHA3Oqhuyt8SRxhjagNvAXeIyF6/5fECETkqIu2BDOA8Y0y1NfMZY/oB20Vkid+y+EAXEekAXAL8KmTadZTqpvy/Q0tqhckIHbNUM0I277eACSLytt/yeI2I7EZrYvf2WxYX6QxcGrJ/vwF0N8aM91ckbxCR70I/twPvoCZtR6luyn8R0NoY09IYkwJcA7zvs0wWhwltfL4IrBKRJ/2WxyuMMQ2MMSeGfk9DHRtW+yuVe4jIfSKSISIt0O/yTBEZ7LNYrmOMqRVyZMAYUwvoBTjuyVetlL+I5AO/Bj5CNwEnicgKf6VyH2PM68B84HRjzBZjzI1+y+QynYHr0Jng0tCrj99CeUATYJYx5it0ojNdROLG/TGOaAR8aoxZBiwE/isi05zupFq5elosFoslMqrVzN9isVgskWGVv8ViscQhVvlbLBZLHBLYAu7169eXFi1a+C2GxWKxxBRLliz5MZIavp4pf2PMS0A4aKPCwJQWLVqweLEr+YwsFoul2mKMyYnkPC/NPuOo3gEpFovFEjN4pvw9TT524AD88IMnXQWCI0dgwQLIieiBXz0oKIB4c1MWgeXLYdmy+Br7unWwaBEcPeq3JNWKQG34GmOGG2MWG2MW79ixo+oNvf8+NGkCQ4ZAbq5zAgaRadN0rNnZ0KIFXHIJ7N7tt1TusmgRtGwJX32l7zduhO/iIIvHfffB2WdD+/ZwxhmwapXfErnLtm1wwQXQujWcdx6sWeO3RO5z8KBnD/ZAKX8RGSMiWSKS1aBBhfsVZXP++XDXXfDaa/CLX1TfGcPKlTq+jAyYNAkeeURn//n5fkvmHp9/DhdeCMZAQoJ+UQYOhI4dq/9q709/gpdfhhdfhD17oFOn6vsA2LlTJzRffAF/+xtMngxt2ujf8vL8lc0tcnP1sz1qlDf9iYhnL6AFsDySc88991yJmjFjREDk0UejbyuozJ4tsndv4fu8PP9kcZt9+0RatRLJzBT54YfC40uWiKSmivTpI1JQ4Jt4rnDkiMidd4ps3lz8+MaNIvXri/zxj76I5TrXXy+SnCzy2WfFj7/0kkjr1iK7dvkilqv87neqr956K6pmgMUSiT6O5CSnXp4r/4ICkauvFklLE9mxI/r2gsTWrWX/bc8ekYEDRebM8U4eL/j970WMKX1cf/+7fpwnTPBeLjd5+mkd1+uvH/+3LVu8l8crNm4sfcyffy6SmChy662ei+Qqixbpfb7ttqibilT5e5bbJ5R87OdAfWAb8CcRebGs87OyssQRV8/t22HvXjj11OjbCgpLl0JWlpp6rrji+L8fPAitWqldeNYs7+Vzi9tu0yX/2FKKOhUUwM9+BocOqTksKbAhLJFz4ACccgq0bQszZ5Z93vr10KAB1KnjnWxuIaImvfK47Tb9DKxdq/tc1YE+fdSkuXFj1PfRGLNERLIqPDGSJ4QfL0dm/iWpLiaByy8XOeGE8pe+zzyjM4mZM72TywvKu4fvvScyeLDITz95J4+bPPGE3sO5c8s+59tvRZKSRB5+2Du53OTNN0UuuaT8lfrmzSIpKSLDhnknl5ts2SJSs6bI44870hxBm/lXFsdm/qCziSuu0FnU3/7mTJt+sWmTjmPkyPI3hnJzoVkz9ZZ4O8Zrnezfr7Pbc87xWxLvKCjQ1VtmJnzySfnn9umjq8GcHEhO9kQ817jgAt24X70aEhPLPu+WW+DVV9UjKD3dO/ncYvt2qFVLX1ES6cw/UN4+rmEMpKbCSy+pWSCWeeEFHc/wCsp6pqbCDTeo2+vWrd7I5hYTJqh747JlkZ3/5Zf6sIhlDh7UCcudd1Z87q23wvffw5Qp7svlJitWwKefws03l6/4Qd1ev/gi9hV/2BOxYUNHFH9liA/lDzpT2L1b7eSxytGjMG4c9O2rs/qKGD4cfvtbdYmMZZ5/Xmf97dpVfO7+/dClCzz+uPtyuUnt2rpKvfTSis/t00c/D88/775cbvL885CSAkOHVnxuZqbuacU6Tz2lrukHDnjedYxrhUrQtatu+o6P4RKgiYmweLF+YCKhVStVII0buyuXm6xcqTP5G2+seCMQVGkOGABvvgmHD7svnxvs3q0bvJHGpyQmqsKcNSt2A/zy8+GNN+Cyy6B+/ciu2bQJrrlGPx+xyvjx+rn2eNYP8aT8jdFgoJkz1b4WqzRpoko9UvLzYfp02LDBPZncZOJEXbkMGBD5Nddco0FQH33knlxu8vbb0KNH5ZTa7bfDli1w4onuyeUmeXnwu9/pCj1S6tSBt96C1193Ty43WbNGTZnXXONL9/Gj/AEGD1ZzQCxuiuXlQf/+MGdO5a7bvVtTPrzwgjtyuc2UKRr1WJnVS48eUK+ePjhikYkTdVP/3HMjv6ZBA7Ubxyo1a6odv3v3yK856STo1UtNuQF1XCmXSZN0UlqZiY2DxJfyP+MMuPtuqFvXb0kqz8cfw7vvwr59lbuufn246KLY/YLMmVP5B1dysm6WTp8ee6k9du6EGTPg6qsjM3MV5Ysv9F7H2gZ/fr6udir72QZdzefkwMKFzsvlNm++CZ07Q9OmvnQfX8ofNOBr4kQ1C8QSU6aoPfuiiyp/7eWXq9ln9Wrn5XKb2rUrZ+YKM3q02oQr8hoJGtOm6QOrf//KX5uSog+O//7XebncZP58uPJK+N//Kn9tv35qFpw61Xm53EQEfv1rzUHmE/Gn/JcvVxvbtGl+SxI5Ivrh7tULatSo/PV9++rPWPuC3HKLejdVhQYN1JQQa3z8MTRqpBHclaVtW/WCibX7PHWqrtZ69qz8tSedBNddp/c7lgi7a192mW8ixJ/yP/98tQfH0hdk2TLdzOvXr2rXN2umrpKV3S/wkx9/hDFjoqtREPYeiSVz1wsvwNy5VXPPNUY/Ix9/HFvxLFOn6r5OVdMajBsHv/mNoyK5zgcf+G6eiz/ln5ioftEffBA79uB9+zSfeZ8+VW/jv//VPYNYYdo0VdrhVUtV2LtXg9xWrnROLrdJStL89VWlXz8NEKsoKjgobNyo9yea+wxa0CiaGiBecuCA7kk98YSvYsSf8gc1n/z0U+QRo35zwQWa9KlRo6q30bRpbNm/P/5YV2gdOlS9jV699OeMGc7I5DbPP6824GhWKl27QrdusXOvw6vRiy+Orp1zzlEbeiwwb57GoEQ75iiJT+XfrZv+nD/fXzkiIT/fuSX83XfDX/7iTFtuIqIBS926RRed3KKFVvyKlcymr72mJp/KevkUpWZNjWUJP/iCzpAhWpAm2mjdrCy9z7Fg4ps1S1d4Xbr4KkZ8Kv+mTXW5edttfktSMXPmaODOZ59F39bSpbER4XzgAJx5ZnRmrjDdu6sJJOgmvv37dXVXGT/3itqLhRKmxqjij+aBB/p/27FD8wMFnZkztfKcD1G9RYlP5Q86K4z2A+cFs2ap4jrrrOjb6t4dvv46+BHOtWvDhx/CL38ZfVt9+qjZbNeu6Ntyk3nzdJXnhPJftkxjWT78MPq23GTtWr3H33wTfVvh1Xx5dQ+CwL59sGRJobw+Er/Kf9MmGDRIb0SQmTkT/t//c6ZQR1ixBH0z0ElPlSuu0E3fSPPF+MXMmeru2Llz9G21aaM+/0E3d02frp46ThTeyczUqOigK//0dPj220BYHeJX+deuDf/5T7Dzv+zbp5GLTpkCzj1XP3xB/oKI6Jf4vvucbXfvXmfbc5qUFM3g6URsQkqKrnaCfJ9B5cvM1H0ZJ/jb33RfK+icfHIgki3Gr/KvX189BIL8Bfn0UzUFOLVETErStAFBTm+xcqUW84jG3bEkDz+s+zxHjjjXptOMGgWTJzvXXvfuav/ets25Np2koEBXJk5NbEAj2Z1YObnJHXfAe+/5LQUQz8ofVKnOmxfcjbEzzoDHHoNOnZxrc+xYbTOohB/GTiqFtm11A3TRIufadJK8POfbDE8Ygmr6WbZM92GcvM+gpqSgBjPu2AHPPBOYTen4Vv7du6viX7DAb0lKp2VLuPde59MUiGggUBCZNUs3450szP3zn+vPoK7yRozQDX0n3RQ7dIAnn9SI9iDy44+6unN64/OOO4I7uZk9W38GYLMX4l35d+0KZ5+ts8KgsX+/blS6UZyjQwfN/x40RHTWFlbWTlGvnpr4wl++oDF7tgbwOel9lpio+fGdsqc7Tc+e6u3jdEbLbt00ViI/39l2nWD2bJ3IVSVvkwvEt/I/4QT46quq58xxkwULNC/N558733ZGhjNxA06Tn6/2+SFDnG+7c2f9XwbN33//fv0MOmnaC7N7t+4jBK26l4h7wVidO2ucyNdfu9N+NCxYoGlaAlJPJL6Vf5iCguBFBoZNUW4s2zt10vTOO3c633Y0JCerC5wby+LBg9UMErQZ4aJF+vnLzna+7a+/1kIhQbOBb9yohWc++MD5tsMP0aBNbgoK9PPdtavfkhzDKv+PP9a0sEGbKcyfr1GubpTlC3tEBC29xaJFGn/hBtnZMGxY1VJiu0n4Id+xo/NtZ2WpwgmaIpw/X23+bhQxad5cXSmDVtwlIUHvw0MP+S3JMazyP+UULewSpC+IiCoFN2aDoEohKSlYYwa46SbNce4W69cHbxZ8/vnwwAM6AXGatDTd3wnafZ4/X1MbOBG1XhJjdLwvvuh829UMq/xbttTNtnnz/JakkLVrNeuoW8q/Zk149NGqVQVzi337dPXl1pgB7rkHrr/evfarQvfu6uPvFp066YrKDXfSqjJ/vtq+3co8mpnpTNSwk1x3HQwd6rcUxbDK3xg1gwRpdtS6tQY7XX65e33cfbfzPtbRsHixe7bvMJ06qVkpKDVud+3SB56bm9CdOqk785dfutdHZThwQH383bzPu3bBr36lJt0gIKLxBwUFfktSDKv8Qb8gGzZoZGkQSEjQ/Cz16rnXR36+Fvz+/nv3+qgM4f0HN/3Sw3sdQXnQT50K7dq5G/Rz8cWwbp3OtINAbq66oEZbvKU8ateGl18OTi3jnByNtHZjXycKrPIH6N0b7r/fbykKefDBqhWzrgzbtmmun4kT3e0nUubP14hmN1NP/OxnkJoaHOW/YIHmWmrb1r0+0tOhVavgZLCtVw/++ld3XFvDJCfrwy4o9zk8sXFztVMFrPIH/fKNHh2IZEvs26c2YLc/uE2bqm00KF+Q556DV191t4+UFM2QGpT9Hbdt32FmztQqV0FwZ167VqtYuU2nTrqyDUIk+/z5us929tl+S1IMq/zDHDyoHxa/WbjQfdt3mE6dVBEGQSlkZKhidpvnngtGYq0DBzS4y4v7vHo1/POf7rnRRoqIZhu9+Wb3++rcWU2bQcjndM45ugcRsE1oq/zDPPigfhG9mJWUhxe27zCdOunm5+bN7vdVHnPnwt//7k2CvbZtg7HCW7xYN3q9esiD/3EdGzdqISEvPtsdO0KzZuo15zc33hjI8qlW+YfJzlZ3OL9n//Pn62avG8FdJQkrHr+Vwuuvq6+7F2HvIpr3/f333e+rPDp00A1JL+q4nnWW+tX7fZ/DAW1ePPDq1dOiKf37u99XeezeHdhaElb5hwmKIvzxR3c3w4rSrp1uLDtRKzca5s/X2aDbtm/Qjc/nnoNXXnG/r/JIT9f/uxMV2ioiKUn3Fvz+bLsZ3BVUXnhBnRiCsAIpgVX+YRo31jTCfn9BPv8c/v1vb/pKTtbsiunp3vRXGuHEZl56QmRn6332a69DBJ54wtu87p066crWz8R24Q1ur2zfH3+s6R7Wr/emv9KYP1/1ihsR3FFilX9ROnYMRm5/LzeG1qzRfCN+FbQJJzbz0ge6Y0eNb/j2W+/6LMqGDRpk9+mn3vU5apQ+ZL1YXZXF00/Dn/7kXX8NG+p+ll8TOhHtO2AunmE8Vf7GmN7GmDXGmHXGmHu97DsiRoyAN9/0b0b4wAPeh4CvWqWb3X7tdXzzjSokL5W/3yY+P/y+g+Dn36ULXHihd/21basBX35N6L79VgNH4135G2MSgX8ClwBnAtcaY870qv+I+NnPVAn59UWZMsX71AN+K8LhwzWxnpfL4nbttJaDX15OCxaoUnIzuKs0br0VbrjB2z7DzJmjEc1eTqwSE/3d6whocFcYL2f+5wHrRGSDiOQBbwCXedh/ZEyZoi+v2bcPli/3/oPSqJEmt/Nzr6NWLW/7S0rSeqp33+1tv2G8Cu4qyYEDmkPfj5XtU09pWgevJ1bZ2ZpL6MABb/sFnUg++6xONgKIl8q/KVB0qrUldOwYxpjhxpjFxpjFO3bs8FC0Ivz5z5rx0mvcLOpREdnZ/iyNN2zQDefFi73v269qSnl5GuXqR56Xjh01rYfXwV5+2r5799agMj8ifVu0CGRwV5hAbfiKyBgRyRKRrAYNGvgjRHa22r+9DvbyMrirJNnZmgnR6wfuvHnqkZGS4m2/oHsdP/+5O2UyyyMlRSuojRjhbb/gn4lv0yZ96Pih/Lt00ehmr/VJbq7Gr/g1iY0AL5X/d0CzIu8zQseCRTjYy+sUuI0awTXXuJvYrCxuvFHt7l5/QebPdz+xWVnUq6cFtefO9b7vlBTdc/Cas8/2J9gr3J9fWS2PHtXMml6yZAn83/8FJ3dWKXip/BcBrY0xLY0xKcA1gM9hlqXg1+xo2DCdKfhBWpo/S9NwQWs/3A8bNtQqbl7f5/vu06yWfpCUpJ+zM87wtt8lS/Sh41dis5tv1s+Zl3sdAd/sBQ+Vv4jkA78GPgJWAZNExMMolwhp0kSzXS5b5l2fublw5Ih3/ZXGP/7hrSeIl4nNyqJjR2+DvUTgpZe8De4qydNPqx3aS/76Vx2zX7bvrCzNKbRxo3d9zp+vk4uGDb3rs5J4avMXkQ9E5DQRaSUio73su1IsXKjFILxi0iQN89+wwbs+S7JlC4wf712w148/qs3dS7/vkmRnexvsFU5s5ndRj9xc9S7zioQEnVD5RXiC4ZVTQ8CDu8IEasM3MDRs6K1L2vz5agdu0cK7PkvSsaOuPrza68jM1M1eP+sId+2q3iD793vTXxBMAXv26H7Dc895098XX2gsh5+ZY9u29XavY/NmnVT4/ZCvAKv8S2PnTvjlL92vphVmwQL18knw8XZ4vdfht5kL1P/6ww+923BesECVkB8b3GFOOEFTHXs1C54xQ5ObpaZ6019peJ3Yrlkz9XC69lpv+qsiVvmXRno6vPEGfPSR+335kdisNLxMbCeiM/8//MH9viLBqwCgtDStXeu337eXie3mz4dTT/Xek6wkI0fCY49505cx+vl2swa3A1jlXxopKVrf1gtF+Pnn/gV3leSyy9Tl1G3Wr9dlcfPm7vdVEU88oV9SL/Y6/vKXYNRMzs7WnDNuuz+KqKujVynKy6NHDw0o9IKRI+Hdd73pKwqs8i+L7Gx1UXM72KtlS824GAT74NNPazi624Rr6AZBKZx6qt7jJUvc7aegwN32K4NXG6AbNmhwVxDuM2gtY7cndAcOaJaAhQvd7ccBrPIvi44dvQn2OuUUzebpReWuSMnPd7f9zz5T23ObNu72EwleKcLHHoPTT/e/TCiov/1f/qKrWzf5/nud3ARF+d98s/vlFMPlOTt3drcfB7DKvyyys/XLumePe30UFOiGo5t9VAYRDQByO/XAvHn6//VzgzuMV4nt5s1TW3+NGu72EwlJSZrUrnVrd/vp0kVn/34Fd5XEi72O8Ko2CGbcCgjAty+gnHwyrF4NF1/sXh8rV2opv/fec6+PymAM1K/vriIU0RnYTTe510dlcVspFBRo+0GZAYPmcnrvPTh0yG9JvCM72/3Edp99pivaAFbuKolV/hXhxSwhSErB7cR2xsDtt8MVV7jTflUYOlQ36dyyy69apYW8g2QKmDsXLr/cvb2O3buhaVMNYAwK4X01Nyc3Bw7ABRe4176DWOVfHu+9py5q37mUf+6zzzSgrFUrd9qvCm4ntluxQqOJg0TPnnDbbe7lGAon9wrSQ95tRfj551qYKEgz4HBiOzczuc6a5V0AXZRY5V8ejRtrwJdbX5B581QhBKHEXhi3g71+8xt1KQ0amza5Nws+/XTNp+O2jb0yhBPbubXR/dlnuqfjR4ryskhK0nv8xBPu9hOEvawIiA0p/eJnP9MNOjcU4bZt6u8epNkgaGK7e++FDh2cbzs/X2ddQRszwJAhOvt3g65d1YU2SA95cHevY948jaBOT3e+7Wg4/XT3CvnccYemcY4RrPIvj3Cwlxuzo/r1NXPooEHOtx0tjz3mTsK1r75Sm2iQbN9hsrPV1OV0sNf+/eo44EfpxIpwK7Fd+CEfxPu8dasqaTfMmtOmeZcnygGs8q+I7Gz13XVaKSQm6szo5JOdbdcJCgpUUe/a5Wy7n36qP4M488/O1nxDTpeU/Phj9f4IYlGPq6/WzehmzSo+tzIcOqR1A/r1c7ZdJ0hOhmeecT51y44dsGZNMD/bZWCVf0Vcfjn89rfO1wB9+GGNOAwiK1bAOefA+w7X2pk1S+3MQUjrUJILLlCzzKxZzrY7c6bm9Pl//8/Zdp2gQQON63DaRp2ergXbe/d2tl0naNBAE+s5fZ8/+UR/duvmbLsuYpV/RXTpolGBTnot/PQTPPhgoatn0GjbVs1STj+cnnkGXn3V2Tadol49aN/e+THPnKkPFj/qFEfCJ5/AXXc52+bq1e5HiUdD9+66Cs3Lc67NmTP1oed21LSDWOUfCXl5sHSpc+3Nnq024O7dnWvTSRISdAYza5azturmzYNpBw4zdixMmOBce9u26SoqqPcZ1Lz3t785l+TtyBFd5dx5pzPtuUG3brqSdzL/Trt26jDgd8bWSmCVfyQ89JB+oJ3azJk5E2rWDKYpIEy3blqUYv16Z9qbMgX+/e9gbnyG6dDB2T2YsCkgyMo/LJtTZpDFi/V70rWrM+25wYUXqlfbDz841+att8LjjzvXngdY5R8J3brpMja8YRktQTcFQKFScMoM8q9/wd//Hjx3x5I89xy8/rozbV18Mbz9troMB5W2bdUO7tR9Drfz8587054bnHSSBm5edZUz7X3/fUx5+YSxyj8SOnVSLwEnviAHDuiSM8izQYDTTtOkc9dcE31bR45oOoGgjxl0T+If/3CmrRNPhP79g20KMEbvy8yZzqzKZs5UZ4H69aNvy03CkxAnxnz//RrAF+RVbSlY5R8JNWuqK6ATyr9WLS3kHWSbKOiXo3dvLSwfLYsW6UMvFpR/9+5qC462wPnWrZrXfetWZ+Ryk27d9DO+c2d07eTmqhNDLNzn5cvV8yza77SIthG0SP0IsMo/Urp314RnTvm+B3k2GOaHH+CRR6K3+8+cqV8MNwLHnKZ7d83HPndudO1Mn66R0j/+6IxcbnLTTbB2bfSz9aQkXS0GKWNrWWRm6p7WjBnRtbNhgwbJxcIDrwRW+UfKkCHqpVO7dnTtdOkCTz7pjExuc/iw1tn973+jaycnR90oA17TFNAZXEpK9Eph5kwd71lnOSOXm4T9/KM1WyQl6SoiCEV6KiI9XYu6O3GfwSr/ak3LlrpJG01ekLVrdVnsVm4Rp8nMVFvmtGnRtfPCC97UQ3aCtDRdoWzfXvU2Cgo0grRHj5hJ8sXzz2tJy2j88596SlfHsULPnuqdFM3qbNo0TV19xhnOyeURMfLJDAhLl2rJxarOkMIz6CCGvZdFv346uzlwILp2glDBKlL++1947bWqX79kifr4/+IXzsnkNvXrqwmjqmkovv9e97GinSh4Sb9++qCORuaHHtLJTYzZ+8Eq/8rx5ZcwerQmZKsKU6eqa13Lls7K5Sb9+qn5p6rL41/9Cq67zlmZ3Ca8MqvqQ37lSl1BBDG9QVn06qXjnjKlatd/8IH+jKWJTYcO8OtfR5dq+6yz4JJLnJPJQ6zyrwx9+ugTvipfkD17YM6c2PpygO5RNGpUtdJ3BQUwebJuoMYat9xS9boD11+vnjNBd3csSnq6+uZXVflPnaoJ4oJSrzcSEhLUrbeqNQdef13HHaNY5V8ZGjXSCkhvvVX5aw8f1ihApwJLvCIlRStv/eY3lb/200/Vdn7ppc7L5TZ16qjnyk8/Ve668GohLc15mdzm0ks1M+XKlZW7bv9+3eO49NKYNH+wfLmOuzIUFMCIETBmjDsyeYBV/pXl6qvV7FPZD0vDhhrhmpXljlxuEnZLrexm4MSJqgRjbbUDep/z8+Hddyt33V//qvmLYrEw+pVXaq77WrUqd92KFbqnM3CgO3K5yeHDer8qm5ph/nydFF19tTtyeYBV/pVlwABdzq9dG/k1e/ao37hbBcLdRqSwzm2k5Oeryadfv+jdY/3g3HM1CGjixMpd98YbOvZYnPk3aaIeO5mZlbvu/PM1JiTISfvKokYNTdv+zjv6IIiUiRP12lhc1Yawyr+yNG2qH/TKeHJMnqyJrtyqEes2xqjJa/LkyIvaHD6sm73Dh7srm1sYozPZGTPUcycSVq9Wp4BYnAGHEdEkb998E9n5R47oNTVqxI5ba0kGDtQJ2ocfRnb+kSPw5pu6B+hEBLxPxOjd8pnERJ3F790b2fljxmjgSyyafMJcf71GN7/9dmTn1wXTLmoAAAdgSURBVKoFf/wjXHSRu3K5ydChWnch0gR8L7ygJrIYquN6HLt3q1KLNBDxX/9SH3enq755Sc+e0Lix3r9I2LRJH3ZDh7opletY5V8VRHTjNxIzyJdfaq6YW26Jzc2wMD16QKtWmpa5IrZt05mRk8Uy/OC00zSuo27dis/NzYVx49SE0Lix66K5Rt26aseeMKHiTJUi+nmoWzey/1FQSU7WspNz5+oKoCJat9aUJ337ui+bi1jlXxWM0dDwN9+sOCf4P/8Jqamx5+tekoQENeHMnasFQMrj+edVgVTFPTRo5OfrfY6k6tojj8Dvf+++TG5z882a2K6iqmuzZqmp6+abvZHLTe68U3P9nHBC+eft2KEP+sREfcUwRgKahjQrK0sWO11M20m++UZNObffrptkpZGbq0vifv3g2We9lc8NfvpJZ4Q33aQPtNLYvbswFYbTNYD9IC8PTj9dN/kXLozt1VukiOjm7ebNsG5d6dHZIpoGY906nQXH4gZ3aRQU6D0v6/M9eLB+DlauDGxyRmPMEhGp0MZsZ/5VpXVrTfb23HPq8lUaqamwapXOCKsDJ52kD7vU1LKjX598Uh8ADz3krWxukZKiye0WLy77YTZpkpo/YjGYrTSMgYcf1o3N1atLP2fhQl0FjhxZfRT/4cO6ov/DH0r/+4oV8J//BL9GQ6SIiOsvYACwAigAsiK55txzz5XAs2GDSFqayN13H/+35ctFDh70XiYveP99kR49RHJzix9fulQkJUVk4EB/5HKLvDyRNm1EmjYV+emn4n/bskWkbl2RTp1ECgr8kc8NCgrK//wWFIi88srxn4FYZ+hQkcREkYULix/PyxM57zy91zt2+CNbhACLJQId69XMfzlwBTDHo/68oWVLnf08+mjx46tXq5dLrNv5y8IYdYG87bbigV8HD2rJwupg4ipKcrLav7dtK56rfs8edRM8fFg3e6uTScgYndHn5+vqNhzpfPiwJjg0Rle+sZSwLxKefFLrOF97rebpBzUF/e53utp5/vnYSttRHpE8IZx6AZ9QnWb+RdmyRWe8t98ucuKJIg0binz1ld9SuccDD4iASMeOInfeKXLggB6vTrPfkjz3nMikSfr7u++KnHqqSFKSyBtv+CuXm3zyia7mWrTQ+9y+vcgJJ4j8+KPfkrnHZ5/pGBs0EFm2TOTIEZGLL9bxxwBEOPMPlPIHhgOLgcXNmzd363/jDq+9JtK8uUiNGiJ9+6pJqLozdqzI6afrMvnTT/2WxlsmTlQzwIwZfkviPnPnimRniyQkiJx9duEDsDqzfLlIz56FZr7Dh2NmYhOp8nfM28cY8zFQmoPzSBF5L3TOJ8BdIlKhG0/gvX1KQ0Q3/arDZlBlyM+PvzHHI/Y+xwSRevs4didFJIZDOR3CmPj8csTjmOMRe5+rFdbV02KxWOIQT5S/Maa/MWYLkA381xjzkRf9WiwWi6V0Ahvha4zZAeRE0UR9IIrKzDGJHXN8YMccH1R1zJki0qCikwKr/KPFGLM4kk2P6oQdc3xgxxwfuD1ma/O3WCyWOMQqf4vFYolDqrPyj93KylXHjjk+sGOOD1wdc7W1+VssFoulbKrzzN9isVgsZVDtlL8xprcxZo0xZp0x5l6/5fECY8xLxpjtxpjlfsviBcaYZsaYWcaYlcaYFcaY3/otkxcYY1KNMQuNMctC464mRRPKxxiTaIz50hgz1W9ZvMIYs8kY87UxZqkxxpU8N9XK7GOMSQTWAj2BLcAi4FoRWemrYC5jjOkK7AdeFZGz/JbHbYwxTYAmIvKFMSYdWAJcHgf32QC1RGS/MSYZ+BT4rYgs8Fk0VzHG3AlkAXVEpJ/f8niBMWYTmgTTtdiG6jbzPw9YJyIbRCQPeAO4zGeZXEdE5gA/+S2HV4jI9yLyRej3fcAqoKm/UrlPKGljuKp6cuhVfWZvpWCMyQD6AmP9lqW6Ud2Uf1Ngc5H3W4gDpRDPGGNaAD8DPvdXEm8ImUCWAtuB6SJS3cf9NDACrQIYTwjwP2PMEmPMcDc6qG7K3xJHGGNqA28Bd4jIXr/l8QIROSoi7YEM4DxjTLU18xlj+gHbRWSJ37L4QBcR6QBcAvwqZNp1lOqm/L8DmhV5nxE6ZqlmhGzebwETRORtv+XxGhHZDcwCevsti4t0Bi4N2b/fALobY8b7K5I3iMh3oZ/bgXdQk7ajVDflvwhobYxpaYxJAa4B3vdZJovDhDY+XwRWiciTfsvjFcaYBsaYE0O/p6GODav9lco9ROQ+EckQkRbod3mmiAz2WSzXMcbUCjkyYIypBfRC66A7SrVS/iKSD/wa+AjdBJwkIiv8lcp9jDGvA/OB040xW4wxN/otk8t0Bq5DZ4JLQ68+fgvlAU2AWcaYr9CJznQRiRv3xziiEfCpMWYZsBD4r4hMc7qTauXqabFYLJbIqFYzf4vFYrFEhlX+FovFEodY5W+xWCxxiFX+FovFEodY5W+xWCxxiFX+FovFEodY5W+xWCxxiFX+FovFEof8fwhQjvg9tCjTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(t):\n",
    "    return np.exp(-t) * np.cos(2 * np.pi * t)\n",
    "\n",
    "\n",
    "t1 = np.arange(0.0, 5.0, 0.1)\n",
    "t2 = np.arange(0.0, 5.0, 0.02)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(t1, f(t1), 'bo', t2, f(t2), 'k')\n",
    "plt.legend(['t1 vs f(t1)',\"t2 vs f(t2)\"])\n",
    "plt.subplot(212)\n",
    "plt.plot(t2, np.cos(2 * np.pi * t2), 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df1[\"class\"],bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X2cVlW99/HPVwh8QkzE0kECBTUkLUHUc4qjx1Q6puidBh5LLYvKLE/d1a11661mJz15LDua55CYoCl6SHMynzKwslJ5EBBIZVQ4gCbiI1iowO/+Y6+xi4t5uJiZNTPXNd/36zWv2Xvttff8FhfMj7XW3msrIjAzM+to23R1AGZmVpucYMzMLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycY6zEkLZZ0eFfH0ZUknShphaR1kj7Q1fFYbXOCsZogaZmkD5eVnSHpwcb9iNg/Ih5o5TpDJIWk3plC7WqXA2dHxI4R8Wj5wdT2YSX7IyTVS3pV0lpJMyUd2qkRW9VygjHrRN0gcb0HWFxJRUl7A78HHgOGAnsAPwd+JWlMtgitZjjBWI9R2suRNEbSHEmvSXpe0hWp2m/T91fSMNJhkraR9H8lLZe0WtI0Sf1LrntaOvaipPPLfs6FkmZIulHSa8AZ6Wf/UdIrkp6TdJWkPiXXC0lnSVqaeg3flrS3pD+keG8trV/WxiZjldRX0jqgF7BA0lMV/JFdCPwxIr4VES9FxNqI+CFwI3DZ1v3pW0/kBGM91ZXAlRGxE7A3cGsqH5u+75yGkf4InJG+jgD2AnYEroJiCAn4EXAqsDvQH6gr+1njgRnAzsBPgY3AV4BdgcOAI4Gzys45BhgFHAp8A5gMfALYExgJnNJMu5qMNSLeiIgdU50DI2Lv5v9o3nYU8N9NlN8KfEjSthVcw3owJxirJT9PvYJXJL1C8Yu/OW8BwyTtGhHrIuKhFuqeClwREU9HxDrgPGBiGu46CfhFRDwYEW8CFwDlC/z9MSJ+HhGbIuKvETE3Ih6KiA0RsQz4L+Afys75t4h4LSIWA4uA+9LPfxW4G2hugr6lWLfWrsBzTZQ/R9ET2qUN17QexAnGaskJEbFz4xdb9gpKnQnsAzwuabakj7ZQdw9gecn+cqA38K50bEXjgYj4C/Bi2fkrSnck7SPpTkl/TsNm/0rxy7zU8yXbf21if0ea1lKsW2sNRa+s3O4USbS8nWabcYKxHikilkbEKcBuFPMJMyTtwJa9D4BnKSbHGw0GNlD80n8OGNR4QNJ2wIDyH1e2fw3wODA8DdF9E1DbW1NxrFvrfuDkJso/DjwUEW+04ZrWgzjBWI8k6ROSBkbEJuCVVLwJeCF936uk+s3AVyQNlbQjRY/jlojYQDG3cpykv0sT7xfSerLoB7wGrJO0H/CFjmpXK7FurYuAv5P0HUm7SOon6UvApyiGAs1a5ARjPdU4YHG6s+pKYGKaH/kL8B3g92ku51DgOuAGijvMngHWA18CSHMkXwKmU/Rm1gGrgZb+d/814J+BtcCPgVs6sF3Nxrq1ImIp8EHgQGAZRSL+NnBiRNzfEcFabZNfOGbWcVKv4RWK4a9nujqejiRpEPAQ8P8iYkpXx2Pdn3swZu0k6ThJ26c5nMspHkxc1rVRdbyIWAl8BNg9JVKzFmVNMJLGSXpCUoOkc5s43lfSLen4w5KGpPIxkuanrwWSTqz0mmZdYDzF5PqzwHCK4baaHBqIiMci4pJ0C7RZi7INkUnqBTxJ8bDWSmA2cEpELCmpcxZwQER8XtJEirHdCZK2B96MiA2SdgcWUNx+Ga1d08zMuoecPZgxQEN64OtNiknQ8WV1xgNT0/YM4EhJioi/lNz1si1/u82zkmuamVk3kHPhvTo2f8BsJXBIc3VSb+VVimcI1kg6hOKOmPcAn0zHK7kmAJImAZMAdthhh1H77bdf+1tkZtaDzJ07d01EDGzr+V29smuzIuJhYH9J7wWmSrp7K8+fTLF+E6NHj445c+ZkiNLMrHZJWt56reblHCJbRbEwX6NBqazJOmmtpP6ULT8REX+ieLZgZIXXNDOzbiBngpkNDE9PFPcBJgL1ZXXqgdPT9knAzIiIdE5vAEnvAfajuO2zkmuamVk3kG2ILM2ZnA3cS7Hy6nURsVjSxcCciKgHpgA3SGoAXqJIGFA8PXyupLcolu04KyLWADR1zVxtMDOztusRT/J7DsbMbOtJmhsRo9t6vp/kNzOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCyL3l0dgFlPcMTUI5o9Nuv0WZ0YiVnncQ/GzMyycIIxM7MsnGDMzCwLJxgzM8vCk/y2hU9/+tPceeed7LbbbixatGizY/fccw/nnHMOGzdu5DOf+Qznnntui+XdJe4hQ4bQr18/evXqRe/evZkzZ06H//yWJvLNeiL3YGwLZ5xxBvfcc88W5Rs3buSLX/wid999N0uWLOHmm29myZIlzZZ3l7gbzZo1i/nz52dJLma2JSeYGnL44Yfz+OOPA/Diiy8ycuTINl1n7Nix7LLLLluUP/LIIwwbNoy99tqLPn36MHHiRO64445myyu1YMECxo4dy4gRI9hmm22QxAUXXNBhcXd3R0w9otkvs2rmIbIa0tDQwD777APAwoULed/73rfZ8Q996EOsXbt2i/Muv/xyPvzhD7d6/VWrVrHnnnu+vT9o0CAefvjhZssrsX79eiZMmMC0adMYM2YM559/PuvXr+eiiy7qsLgBJHH00Ucjic997nNMmjSpovPMrO2yJhhJ44ArgV7AtRFxadnxvsA0YBTwIjAhIpZJOgq4FOgDvAl8PSJmpnMeAHYH/pouc3RErM7ZjmqwfPly6urq2GabolO6cOFCDjjggM3q/O53v+uK0Fp0//33c9BBBzFmzBgADjjgAO655x4kvV2nI+J+8MEHqaurY/Xq1Rx11FHst99+jB07tt3XNbPmZUswknoBVwNHASuB2ZLqI6J0cP5M4OWIGCZpInAZMAFYAxwXEc9KGgncC9SVnHdqRHggvcSCBQs2Syhz585lwoQJm9Vpb0+grq6OFStWvL2/cuVK6urqmi2vxKJFizbrac2bN4+DDjqoQ+NujB1gt91248QTT+SRRx5xgjHLLGcPZgzQEBFPA0iaDowHShPMeODCtD0DuEqSIuLRkjqLge0k9Y2INzLGW9Xmz5/P+vXrAVi6dCl33HEHl1xyyWZ12tsTOPjgg1m6dCnPPPMMdXV1TJ8+nZtuuol99923yXKAI488kmnTpjWbcAYMGMDMmTMBePLJJ7ntttv4wx/+0KFxv/7662zatIl+/frx+uuvc99997VpjsfMtk7OSf46YEXJ/ko274VsViciNgCvAgPK6nwMmFeWXH4iab6k81U6ltKDLViwgE2bNnHggQdy8cUXM2LECKZOndqma51yyikcdthhPPHEEwwaNIgpU6YA0Lt3b6666iqOOeYY3vve9/Lxj3+c/fffv9nyTZs20dDQ0OLE+ymnnMK6desYOXIkkyZN4uabb2bAgPK/Au2L+/nnn+eDH/wgBx54IGPGjOHYY49l3LhxbfoZZlY5RUSeC0snAeMi4jNp/5PAIRFxdkmdRanOyrT/VKqzJu3vD9RTzLM8lcrqImKVpH7Az4AbI2JaEz9/EjAJYPDgwaOWL1+epZ3dxfDhw5k3bx79+vXr6lDetmjRIq677jquuOKKrg6lU3T2XV9eJNNykzQ3Ika39fycPZhVwJ4l+4NSWZN1JPUG+lNM9iNpEHA7cFpjcgGIiFXp+1rgJoqhuC1ExOSIGB0RowcOHNghDequ1q5di6RulVwARo4c2WOSi5ltKWeCmQ0MlzRUUh9gIkVvpFQ9cHraPgmYGREhaWfgl8C5EfH7xsqSekvaNW2/A/gosIgerl+/fjz55JNdHYaZ2WayJZg0p3I2xR1gfwJujYjFki6WdHyqNgUYIKkB+CrQuL7I2cAw4II01zJf0m5AX+BeSQuB+RQ9oB/naoOZmbVd1udgIuIu4K6ysgtKttcDJzdx3iXAJeXlyaiOjNHMzPLwUjFmZpaFl4ox2wpeH8yscu7BmJlZFu7BmDXBPRWz9nMPxszMsnAPxqxKtdTL8lP+1h24B2NmZlk4wZiZWRZOMGZmloUTjJmZZeEEY2ZmWTjBmJlZFk4wZmaWhROMmZll4QRjZmZZOMGYmVkWTjBmZpaF1yIzq0Fep8y6A/dgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzyyLrUjGSxgFXAr2AayPi0rLjfYFpwCjgRWBCRCyTdBRwKdAHeBP4ekTMTOeMAq4HtgPuAs6JiMjZDqtNLS2nUsuaa7eXkLGOlq0HI6kXcDXwEWAEcIqkEWXVzgRejohhwPeBy1L5GuC4iHgfcDpwQ8k51wCfBYanr3G52mBmZm2Xc4hsDNAQEU9HxJvAdGB8WZ3xwNS0PQM4UpIi4tGIeDaVLwa2k9RX0u7AThHxUOq1TANOyNgGMzNro5wJpg5YUbK/MpU1WSciNgCvAgPK6nwMmBcRb6T6K1u5JgCSJkmaI2nOCy+80OZGmJlZ23TrSX5J+1MMm31ua8+NiMkRMToiRg8cOLDjgzMzsxblnORfBexZsj8olTVVZ6Wk3kB/isl+JA0CbgdOi4inSuoPauWaZm/rqRP5Zt1Bzh7MbGC4pKGS+gATgfqyOvUUk/gAJwEzIyIk7Qz8Ejg3In7fWDkingNek3SoJAGnAXdkbIOZmbVRtgST5lTOBu4F/gTcGhGLJV0s6fhUbQowQFID8FXg3FR+NjAMuEDS/PS1Wzp2FnAt0AA8Bdydqw1mZtZ2WZ+DiYi7KJ5VKS27oGR7PXByE+ddAlzSzDXnACM7NlIzM+to3XqS38zMqpcTjJmZZeEEY2ZmWTjBmJlZFk4wZmaWhROMmZllUVGCkXSbpGMlOSGZmVlFKk0YPwL+GVgq6VJJ+2aMyczMakBFCSYi7o+IU4GDgGXA/ZL+IOlTkt6RM0AzM6tOFQ95SRoAnAF8BniU4k2VBwG/yhKZmZlVtYqWipF0O7AvxZslj0uLTgLcImlOruDMzKx6VboW2Y/TumJvk9Q3It6IiNEZ4jIzsypX6RBZUwtP/rEjAzEzs9rSYg9G0rspXkm8naQPAEqHdgK2zxybmZlVsdaGyI6hmNgfBFxRUr4W+GammMzMrAa0mGAiYiowVdLHIuJnnRSTmXWBll4vPev0WZ0YidWK1obIPhERNwJDJH21/HhEXNHEaWZmZq0Oke2Qvu+YOxAzM6strQ2R/Vf6flHnhGNmZrWitSGyH7Z0PCK+3LHhmJlZrWhtiGxup0RhZmY1p5K7yMzMzLZaa0NkP4iIf5H0CyDKj0fE8dkiMzOzqtbaENkN6fvluQMxM7Pa0toQ2dz0/TeS+gD7UfRknoiINzshPjMzq1KVLtd/LPCfwFMU65ENlfS5iLg7Z3BmZla9Kl2u/9+BIyKiAUDS3sAvAScYsx7Ay8hYW1SaYNY2JpfkaYoFL1skaRzFmy97AddGxKVlx/sC04BRwIvAhIhYlt6eOQM4GLg+Is4uOecBYHfgr6no6IhYXWE7rAa19MvPzLpOa3eR/a+0OUfSXcCtFHMwJwOzWzm3F3A1cBSwEpgtqT4ilpRUOxN4OSKGSZoIXAZMANYD5wMj01e5UyPCb9I0M+vGWuvBHFey/TzwD2n7BWC7Vs4dAzRExNMAkqYD44HSBDMeuDBtzwCukqSIeB14UNKwVltgZmbdUmt3kX2qHdeuA1aU7K8EDmmuTkRskPQqMABY08q1fyJpI/Az4JKI2OIZHUmTgEkAgwcPblMDzMys7Sq9i2xbiuGs/YFtG8sj4tOZ4mrJqRGxSlI/igTzSYp5nM1ExGRgMsDo0aO3SEBmZpbXNhXWuwF4N8UbLn9D8YbL1ib5VwF7luwPSmVN1pHUG+hPMdnfrIhYlb6vBW6iGIozM7NuptIEMywizgdeT+uTHcuWw13lZgPDJQ1ND2lOBOrL6tQDp6ftk4CZTQ13NZLUW9KuafsdwEeBRRW2wczMOlGltym/lb6/Imkk8Gdgt5ZOSHMqZwP3UtymfF1ELJZ0MTAnIuqBKcANkhqAlyiSEACSlgE7AX0knQAcDSwH7k3JpRdwP/DjCttgZmadqNIEM1nSOyluHa6neMPl+a2dFBF3AXeVlV1Qsr2e4pbnps4d0sxlR1UWspmZdaWKEkxEXJs2fwPslS8cMzOrFRXNwUgaIOk/JM2TNFfSD9LT9mZmZk2qdJJ/OrAa+BjFZPwa4JZcQZmZWfWrdA5m94j4dsn+JZIm5AjIzMxqQ6U9mPskTZS0Tfr6OMXdYWZmZk1qbbHLtRSLWwr4F+DGdGgbYB3wtazRmZlZ1WptLbJ+nRWImZnVlkrnYJB0PDA27T4QEXfmCcnMzGpBpbcpXwqcQ7HU/hLgHEnfzRmYmZlVt0p7MP8EvD8iNgFImgo8CpyXKzAzM6tuFQ+RATtTrBcGxarHZp3Gr0U2qz6VJpjvAo9KmkVxR9lY4NxsUZlZ1Wgp+c86fVYnRmLdTasJRpKAB4FDgYNT8f+JiD/nDMzMzKpbqwkmIkLSXRHxPrZ8n4uZmVmTKn2Sf56kg1uvZmZmVqh0DuYQ4BPpJWCvU8zDREQckCswMzOrbpUmmGOyRmFmZjWntbXItgU+DwwDHgOmRMSGzgjMzMyqW2tzMFOB0RTJ5SPAv2ePyMzMakJrQ2Qj0t1jSJoCPJI/JDMzqwWt9WDeatzw0JiZmW2N1nowB0p6LW0L2C7tN95FtlPW6MzMrGq19j6YXp0ViJmZ1ZZKH7Q0MzPbKk4wZmaWhROMmZll4QRjZmZZZE0wksZJekJSg6Qt3h8jqa+kW9LxhyUNSeUDJM2StE7SVWXnjJL0WDrnh+l1AmZm1s1kSzCSegFXU6wAMAI4RdKIsmpnAi9HxDDg+8BlqXw9cD7wtSYufQ3wWWB4+hrX8dGbmVl75ezBjAEaIuLpiHgTmA6ML6sznmI5GoAZwJGSFBGvR8SDFInmbZJ2B3aKiIciIoBpwAkZ22BmZm1U6WrKbVEHrCjZX0mx7H+TdSJig6RXgQHAmhauubLsmnVNVZQ0CZgEMHjw4K2N3cw6gF+n3LPV7CR/REyOiNERMXrgwIFdHY6ZWY+TM8GsAvYs2R+UypqsI6k30B94sZVrDmrlmmZm1g3kTDCzgeGShkrqA0wE6svq1AOnp+2TgJlpbqVJEfEc8JqkQ9PdY6cBd3R86GZm1l7Z5mDSnMrZwL1AL+C6iFgs6WJgTkTUA1OAGyQ1AC9RJCEA0uuZdwL6SDoBODoilgBnAdcD2wF3py8zM+tmck7yExF3AXeVlV1Qsr0eOLmZc4c0Uz4HGNlxUZqZWQ5ZE4zZ1mjpjiMzqz41exeZmZl1LScYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAs/yW+dyk/rm/Uc7sGYmVkWTjBmZpaFh8jMrEv4dcq1zz0YMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzy8IJxszMsvBSMdbhvGKytZeXkakN7sGYmVkW7sFYm7mnYmYtydqDkTRO0hOSGiSd28TxvpJuSccfljSk5Nh5qfwJSceUlC+T9Jik+ZLm5IzfzMzaLlsPRlIv4GrgKGAlMFtSfUQsKal2JvByRAyTNBG4DJggaQQwEdgf2AO4X9I+EbExnXdERKzJFbuZmbVfzh7MGKAhIp6OiDeB6cD4sjrjgalpewZwpCSl8ukR8UZEPAM0pOuZmVmVyJlg6oAVJfsrU1mTdSJiA/AqMKCVcwO4T9JcSZMyxG1mZh2gGif5PxgRqyTtBvxK0uMR8dvySin5TAIYPHhwZ8doZtbj5ezBrAL2LNkflMqarCOpN9AfeLGlcyOi8ftq4HaaGTqLiMkRMToiRg8cOLDdjTEzs62TM8HMBoZLGiqpD8WkfX1ZnXrg9LR9EjAzIiKVT0x3mQ0FhgOPSNpBUj8ASTsARwOLMrbBzMzaKNsQWURskHQ2cC/QC7guIhZLuhiYExH1wBTgBkkNwEsUSYhU71ZgCbAB+GJEbJT0LuD24j4AegM3RcQ9udpgZmZtl3UOJiLuAu4qK7ugZHs9cHIz534H+E5Z2dPAgR0fqZmZdbRqnOQ3sx6suRUkvEZZ9+O1yMzMLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwrcpW4v8UjEzaysnGDOrCS39Z8jPyHQND5GZmVkWTjBmZpaFE4yZmWXhBGNmZlk4wZiZWRZOMGZmloVvUzY/62JmWbgHY2ZmWbgHY2Y1zw9hdg33YMzMLAsnGDMzy8JDZD2EJ/LNrLO5B2NmZlm4B1ND3Esx23q+ASAfJxgzs2Y4+bSPh8jMzCwLJxgzM8vCQ2RmZm3g4bPWuQdjZmZZZO3BSBoHXAn0Aq6NiEvLjvcFpgGjgBeBCRGxLB07DzgT2Ah8OSLureSatcB3g5nVrp7U88mWYCT1Aq4GjgJWArMl1UfEkpJqZwIvR8QwSROBy4AJkkYAE4H9gT2A+yXtk85p7ZpVwUnErHb533chZw9mDNAQEU8DSJoOjAdKk8F44MK0PQO4SpJS+fSIeAN4RlJDuh4VXLPT9aT/kZhZPs39Lmnp90hbk1ln/G7KmWDqgBUl+yuBQ5qrExEbJL0KDEjlD5WdW5e2W7smAJImAZPS7huSFrWhDe2mM9QZP2ZXYE1n/KAuUMttA7ev2nVK+3L8Hqnwmvu252fU7F1kETEZmAwgaU5EjO7ikLKp5fbVctvA7at2PaF97Tk/511kq4A9S/YHpbIm60jqDfSnmOxv7txKrmlmZt1AzgQzGxguaaikPhST9vVldeqB09P2ScDMiIhUPlFSX0lDgeHAIxVe08zMuoFsQ2RpTuVs4F6KW4qvi4jFki4G5kREPTAFuCFN4r9EkTBI9W6lmLzfAHwxIjYCNHXNCsKZ3MHN625quX213DZw+6qd29cCFR0GMzOzjuUn+c3MLAsnGDMzy6ImE4ykXpIelXRn2h8q6WFJDZJuSTcIVCVJO0uaIelxSX+SdJikXST9StLS9P2dXR1nW0n6iqTFkhZJulnSttX8+Um6TtLq0uewmvu8VPhhaudCSQd1XeSVaaZ930t/PxdKul3SziXHzkvte0LSMV0TdWWaalvJsf8tKSTtmvZr4rNL5V9Kn99iSf9WUr7Vn11NJhjgHOBPJfuXAd+PiGHAyxRL1FSrK4F7ImI/4ECKdp4L/DoihgO/TvtVR1Id8GVgdESMpLiRo3EJoWr9/K4HxpWVNfd5fYTijsnhFA8JX9NJMbbH9WzZvl8BIyPiAOBJ4DyAsiWgxgE/SktKdVfXs2XbkLQncDTwPyXFNfHZSTqCYnWUAyNif+DyVN6mz67mEoykQcCxwLVpX8A/UixFAzAVOKFromsfSf2BsRR33xERb0bEKxR/IaamalXbvqQ3sF16Lmp74Dmq+POLiN9S3CFZqrnPazwwLQoPATtL2r1zIm2bptoXEfdFxIa0+xDF82pQsgRURDwDlC4B1e0089kBfB/4BlB6h1RNfHbAF4BL0zJdRMTqVN6mz67mEgzwA4oPf1PaHwC8UvIXvnTZmWozFHgB+EkaArxW0g7AuyLiuVTnz8C7uizCdoiIVRT/Y/ofisTyKjCX2vn8GjX3eTW1vFK1t/XTwN1pu+rbJ2k8sCoiFpQdqvq2JfsAH0pD0r+RdHAqb1P7airBSPoosDoi5nZ1LJn0Bg4CromIDwCvUzYclh5Urcp7z9NcxHiKRLoHsANNDFHUkmr+vFoj6VsUz7H9tKtj6QiStge+CVzQ1bFk1BvYBTgU+DpwaxoFapOaSjDA3wPHS1oGTKcYWrmSorva+FBpNS8vsxJYGREPp/0ZFAnn+cbuePq+upnzu7sPA89ExAsR8RZwG8VnWiufX6PmPq+aWQpJ0hnAR4FT428P21V7+/am+M/PgvQ7ZhAwT9K7qf62NVoJ3JaG+h6hGAnalTa2r6YSTEScFxGDImIIxYTUzIg4FZhFsRQNFEvT3NFFIbZLRPwZWCGpcYXTIylWOyhdcqdq20cxNHaopO3T/5oa21cTn1+J5j6veuC0dEfSocCrJUNpVUPFSwG/ARwfEX8pOdTcElBVISIei4jdImJI+h2zEjgo/busic8O+DlwBICKd3D1oVgtum2fXUTU5BdwOHBn2t4r/WE0AP8N9O3q+NrRrvcDc4CF6S/DOynmmX4NLAXuB3bp6jjb0b6LgMeBRcANQN9q/vyAmynmk96i+IV0ZnOfFyCKF+o9BTxGcTddl7ehDe1roBivn5++/rOk/rdS+54APtLV8W9t28qOLwN2rbHPrg9wY/r3Nw/4x/Z8dl4qxszMsqipITIzM+s+nGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzaQdK30qqzCyXNl3RIhp/xzY6+plln8G3KZm0k6TDgCuDwiHgjLd3eJyKe7aDri+L5itciYseOuKZZZ3IPxqztdgfWxN9Wnl0TEc9KWibpu6lHM0fSQZLulfSUpM8DSNpR0q8lzZP0WFpEEUlD0vs2plE87DaFYnXp+ZJ+KmkHSb+UtEDFO3MmdFXjzVrjHoxZG0naEXiQ4rUC9wO3RMRv0jpVl0XENZK+T7Hkzd8D2wKLIuJdja8jiIjXUs/nIYrlN94DPA38XRTLviNpXWMPRtLHgHER8dm03z8iXu3EZptVzD0YszaKiHXAKIoXTL0A3JIWeYRi7SYolg15OCLWRsQLwBsq3vAo4F8lLaRITnX8bdn+5Y3JpQmPAUdJukzSh5xcrDvr3XoVM2tORGwEHgAekPQYf1vE8o30fVPJduN+b+BUYCAwKiLeSr2ebVOd11v4eU+m1/H+E3CJpF+FdBvuAAAApUlEQVRHxMUd1ByzDuUejFkbSdpX0vCSovcDyys8vT/Fu4veSq+pfU8Ldd+S9I70M/cA/hIRNwLfo3hdg1m35B6MWdvtCPxHGvLaQLGK8CSK96C05qfAL1KvZw7FCtLNmQwslDQPmAZ8T9ImilVwv9CO+M2y8iS/mZll4SEyMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyz+P1xj897kQGBxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma = 100, 15\n",
    "x = mu + sigma * np.random.randn(10000)\n",
    "plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75)\n",
    "\n",
    "plt.xlabel('Smarts')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of IQ')\n",
    "plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
    "plt.axis([40, 160, 0, 0.03])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\mu=100,\\ \\sigma=15$\n"
     ]
    }
   ],
   "source": [
    "print(r'$\\mu=100,\\ \\sigma=15$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(0.0, 5.0, 0.01)\n",
    "s = np.cos(2 * np.pi * t)\n",
    "plt.plot(t, s, lw=2)\n",
    "\n",
    "plt.annotate('local max', xy=(2, 1), xytext=(3, 1.5),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             )\n",
    "\n",
    "plt.ylim(-2, 2)\n",
    "plt.savefig(\"dutch.png\",transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n = 12\n",
    "X = np.arange(n)\n",
    "Y1 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\n",
    "Y2 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\n",
    "\n",
    "plt.bar(X, +Y1, facecolor='#9999ff', edgecolor='white')\n",
    "plt.bar(X, -Y2, facecolor='#ff9999', edgecolor='white')\n",
    "\n",
    "for x, y in zip(X, Y1):\n",
    "    plt.text(x + 0.4, y + 0.05, '%.2f' % y, ha='center', va='bottom')\n",
    "\n",
    "plt.ylim(-1.25, +1.25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(X, +Y1,radius=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, 30, 45, 75, 85, 100]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([10,20,30,45,75,85,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.142857142857146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE6hJREFUeJzt3X+s1fd93/Hna9xAUpbYK7mJXCCBCjYPO40b35FUc6vWyC5W05CoeMHyElRZZZWN1KmrJjIpnoYSafwzb1W9qDQ4pWgetui8XDUkJC2ptlYK4ZKQ2thluyFEQNIabNepU2FK8t4f50N3cnTI/QL3h3t5PqSj8/1+vu/v93zeyRGve77fc75OVSFJ0j+Y6wlIkl4bDARJEmAgSJIaA0GSBBgIkqTGQJAkAR0DIcn6JMeTTCbZNmT7oiRPtO2Hkqxo42uTHG2PryX5QN8+J5M83bZNTFdDkqSrk6l+h5BkAfB/gLuA08Bh4L6qerav5kHgJ6rqV5NsAj5QVR9M8iPAhaq6mOQm4GvAj7X1k8BYVZ2bkc4kSVekyyeEtcBkVZ2oqgvAXmDDQM0GYHdb3gesS5Kq+puqutjGXw/4KzhJeo0a6VCzFDjVt34aePflatpf/y8DS4BzSd4NPAa8HfhQX0AU8PkkBfx2Ve0c9uJJtgBbABYvXnz7zTff3KkxSVLPkSNHzlXV6FR1XQLhmlTVIeCWJP8U2J3ks1V1Hrijqs4keQvwhSR/XlX/a8j+O4GdAGNjYzUx4eUGSboSSb7Zpa7LKaMzwPK+9WVtbGhNkhHgBuCF/oKqeg54Bbi1rZ9pz88DT9E7NSVJmiNdAuEwsDrJyiQLgU3A+EDNOLC5LW8EDlZVtX1GAJK8HbgZOJlkcZI3tvHFwN3AM9fejiTpak15yqhdE9gKHAAWAI9V1bEk24GJqhoHdgF7kkwCL9ILDYA7gG1J/hb4PvBgVZ1L8uPAU0kuzeHxqvrcdDcnSepuyq+dvpZ4DUGSrlySI1U1NlWdv1SWJAEGgiSpMRAkSYCBIElqDARJEjALv1R+rVix7TNz8ron/+MvzMnrgj3PJnuePXPV71yarf+t/YQgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSU2nQEiyPsnxJJNJtg3ZvijJE237oSQr2vjaJEfb42tJPtD1mJKk2TVlICRZADwK3AOsAe5Lsmag7AHgpapaBTwC7GjjzwBjVXUbsB747SQjHY8pSZpFXT4hrAUmq+pEVV0A9gIbBmo2ALvb8j5gXZJU1d9U1cU2/nqgruCYkqRZ1CUQlgKn+tZPt7GhNS0AXgaWACR5d5JjwNPAr7btXY5J239LkokkE2fPnu0wXUnS1Zjxi8pVdaiqbgH+GfCRJK+/wv13VtVYVY2Njo7OzCQlSZ0C4QywvG99WRsbWpNkBLgBeKG/oKqeA14Bbu14TEnSLOoSCIeB1UlWJlkIbALGB2rGgc1teSNwsKqq7TMCkOTtwM3AyY7HlCTNopGpCqrqYpKtwAFgAfBYVR1Lsh2YqKpxYBewJ8kk8CK9f+AB7gC2Jflb4PvAg1V1DmDYMae5N0nSFZgyEACqaj+wf2Ds4b7l88C9Q/bbA+zpekxJ0tzxl8qSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElS0ykQkqxPcjzJZJJtQ7YvSvJE234oyYo2fleSI0mebs939u3zx+2YR9vjLdPVlCTpyo1MVZBkAfAocBdwGjicZLyqnu0rewB4qapWJdkE7AA+CJwDfrGqvpXkVuAAsLRvv/uramKaepEkXYMunxDWApNVdaKqLgB7gQ0DNRuA3W15H7AuSarqq1X1rTZ+DHhDkkXTMXFJ0vTqEghLgVN966f5wb/yf6Cmqi4CLwNLBmp+CfhKVb3aN/apdrroo0ky7MWTbEkykWTi7NmzHaYrSboas3JROckt9E4j/au+4fur6h3AT7fHh4btW1U7q2qsqsZGR0dnfrKSdJ3qEghngOV968va2NCaJCPADcALbX0Z8BTw4ar6+qUdqupMe/5r4HF6p6YkSXOkSyAcBlYnWZlkIbAJGB+oGQc2t+WNwMGqqiQ3Ap8BtlXVn14qTjKS5M1t+XXAe4Fnrq0VSdK1mDIQ2jWBrfS+IfQc8GRVHUuyPcn7WtkuYEmSSeDXgUtfTd0KrAIeHvh66SLgQJI/A47S+4TxO9PZmCTpykz5tVOAqtoP7B8Ye7hv+Txw75D9PgZ87DKHvb37NCVJM81fKkuSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJElNp0BIsj7J8SSTSbYN2b4oyRNt+6EkK9r4XUmOJHm6Pd/Zt8/tbXwyyW8myXQ1JUm6clMGQpIFwKPAPcAa4L4kawbKHgBeqqpVwCPAjjZ+DvjFqnoHsBnY07fPJ4BfAVa3x/pr6EOSdI26fEJYC0xW1YmqugDsBTYM1GwAdrflfcC6JKmqr1bVt9r4MeAN7dPETcCbqupLVVXA7wHvv+ZuJElXrUsgLAVO9a2fbmNDa6rqIvAysGSg5peAr1TVq63+9BTHlCTNopHZeJEkt9A7jXT3Vey7BdgC8La3vW2aZyZJuqTLJ4QzwPK+9WVtbGhNkhHgBuCFtr4MeAr4cFV9va9+2RTHBKCqdlbVWFWNjY6OdpiuJOlqdAmEw8DqJCuTLAQ2AeMDNeP0LhoDbAQOVlUluRH4DLCtqv70UnFVfRv4TpL3tG8XfRj49DX2Ikm6BlMGQrsmsBU4ADwHPFlVx5JsT/K+VrYLWJJkEvh14NJXU7cCq4CHkxxtj7e0bQ8CnwQmga8Dn52upiRJV67TNYSq2g/sHxh7uG/5PHDvkP0+BnzsMsecAG69kslKkmaOv1SWJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSmk6BkGR9kuNJJpNsG7J9UZIn2vZDSVa08SVJvpjklSS/NbDPH7djHm2Pt0xHQ5KkqzMyVUGSBcCjwF3AaeBwkvGqerav7AHgpapalWQTsAP4IHAe+Chwa3sMur+qJq6xB0nSNOjyCWEtMFlVJ6rqArAX2DBQswHY3Zb3AeuSpKq+W1V/Qi8YJEmvYV0CYSlwqm/9dBsbWlNVF4GXgSUdjv2pdrroo0nSoV6SNEPm8qLy/VX1DuCn2+NDw4qSbEkykWTi7NmzszpBSbqedAmEM8DyvvVlbWxoTZIR4AbghR920Ko6057/Gnic3qmpYXU7q2qsqsZGR0c7TFeSdDW6BMJhYHWSlUkWApuA8YGacWBzW94IHKyqutwBk4wkeXNbfh3wXuCZK528JGn6TPkto6q6mGQrcABYADxWVceSbAcmqmoc2AXsSTIJvEgvNABIchJ4E7AwyfuBu4FvAgdaGCwA/hD4nWntTJJ0RaYMBICq2g/sHxh7uG/5PHDvZfZdcZnD3t5tipKk2eAvlSVJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAR0DIcn6JMeTTCbZNmT7oiRPtO2Hkqxo40uSfDHJK0l+a2Cf25M83fb5zSSZjoYkSVdnykBIsgB4FLgHWAPcl2TNQNkDwEtVtQp4BNjRxs8DHwV+Y8ihPwH8CrC6PdZfTQOSpOnR5RPCWmCyqk5U1QVgL7BhoGYDsLst7wPWJUlVfbeq/oReMPydJDcBb6qqL1VVAb8HvP9aGpEkXZsugbAUONW3frqNDa2pqovAy8CSKY55eopjApBkS5KJJBNnz57tMF1J0tV4zV9UrqqdVTVWVWOjo6NzPR1Jmre6BMIZYHnf+rI2NrQmyQhwA/DCFMdcNsUxJUmzqEsgHAZWJ1mZZCGwCRgfqBkHNrfljcDBdm1gqKr6NvCdJO9p3y76MPDpK569JGnajExVUFUXk2wFDgALgMeq6liS7cBEVY0Du4A9SSaBF+mFBgBJTgJvAhYmeT9wd1U9CzwI/C7wBuCz7SFJmiNTBgJAVe0H9g+MPdy3fB649zL7rrjM+ARwa9eJSpJm1mv+orIkaXYYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAjoGQpL1SY4nmUyybcj2RUmeaNsPJVnRt+0jbfx4kp/vGz+Z5OkkR5NMTEczkqSrNzJVQZIFwKPAXcBp4HCS8ap6tq/sAeClqlqVZBOwA/hgkjXAJuAW4MeAP0zyj6vqe22/n6uqc9PYjyTpKnX5hLAWmKyqE1V1AdgLbBio2QDsbsv7gHVJ0sb3VtWrVfUNYLIdT5L0GtMlEJYCp/rWT7exoTVVdRF4GVgyxb4FfD7JkSRbLvfiSbYkmUgycfbs2Q7TlSRdjbm8qHxHVb0LuAd4KMnPDCuqqp1VNVZVY6Ojo7M7Q0m6jnQJhDPA8r71ZW1saE2SEeAG4IUftm9VXXp+HngKTyVJ0pzqEgiHgdVJViZZSO8i8fhAzTiwuS1vBA5WVbXxTe1bSCuB1cCXkyxO8kaAJIuBu4Fnrr0dSdLVmvJbRlV1MclW4ACwAHisqo4l2Q5MVNU4sAvYk2QSeJFeaNDqngSeBS4CD1XV95K8FXiqd92ZEeDxqvrcDPQnSepoykAAqKr9wP6BsYf7ls8D915m348DHx8YOwG880onK0maOf5SWZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWo6BUKS9UmOJ5lMsm3I9kVJnmjbDyVZ0bftI238eJKf73pMSdLsmjIQkiwAHgXuAdYA9yVZM1D2APBSVa0CHgF2tH3XAJuAW4D1wH9NsqDjMSVJs6jLJ4S1wGRVnaiqC8BeYMNAzQZgd1veB6xLkja+t6perapvAJPteF2OKUmaRSMdapYCp/rWTwPvvlxNVV1M8jKwpI1/aWDfpW15qmMCkGQLsKWtvpLkeIc5D/Nm4NxV7nvVsmO2X/EH2PMssedZNSf9zqXsuOae396lqEsgzKmq2gnsvNbjJJmoqrFpmNLfG/Z8fbjeer7e+oXZ67nLKaMzwPK+9WVtbGhNkhHgBuCFH7Jvl2NKkmZRl0A4DKxOsjLJQnoXiccHasaBzW15I3CwqqqNb2rfQloJrAa+3PGYkqRZNOUpo3ZNYCtwAFgAPFZVx5JsByaqahzYBexJMgm8SO8feFrdk8CzwEXgoar6HsCwY05/ez/gmk87/T1kz9eH663n661fmKWe0/tDXpJ0vfOXypIkwECQJDXzMhCSPJbk+STP9I39aJIvJPm/7fkfzeUcp1OS5Um+mOTZJMeS/Fobn889vz7Jl5N8rfX8H9r4ynb7lMl2O5WFcz3X6dZ+7f/VJH/Q1ud1z0lOJnk6ydEkE21s3r63AZLcmGRfkj9P8lySn5qNnudlIAC/S+9WGf22AX9UVauBP2rr88VF4N9U1RrgPcBD7VYg87nnV4E7q+qdwG3A+iTvoXfblEfabVReondblfnm14Dn+tavh55/rqpu6/su/nx+bwP8F+BzVXUz8E56/3/PfM9VNS8fwArgmb7148BNbfkm4Phcz3EGe/80cNf10jPwI8BX6P3a/Rww0sZ/Cjgw1/Ob5l6XtX8M7gT+AMh10PNJ4M0DY/P2vU3vd1zfoH3pZzZ7nq+fEIZ5a1V9uy3/BfDWuZzMTGl3mv1J4BDzvOd26uQo8DzwBeDrwF9V1cVW0n+rlPniPwP/Fvh+W1/C/O+5gM8nOdJuZQPz+729EjgLfKqdGvxkksXMQs/XUyD8nepF7Lz7vm2Sfwj8PvCvq+o7/dvmY89V9b2quo3eX81rgZvneEozKsl7geer6shcz2WW3VFV76J3d+SHkvxM/8Z5+N4eAd4FfKKqfhL4LgOnh2aq5+spEP4yyU0A7fn5OZ7PtEryOnph8N+q6n+04Xnd8yVV9VfAF+mdLrmx3T4F5t8tUf458L4kJ+ndIfhOeuea53PPVNWZ9vw88BS98J/P7+3TwOmqOtTW99ELiBnv+XoKhP7ba2ymd559Xmi3Gt8FPFdV/6lv03zueTTJjW35DfSumTxHLxg2trJ51XNVfaSqllXVCnp3AzhYVfczj3tOsjjJGy8tA3cDzzCP39tV9RfAqST/pA2to3e3hxnveV7+UjnJfwd+lt5tcv8S+PfA/wSeBN4GfBP4F1X14lzNcToluQP438DT/P9zy/+O3nWE+drzT9D7b3AsoPeHzZNVtT3Jj9P76/lHga8C/7KqXp27mc6MJD8L/EZVvXc+99x6e6qtjgCPV9XHkyxhnr63AZLcBnwSWAicAH6Z9j5nBnuel4EgSbpy19MpI0nSD2EgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJzf8D26B8SdVq6WAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist([10,20,30,40,50,60],density=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "210/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30+40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = n!/(n-r)!\n",
    "ncr = n!/(n-r)!r!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Algorithms:-\n",
    "\n",
    "01. Linear regression -> regression  \n",
    "02. Logistic regression -> Classification  \n",
    "03. SVM -> Classification  \n",
    "04. K-means -> clustering  \n",
    "05. KNN  -> clustering  \n",
    "06. Hierarchy clustering -> clustering  \n",
    "07. LDA -> topic modeling  \n",
    "08. TF-IDF -> topic modeling  \n",
    "09. Eclat -> associative learning  \n",
    "10. Apriori -> associative learning  \n",
    "11. Random forest -> Ensemble method  \n",
    "12. AdaBoost -> Ensemble method  \n",
    "13. Decision tree -> Classification and regression  \n",
    "14. Naive Baye's -> Classification  and regression \n",
    "15. PCA -> Dimensionality reduction \n",
    "\n",
    "Neural Network:-\n",
    "\n",
    "1. perceptron\n",
    "2. sigmoid\n",
    "3. multi layer preceptron\n",
    "4. Backpropagation\n",
    "        4.a gradient descent\n",
    "        4.b stochostic gradient descent\n",
    "5. Vanila neural network\n",
    "\n",
    "Deep Learning:-\n",
    "1. Optimization of Neural network\n",
    "2. Terminology in DL\n",
    "3. CNN\n",
    "4. RNN\n",
    "5. LSTM\n",
    "6. GRU\n",
    "7. Bi-LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1 -> Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./Advertising.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TV  radio  newspaper\n",
       "sales                      \n",
       "1.6     1      1          1\n",
       "3.2     1      1          1\n",
       "4.8     1      1          1\n",
       "5.3     2      2          2\n",
       "5.5     1      1          1\n",
       "5.6     1      1          1\n",
       "5.7     1      1          1\n",
       "5.9     1      1          1\n",
       "6.6     2      2          2\n",
       "6.7     1      1          1\n",
       "6.9     1      1          1\n",
       "7.0     1      1          1\n",
       "7.2     2      2          2\n",
       "7.3     2      2          2\n",
       "7.6     2      2          2\n",
       "8.0     1      1          1\n",
       "8.1     1      1          1\n",
       "8.4     1      1          1\n",
       "8.5     1      1          1\n",
       "8.6     1      1          1\n",
       "8.7     3      3          3\n",
       "8.8     2      2          2\n",
       "9.2     1      1          1\n",
       "9.3     2      2          2\n",
       "9.4     1      1          1\n",
       "9.5     3      3          3\n",
       "9.6     2      2          2\n",
       "9.7     5      5          5\n",
       "9.9     1      1          1\n",
       "10.1    3      3          3\n",
       "...    ..    ...        ...\n",
       "19.0    2      2          2\n",
       "19.2    2      2          2\n",
       "19.4    1      1          1\n",
       "19.6    2      2          2\n",
       "19.7    1      1          1\n",
       "19.8    1      1          1\n",
       "20.1    1      1          1\n",
       "20.2    2      2          2\n",
       "20.7    3      3          3\n",
       "20.8    1      1          1\n",
       "21.2    1      1          1\n",
       "21.4    1      1          1\n",
       "21.5    1      1          1\n",
       "21.7    1      1          1\n",
       "21.8    1      1          1\n",
       "22.1    1      1          1\n",
       "22.2    1      1          1\n",
       "22.3    1      1          1\n",
       "22.4    1      1          1\n",
       "22.6    2      2          2\n",
       "23.2    1      1          1\n",
       "23.7    1      1          1\n",
       "23.8    2      2          2\n",
       "24.2    1      1          1\n",
       "24.4    1      1          1\n",
       "24.7    1      1          1\n",
       "25.4    3      3          3\n",
       "25.5    1      1          1\n",
       "26.2    1      1          1\n",
       "27.0    1      1          1\n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(\"sales\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2 -> split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.loc[:,\"TV\":\"newspaper\"]\n",
    "y = dataset.sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper\n",
       "1  230.1   37.8       69.2\n",
       "2   44.5   39.3       45.1\n",
       "3   17.2   45.9       69.3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4)\n",
      "(160, 3)\n",
      "(40, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>248.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>241.7</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>78.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>204.1</td>\n",
       "      <td>32.9</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper\n",
       "177  248.4   30.2       20.3\n",
       "112  241.7   38.0       23.2\n",
       "115   78.2   46.8       34.5\n",
       "15   204.1   32.9       46.0\n",
       "107   25.0   11.0       29.7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3 define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-5 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-6 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.350739058732136"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-7 Real time testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr = [[0,200,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.04284019])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.452108386353974"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo+(beta[0]*75)+(beta[1]*75)+(beta[2]*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"DutchModel.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(model,open(modelName,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedModel = pk.load(open(modelName,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.04284019])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedModel.predict([[0,200,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from nltk.corpus import stopwords\n",
    "import string,re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1 -> Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./labeledTrainData.tsv\",sep=\"\\t\",quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "special = list(string.punctuation)\n",
    "special.extend(list(map(str,(np.arange(0,10)))))\n",
    "def cleaning(review):\n",
    "    tagFree = BeautifulSoup(review,\"html.parser\") #removing html tags\n",
    "    onlyText = [char.lower() for char in tagFree.get_text() if not char in special]  # removing numbers and others except small and capital alphabets\n",
    "    words = \"\".join(onlyText).split() #spiliting sentences into words\n",
    "    useful = [w for w in words if not w in stop]  #removing stopping words\n",
    "    return ' '.join(useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(map(cleaning,dataset.review))\n",
    "y = dataset.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2 -> Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(dataset.review,y,test_size=0.3,random_state=21)\n",
    "#X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)\n",
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 -> model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer(min_df=5,ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vetorised=vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17500x116092 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4722670 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vetorised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_vetorised,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8892\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_test,Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.89      0.89      3770\n",
      "          1       0.89      0.89      0.89      3730\n",
      "\n",
      "avg / total       0.89      0.89      0.89      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./train.csv\")\n",
    "dataset = dataset.iloc[:70] #to skip setosa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            class  petal_length  petal_width  sepal_length  sepal_width\n",
       "0  Iris-virginica           5.5          1.8           6.4          3.1\n",
       "1  Iris-virginica           5.9          2.3           6.8          3.2\n",
       "2  Iris-virginica           5.4          2.3           6.2          3.4\n",
       "3  Iris-virginica           4.8          1.8           6.0          3.0\n",
       "4  Iris-virginica           5.1          2.3           6.9          3.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 petal_length  petal_width  sepal_length  sepal_width\n",
       "class                                                                \n",
       "Iris-versicolor            35           35            35           35\n",
       "Iris-virginica             35           35            35           35"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(\"class\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separating input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.loc[:,\"petal_length\":\"sepal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=chi2,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = selector.fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.94913717, 5.08854701, 1.04988537, 0.16269404])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(selected_features,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=10,kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Iris-versicolor       0.90      1.00      0.95         9\n",
      " Iris-virginica       1.00      0.80      0.89         5\n",
      "\n",
      "    avg / total       0.94      0.93      0.93        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_pred,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy check for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1,X_test1,Y_train1,Y_test1 = train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "model.fit(X_train1,Y_train1)\n",
    "Y_pred1 = model.predict(X_test1)\n",
    "accuracy_score(Y_test1,Y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':[0.01,0.1,1,10,100,1000],'kernel':[\"rbf\",'linear','sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model,param_grid=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['rbf', 'linear', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['rbf', 'linear', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9464285714285714"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.55357, std: 0.00262, params: {'C': 0.01, 'kernel': 'rbf'},\n",
       " mean: 0.55357, std: 0.00262, params: {'C': 0.01, 'kernel': 'linear'},\n",
       " mean: 0.55357, std: 0.00262, params: {'C': 0.01, 'kernel': 'sigmoid'},\n",
       " mean: 0.83929, std: 0.08119, params: {'C': 0.1, 'kernel': 'rbf'},\n",
       " mean: 0.89286, std: 0.00524, params: {'C': 0.1, 'kernel': 'linear'},\n",
       " mean: 0.55357, std: 0.00262, params: {'C': 0.1, 'kernel': 'sigmoid'},\n",
       " mean: 0.92857, std: 0.02095, params: {'C': 1, 'kernel': 'rbf'},\n",
       " mean: 0.94643, std: 0.04091, params: {'C': 1, 'kernel': 'linear'},\n",
       " mean: 0.55357, std: 0.00262, params: {'C': 1, 'kernel': 'sigmoid'},\n",
       " mean: 0.87500, std: 0.05500, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: 0.89286, std: 0.04765, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: 0.55357, std: 0.00262, params: {'C': 10, 'kernel': 'sigmoid'},\n",
       " mean: 0.89286, std: 0.04765, params: {'C': 100, 'kernel': 'rbf'},\n",
       " mean: 0.91071, std: 0.06929, params: {'C': 100, 'kernel': 'linear'},\n",
       " mean: 0.55357, std: 0.00262, params: {'C': 100, 'kernel': 'sigmoid'},\n",
       " mean: 0.89286, std: 0.04765, params: {'C': 1000, 'kernel': 'rbf'},\n",
       " mean: 0.91071, std: 0.06929, params: {'C': 1000, 'kernel': 'linear'},\n",
       " mean: 0.55357, std: 0.00262, params: {'C': 1000, 'kernel': 'sigmoid'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "5     57    1   0       140   192    0        1      148      0      0.4   \n",
       "6     56    0   1       140   294    0        0      153      0      1.3   \n",
       "7     44    1   1       120   263    0        1      173      0      0.0   \n",
       "8     52    1   2       172   199    1        1      162      0      0.5   \n",
       "9     57    1   2       150   168    0        1      174      0      1.6   \n",
       "10    54    1   0       140   239    0        1      160      0      1.2   \n",
       "11    48    0   2       130   275    0        1      139      0      0.2   \n",
       "12    49    1   1       130   266    0        1      171      0      0.6   \n",
       "13    64    1   3       110   211    0        0      144      1      1.8   \n",
       "14    58    0   3       150   283    1        0      162      0      1.0   \n",
       "15    50    0   2       120   219    0        1      158      0      1.6   \n",
       "16    58    0   2       120   340    0        1      172      0      0.0   \n",
       "17    66    0   3       150   226    0        1      114      0      2.6   \n",
       "18    43    1   0       150   247    0        1      171      0      1.5   \n",
       "19    69    0   3       140   239    0        1      151      0      1.8   \n",
       "20    59    1   0       135   234    0        1      161      0      0.5   \n",
       "21    44    1   2       130   233    0        1      179      1      0.4   \n",
       "22    42    1   0       140   226    0        1      178      0      0.0   \n",
       "23    61    1   2       150   243    1        1      137      1      1.0   \n",
       "24    40    1   3       140   199    0        1      178      1      1.4   \n",
       "25    71    0   1       160   302    0        1      162      0      0.4   \n",
       "26    59    1   2       150   212    1        1      157      0      1.6   \n",
       "27    51    1   2       110   175    0        1      123      0      0.6   \n",
       "28    65    0   2       140   417    1        0      157      0      0.8   \n",
       "29    53    1   2       130   197    1        0      152      0      1.2   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "273   58    1   0       100   234    0        1      156      0      0.1   \n",
       "274   47    1   0       110   275    0        0      118      1      1.0   \n",
       "275   52    1   0       125   212    0        1      168      0      1.0   \n",
       "276   58    1   0       146   218    0        1      105      0      2.0   \n",
       "277   57    1   1       124   261    0        1      141      0      0.3   \n",
       "278   58    0   1       136   319    1        0      152      0      0.0   \n",
       "279   61    1   0       138   166    0        0      125      1      3.6   \n",
       "280   42    1   0       136   315    0        1      125      1      1.8   \n",
       "281   52    1   0       128   204    1        1      156      1      1.0   \n",
       "282   59    1   2       126   218    1        1      134      0      2.2   \n",
       "283   40    1   0       152   223    0        1      181      0      0.0   \n",
       "284   61    1   0       140   207    0        0      138      1      1.9   \n",
       "285   46    1   0       140   311    0        1      120      1      1.8   \n",
       "286   59    1   3       134   204    0        1      162      0      0.8   \n",
       "287   57    1   1       154   232    0        0      164      0      0.0   \n",
       "288   57    1   0       110   335    0        1      143      1      3.0   \n",
       "289   55    0   0       128   205    0        2      130      1      2.0   \n",
       "290   61    1   0       148   203    0        1      161      0      0.0   \n",
       "291   58    1   0       114   318    0        2      140      0      4.4   \n",
       "292   58    0   0       170   225    1        0      146      1      2.8   \n",
       "293   67    1   2       152   212    0        0      150      0      0.8   \n",
       "294   44    1   0       120   169    0        1      144      1      2.8   \n",
       "295   63    1   0       140   187    0        0      144      1      4.0   \n",
       "296   63    0   0       124   197    0        1      136      1      0.0   \n",
       "297   59    1   0       164   176    1        0       90      0      1.0   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "5        1   0     1       1  \n",
       "6        1   0     2       1  \n",
       "7        2   0     3       1  \n",
       "8        2   0     3       1  \n",
       "9        2   0     2       1  \n",
       "10       2   0     2       1  \n",
       "11       2   0     2       1  \n",
       "12       2   0     2       1  \n",
       "13       1   0     2       1  \n",
       "14       2   0     2       1  \n",
       "15       1   0     2       1  \n",
       "16       2   0     2       1  \n",
       "17       0   0     2       1  \n",
       "18       2   0     2       1  \n",
       "19       2   2     2       1  \n",
       "20       1   0     3       1  \n",
       "21       2   0     2       1  \n",
       "22       2   0     2       1  \n",
       "23       1   0     2       1  \n",
       "24       2   0     3       1  \n",
       "25       2   2     2       1  \n",
       "26       2   0     2       1  \n",
       "27       2   0     2       1  \n",
       "28       2   1     2       1  \n",
       "29       0   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "273      2   1     3       0  \n",
       "274      1   1     2       0  \n",
       "275      2   2     3       0  \n",
       "276      1   1     3       0  \n",
       "277      2   0     3       0  \n",
       "278      2   2     2       0  \n",
       "279      1   1     2       0  \n",
       "280      1   0     1       0  \n",
       "281      1   0     0       0  \n",
       "282      1   1     1       0  \n",
       "283      2   0     3       0  \n",
       "284      2   1     3       0  \n",
       "285      1   2     3       0  \n",
       "286      2   2     2       0  \n",
       "287      2   1     2       0  \n",
       "288      1   1     3       0  \n",
       "289      1   1     3       0  \n",
       "290      2   1     3       0  \n",
       "291      0   3     1       0  \n",
       "292      1   2     1       0  \n",
       "293      1   0     3       0  \n",
       "294      0   0     1       0  \n",
       "295      2   2     3       0  \n",
       "296      1   0     2       0  \n",
       "297      1   2     1       0  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./heart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisData = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class  petal_length  petal_width  sepal_length  sepal_width\n",
       "101  Iris-setosa           1.7          0.3           5.7          3.8\n",
       "102  Iris-setosa           1.3          0.4           5.4          3.9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisData[101:103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica =[[5.5,1.8,6.4,3.1],[5.9,2.3,6.8,3.2]]\n",
    "versicolor =[[4.0,1.3,6.1,2.8],[3.6,1.3,5.6,2.9]]\n",
    "setaso = [[1.7,0.3,5.7,3.8],[1.3,0.4,5.4,3.9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import*\n",
    " \n",
    "def euclidean_distance(x,y):\n",
    " \n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519615242270663"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(setaso[0],setaso[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3302360395462087"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(setaso[0],versicolor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.130727575266252"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(virginica[0],versicolor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648074069840786"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(versicolor[0],versicolor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 petal_length  petal_width  sepal_length  sepal_width\n",
       "class                                                                \n",
       "Iris-setosa                35           35            35           35\n",
       "Iris-versicolor            35           35            35           35\n",
       "Iris-virginica             35           35            35           35"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisData.groupby('class').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step - 1 data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisData = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separating input from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = irisData.loc[:,\"petal_length\":\"sepal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of cluster identification (elbow method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = []\n",
    "K = []\n",
    "for k in range(1,106):\n",
    "    modelKM = KMeans(n_clusters=k)\n",
    "    modelKM.fit(X)\n",
    "    score.append(modelKM.inertia_)\n",
    "    K.append(k)\n",
    "\n",
    "plt.plot(K,score,\"bx-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.29736842, 1.39210526, 5.8       , 2.71842105],\n",
       "       [1.47714286, 0.24571429, 5.02857143, 3.46571429],\n",
       "       [5.58125   , 2.003125  , 6.74375   , 3.0125    ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import  Counter\n",
    "labels = Counter(model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 32, 0: 38, 1: 35})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16666667  1.46666667]\n",
      " [ 6.5         8.        ]\n",
      " [ 9.         11.        ]]\n",
      "[0 1 0 1 0 2]\n",
      "coordinate: [1. 2.] label: 0\n",
      "coordinate: [5. 8.] label: 1\n",
      "coordinate: [1.5 1.8] label: 0\n",
      "coordinate: [8. 8.] label: 1\n",
      "coordinate: [1.  0.6] label: 0\n",
      "coordinate: [ 9. 11.] label: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEZZJREFUeJzt3W9s3Hd9wPH3J44jGocNRl0aUliCQqsiNOzMIoVs1UQpxcUDNO0BSEWsXdVNQqywSQiQKjTlAZuEEHsypKpNadUCYm3RpgiTIv6OaPV0iV21NFAMCaUhJUZsgE0nO/ZnD+7cOm4d23dn/+6+fb+kKPb5fPdRrn37d9/f986RmUiSut+WqgeQJLWHQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSrE1s28s4svvjh37969mXcpSV3v2LFjv8zM/tWut6lB3717N7VabTPvUpK6XkT8dC3Xc8lFkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CVpnWbPLbDWX9+ZmcyeW9jgieoMuiStw+y5BW6+p8bBwydWjXpmcvDwCW6+p7YpUTfokrQOvT3B3v4dHDp68oJRX4z5oaMn2du/g96e2PDZNvWl/5LU7SKC20auBODQ0ZMA3DZyJRHPBXtpzG86sOd5X98oBl2S1ml51JNk31WXMDEzw0BfH8cfPstdR09taszBoEtSUxajniR3HT3Fv54+zdQVvfT/cI6LTs1x44HdmxpzcA1dkpoWEey76hKe2d3LRafmeM2R33HRqTme2d3Lvqsu2dSYg0GXpJZMzMwwdUXveZdNXdHLIzMzmz6LQZekFgz09dH/w7nzLuv/4Rxv7Ovb9FkMuiQ1KTM5/vDZZ5dZnrxu+7PLL8cfPrvmFx+1iydFJakJi1sT7zp6ihsP7GbfVZfwyMwMb3zDc7tcgnCXiyR1spX2mf95f/3Xfo6MXEwQK+5T3ygGXZLWYS0vGlrLi482gkGXpHWYm08mp6ZXfdHQ0qhPTk0zN59s27qxQY/NXLQfGhrKWq22afcnSRth9twCvT2xpiPuzGzEvPk9KBFxLDOHVrueR+iStE7riXNEbPiR+SK3LUpSIQy6JBXCoEtSIQy6JBXCoEtSIQy6JBVi1aBHxKGIOBsRjy257A8i4usR8aPG3y/f2DElSatZyxH654F3LLvsY8A3MvN1wDcan0uSKrRq0DPzu8Cvll38buDuxsd3A+9p81ySpHVqdg39lZl5pvHx08Ar2zSPJKlJLZ8Uzfqbwaz4hjARcUtE1CKiNjU11erdSZJW0GzQfxEROwEaf59d6YqZeXtmDmXmUH/jvYIlSe3XbND/A/hA4+MPAP/ennEkSc1ay7bFLwL/BVwREU9FxF8D/wRcGxE/At7W+FySVKFV3z43M9+3wpeuafMskqQW+EpRSSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0qcvNnlsgM9d03cxk9tzCBk+kqhh0qYvNnlvg5ntqHDx8YtWoZyYHD5/g5ntqRr1QBl3qYr09wd7+HRw6evKCUV+M+aGjJ9nbv4PentjkSbUZtlY9gKTmRQS3jVwJwKGjJwG4beRKIp4L9tKY33Rgz/O+rnK0FPSI+AhwM5DAo8CNmfl/7RhM2jDz8zA6CuPjMDgIw8PQ01P1VE27UNSLjHlhj187NR30iNgF/B3w+sx8JiK+DLwX+HybZpPab34errsOxsZgZgb6+mD/fjhypKujsFLUi4x5gY9fu7S65LIVuCgi5oDtwM9bH0naQKOj9RhMT9c/n56ufz46CiMj1c7WouVRXwx7MTGHoh+/dmj6pGhmngY+DTwJnAF+nZkPLb9eRNwSEbWIqE1NTTU/qdQO4+P1I7ulZmZgYqKaedpsadQXFRNzKP7xa1XTQY+IlwPvBvYArwL6IuKG5dfLzNszcygzh/r7+5ufVGqHwcH60/Sl+vpgYKCaedpscc18qbVsaewahT9+rWpl2+LbgJOZOZWZc8CDwFvaM5a0QYaH62uuO3ZARP3v/fvrl3e55SdAT37qem46sGfVLY1dpeDHrx1aWUN/ErgqIrYDzwDXALW2TCVtlJ6e+gm00dH60/SBgSJ2Say0m2W1LY1dp9DHr12aDnpmjkXE/cBx4BwwDtzersGkDdPTUz+BVshJtAttTSw26gU9fu3U0i6XzPwk8Mk2zSJpndayz7zIqOsF+UpRqYvNzSeTU9Orbk1cGvXJqWnm5pNtWw16aWIzT5QMDQ1lreYyu9ROs+cW6O2JNR1xZ2Yj5r6NUzeJiGOZObTa9TxCl7rceuIcER6ZF8wf05JUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUiJaCHhEvi4j7I+IHEXEiIt7crsEkSeuztcXv/xfga5n5lxGxDdjehpkkSU1oOugR8fvA1cBfAWTmLDDbnrEkSevVypLLHmAKuCsixiPijojoW36liLglImoRUZuammrh7iRJF9JK0LcC+4DPZeYgMAN8bPmVMvP2zBzKzKH+/v4W7k6SdCGtBP0p4KnMHGt8fj/1wEuSKtB00DPzaeBnEXFF46JrgMfbMpUkad1a3eXyIeC+xg6XnwA3tj6SJKkZLQU9MyeAoTbNIklqga8UlaRCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKoRBl6RCGHRJKkTLQY+InogYj4jD7RhIktScdhyh3wqcaMPtSJJa0FLQI+Iy4J3AHe0ZR5LUrFaP0D8LfBRYWOkKEXFLRNQiojY1NdXi3UmSVtJ00CNiBDibmccudL3MvD0zhzJzqL+/v9m7kyStopUj9APAuyLiFPAl4K0RcW9bppIkrVvTQc/Mj2fmZZm5G3gv8M3MvKFtk0mS1sV96JJUiK3tuJHM/Dbw7XbcliSpOR6hS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1Ihmg56RLw6Ir4VEY9HxPcj4tZ2DiZJWp+tLXzvOeAfMvN4RLwUOBYRX8/Mx9s0GwDzC/OMTo4yfmacwZ2DDO8dpmdLTzvvQpKK0HTQM/MMcKbx8W8j4gSwC2hb0OcX5rnu3usYOz3GzOwMfdv62L9rP0duOGLUJWmZtqyhR8RuYBAYa8ftLRqdHGXs9BjTs9MkyfTsNGOnxxidHG3n3UhSEVoOekTsAB4APpyZv3mBr98SEbWIqE1NTa3rtsfPjDMzO3PeZTOzM0w8PdHKyJJUpJaCHhG91GN+X2Y++ELXyczbM3MoM4f6+/vXdfuDOwfp29Z33mV92/oYuHSgqXnnF+Y5/MRhDn7nIIefOMz8wnxTtyNJnajpNfSICOBO4ERmfqZ9Iz1neO8w+3ftf94a+vDe4XXfluvxkkrXyi6XA8D7gUcjYnEN5BOZ+dXWx6rr2dLDkRuOMDo5yrGfP8K+nW/k+tetvsslM5mbT7Ztfe4JyNL1eOC89fiRy0faNbIkVabpJZfM/F5mRmb+UWYONP60LeaLerb08PbXXs+Pf3It40+8li1x4ZEzk4OHT3DzPTVmzy08e7nr8ZJK1xWvFO3tCfb27+DQ0ZMcPHyCzHzB6y3G/NDRk+zt30FvTzz7tXavx0tSp2llyWXTRAS3jVwJwKGjJwG4beRK6sv4dUtjftOBPc/7ejvX4yWpE3VF0OHCUV8t5nD+evzE0xMMXDrgq04lFaVrgg4rR321mC/q2dLDyOUjngSVVKSuCjo8P+qLYV8t5pJUuq44Kbrc0qgvMuaSXuy6MuiLa+ZLXWj3iyS9GHRd0JefAD35qeu56cCeVbc0SlLpumoNfaXdLKttaZSkF4OuCfqFtiYadUnqkqCvZZ+5UZf0YtcVQZ+bTyanplfdmrg06pNT04036DLokl4cYjNPIg4NDWWtVmvqe2fPLdDbE2s64n6hd1uUpG4VEccyc2i163XFETqwrjhHhEfmkl50PISVpEIYdEkqhEGXpEIYdEkqRMefFJ1fmGd0cpTxM+MM7hz0PcwlaQUdHfT5hXmuu/e65/2WoSM3HDHqkrRMRy+5jE6OMnZ6jOnZaZJkenaasdNjjE6OVj2aJHWcjg76+JlxZmZnzrtsZnaGiacnKppIkjpXRwd9cOcgfdv6zrusb1sfA5cOVDSRJHWujg768N5h9u/az45tOwiCHdt2sH/Xfob3Dlc9miR1nI4+KdqzpYcjNxxhdHKUiacnGLh0wF0ukrSCjg461KM+cvkII5ePVD2KJHW0jl5ykSStnUGXpEIYdEkqhEGXpEIYdEkqxKb+CrqImAJ+2uS3Xwz8so3jtEMnzgSdOZczrV0nzuVMa7NRM/1hZvavdqVNDXorIqK2lt+pt5k6cSbozLmcae06cS5nWpuqZ3LJRZIKYdAlqRDdFPTbqx7gBXTiTNCZcznT2nXiXM60NpXO1DVr6JKkC+umI3RJ0gV0fNAj4lBEnI2Ix6qeZVFEvDoivhURj0fE9yPi1g6Y6SUR8d8R8Uhjpn+seqZFEdETEeMRcbjqWRZFxKmIeDQiJiKiVvU8ABHxsoi4PyJ+EBEnIuLNFc9zRePfZ/HPbyLiw1XOtCgiPtL47/yxiPhiRLykA2a6tTHP96v6d+r4JZeIuBqYBu7JzDdUPQ9AROwEdmbm8Yh4KXAMeE9mPl7hTAH0ZeZ0RPQC3wNuzcyHq5ppUUT8PTAE/F5mdsTbZkbEKWAoMztmH3NE3A38Z2beERHbgO2Z+b9VzwX1H8rAaWB/Zjb7WpJ2zbKL+n/fr8/MZyLiy8BXM/PzFc70BuBLwJuAWeBrwN9m5uRmztHxR+iZ+V3gV1XPsVRmnsnM442PfwucAHZVPFNm5nTj097Gn8p/WkfEZcA7gTuqnqWTRcTvA1cDdwJk5mynxLzhGuDHVcd8ia3ARRGxFdgO/Lziea4ExjLzd5l5DvgO8BebPUTHB73TRcRuYBAYq3aSZ5c2JoCzwNczs/KZgM8CHwUWqh5kmQQeiohjEXFL1cMAe4Ap4K7G8tQdEdG32jdtovcCX6x6CIDMPA18GngSOAP8OjMfqnYqHgP+NCJeERHbgeuBV2/2EAa9BRGxA3gA+HBm/qbqeTJzPjMHgMuANzWeBlYmIkaAs5l5rMo5VvAnmbkPGAY+2Fjaq9JWYB/wucwcBGaAj1U7Ul1j+eddwL9VPQtARLwceDf1H4KvAvoi4oYqZ8rME8A/Aw9RX26ZAOY3ew6D3qTGOvUDwH2Z+WDV8yzVeKr+LeAdFY9yAHhXY736S8BbI+LeakeqaxzlkZlnga9QX/us0lPAU0ueVd1PPfCdYBg4npm/qHqQhrcBJzNzKjPngAeBt1Q8E5l5Z2b+cWZeDfwP8MRmz2DQm9A4AXkncCIzP1P1PAAR0R8RL2t8fBFwLfCDKmfKzI9n5mWZuZv6U/ZvZmalR1IAEdHXOJlNY1nj7dSfMlcmM58GfhYRVzQuugao7CT7Mu+jQ5ZbGp4EroqI7Y3/F6+hfh6rUhFxSePv11BfP//CZs/Q8b9TNCK+CPwZcHFEPAV8MjPvrHYqDgDvBx5trFkDfCIzv1rhTDuBuxu7EbYAX87Mjtkm2GFeCXyl3gK2Al/IzK9VOxIAHwLuayxx/AS4seJ5Fn/gXQv8TdWzLMrMsYi4HzgOnAPG6YxXjT4QEa8A5oAPVnFSu+O3LUqS1sYlF0kqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEL8P/MtOAp16/7PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = np.array([[1, 2],\n",
    "              [5, 8],\n",
    "              [1.5, 1.8],\n",
    "              [8, 8],\n",
    "              [1, 0.6],\n",
    "              [9, 11]])\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n",
    "\n",
    "print(centroids)\n",
    "print(labels)\n",
    "\n",
    "colors = [\"g.\",\"r.\",\"c.\",\"y.\"]\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(\"coordinate:\",X[i], \"label:\", labels[i])\n",
    "    plt.plot(X[i][0], X[i][1], colors[labels[i]], markersize = 10)\n",
    "\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=150, linewidths=5, zorder=10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/crawford/20-newsgroups#alt.atheism.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hierarchy clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=np.array([[1,1],[1.1,1.1],[3,3],[4,4],[3,3.5],[3.5,4]])\n",
    "\n",
    "X = np.array([[1, 2],\n",
    "              [5, 8],\n",
    "              [1.5, 1.8],\n",
    "              [8, 8],\n",
    "              [1, 0.6],\n",
    "              [8, 8]])\n",
    "x = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(x[:,0],x[:,1],s=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linkage declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix=linkage(x,\"single\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.        , 5.        , 0.        , 2.        ],\n",
       "       [0.        , 2.        , 0.53851648, 2.        ],\n",
       "       [4.        , 7.        , 1.3       , 3.        ],\n",
       "       [1.        , 6.        , 3.        , 3.        ],\n",
       "       [8.        , 9.        , 7.119691  , 6.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkage_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dend=dendrogram(linkage_matrix,truncate_mode=None)\n",
    "\n",
    "plt.title(\"Hierarchial clustering\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dend=dendrogram(linkage_matrix,truncate_mode='lastp',p=6)\n",
    "\n",
    "plt.title(\"Hierarchial clustering\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/datadriveninvestor/unsupervised-learning-with-python-k-means-and-hierarchical-clustering-f36ceeec919c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Corn</th>\n",
       "      <th>Dill</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Ice cream</th>\n",
       "      <th>Kidney Beans</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Nutmeg</th>\n",
       "      <th>Onion</th>\n",
       "      <th>Unicorn</th>\n",
       "      <th>Yogurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Apple   Corn   Dill   Eggs  Ice cream  Kidney Beans   Milk  Nutmeg  Onion  Unicorn  Yogurt\n",
       "0  False  False  False   True      False          True   True    True   True    False    True\n",
       "1  False  False   True   True      False          True  False    True   True    False    True\n",
       "2   True  False  False   True      False          True   True   False  False    False   False\n",
       "3  False   True  False  False      False          True   True   False  False     True    True\n",
       "4  False   True  False   True       True          True  False   False   True    False   False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding combo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion, Eggs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Yogurt, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion, Eggs, Kidney Beans)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                     itemsets\n",
       "0       0.8                       (Eggs)\n",
       "1       1.0               (Kidney Beans)\n",
       "2       0.6                       (Milk)\n",
       "3       0.6                      (Onion)\n",
       "4       0.6                     (Yogurt)\n",
       "5       0.8         (Eggs, Kidney Beans)\n",
       "6       0.6                (Onion, Eggs)\n",
       "7       0.6         (Milk, Kidney Beans)\n",
       "8       0.6        (Onion, Kidney Beans)\n",
       "9       0.6       (Yogurt, Kidney Beans)\n",
       "10      0.6  (Onion, Eggs, Kidney Beans)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive baye's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook = [\"sunny\",\"sunny\",\"overcast\",\"rainy\",\"rainy\",\"rainy\",\"overcast\",\"sunny\",\"sunny\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 1, 1, 1, 0, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit_transform(outlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['overcast', 'rainy', 'sunny'], dtype='<U8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  wind play\n",
       "0         2            2         1     0   no\n",
       "1         2            2         1     1   no\n",
       "2         1            2         1     0  yes\n",
       "3         0            1         1     0  yes\n",
       "4         0            0         0     0  yes\n",
       "5         0            0         0     1   no\n",
       "6         1            0         0     1  yes\n",
       "7         2            1         1     0   no\n",
       "8         2            0         0     0  yes\n",
       "9         0            1         0     0  yes\n",
       "10        2            1         0     1  yes\n",
       "11        1            1         1     1  yes\n",
       "12        1            2         0     0  yes\n",
       "13        0            1         1     1   no"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separating input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.loc[:,\"outlook\":\"wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outlook  temperature  humidity  wind\n",
       "0        2            2         1     0\n",
       "1        2            2         1     1\n",
       "2        1            2         1     0\n",
       "3        0            1         1     0\n",
       "4        0            0         0     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     no\n",
       "1     no\n",
       "2    yes\n",
       "3    yes\n",
       "4    yes\n",
       "Name: play, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_case = \"SMHT\"\n",
    "testData = [2,1,1,1]\n",
    "model.predict([testData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82612248, 0.17387752]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([testData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype='<U3')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook = [\"sunny\",\"sunny\",\"overcast\",\"rainy\",\"rainy\",\"rainy\",\"overcast\",\"sunny\",\"sunny\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 1, 1, 1, 0, 2, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit_transform(outlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['overcast', 'rainy', 'sunny'], dtype='<U8')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  wind play\n",
       "0         2            2         1     0   no\n",
       "1         2            2         1     1   no\n",
       "2         1            2         1     0  yes\n",
       "3         0            1         1     0  yes\n",
       "4         0            0         0     0  yes\n",
       "5         0            0         0     1   no\n",
       "6         1            0         0     1  yes\n",
       "7         2            1         1     0   no\n",
       "8         2            0         0     0  yes\n",
       "9         0            1         0     0  yes\n",
       "10        2            1         0     1  yes\n",
       "11        1            1         1     1  yes\n",
       "12        1            2         0     0  yes\n",
       "13        0            1         1     1   no"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separating input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.loc[:,\"outlook\":\"wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outlook  temperature  humidity  wind\n",
       "0        2            2         1     0\n",
       "1        2            2         1     1\n",
       "2        1            2         1     0\n",
       "3        0            1         1     0\n",
       "4        0            0         0     0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     no\n",
       "1     no\n",
       "2    yes\n",
       "3    yes\n",
       "4    yes\n",
       "Name: play, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_case = \"SMHT\"\n",
    "testData = [2,1,1,1]\n",
    "model.predict([testData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([testData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p,q):\n",
    "    return (-p*m.log2(p)) + (-q*m.log2(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "play = entropy(9/14,5/14)\n",
    "sunny = entropy(2/5,3/5)\n",
    "rainy = entropy(2/5,3/5)\n",
    "overcast = 0\n",
    "outlook = 5/14*sunny+4/14*overcast+5/14*rainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706309"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunny = entropy(2/5)+entropy(3/5)\n",
    "rainy = entropy(2/5)+entropy(3/5)\n",
    "overcast = entropy(4/4)\n",
    "outlook = 5/14*sunny+4/14*overcast+5/14*rainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935361388961918"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot = entropy(2/5)+entropy(3/5)\n",
    "mild = entropy(2/5)+entropy(3/5)\n",
    "cool = entropy(4/4)\n",
    "outlook = 5/14*hot+4/14*mild+5/14*cool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding multi-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"outlook\"] = [\"sunny\",\"sunny\",\"overcast\",\"rainy\",\"rainy\"]\n",
    "data[\"temperature\"] =[\"hot\",\"hot\",\"hot\",\"mild\",\"cool\"]\n",
    "data[\"humidity\"] = [\"high\",\"high\",\"high\",\"high\",\"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook temperature humidity\n",
       "0     sunny         hot     high\n",
       "1     sunny         hot     high\n",
       "2  overcast         hot     high\n",
       "3     rainy        mild     high\n",
       "4     rainy        cool   normal"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (5, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1dde78e51be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (5, 3)"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit_transform(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {\n",
    "    \"sunny\":2,\n",
    "    \"rainy\":1,\n",
    "    \"overcast\":0,\n",
    "    \"hot\":2,\n",
    "    \"mild\":1,\n",
    "    \"cool\":0,\n",
    "    \"high\":1,\n",
    "    \"normal\":0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(dat,encoder):\n",
    "    for k,v in encoder.items():\n",
    "        dat.replace({k:v},inplace=True)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outlook  temperature  humidity\n",
       "0        2            2         1\n",
       "1        2            2         1\n",
       "2        0            2         1\n",
       "3        1            1         1\n",
       "4        1            0         0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remap(DF[[\"outlook\",'temperature','humidity']],encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from nltk.corpus import stopwords\n",
    "import string,re\n",
    "import numpy\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1 -> Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./labeledTrainData.tsv\",sep=\"\\t\",quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "special = list(string.punctuation)\n",
    "special.extend(list(map(str,(np.arange(0,10)))))\n",
    "def cleaning(review):\n",
    "    tagFree = BeautifulSoup(review,\"html.parser\") #removing html tags\n",
    "    onlyText = [char.lower() for char in tagFree.get_text() if not char in special]  # removing numbers and others except small and capital alphabets\n",
    "    words = \"\".join(onlyText).split() #spiliting sentences into words\n",
    "    useful = [w for w in words if not w in stop]  #removing stopping words\n",
    "    return ' '.join(useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(map(cleaning,dataset.review))\n",
    "y = dataset.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2 -> Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_test,Y_train,Y_test = train_test_split(dataset.review,y,test_size=0.3,random_state=21)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)\n",
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer(min_df=5,ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vetorised=vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17500x62397 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2111245 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vetorised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 -> model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000,criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vetorised,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605333333333334\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_test,Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.86      3770\n",
      "          1       0.85      0.88      0.86      3730\n",
      "\n",
      "avg / total       0.86      0.86      0.86      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entropy'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('criterion',\n",
       " 'max_depth',\n",
       " 'min_samples_split',\n",
       " 'min_samples_leaf',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'max_features',\n",
       " 'max_leaf_nodes',\n",
       " 'min_impurity_decrease',\n",
       " 'min_impurity_split',\n",
       " 'random_state')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1765053490, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1719584655, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=821050558, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=161388568, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=170260902, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1486030472, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=341179132, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1673006008, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=952265002, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1451519957, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2103217628, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=265739136, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=498551339, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1880483730, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1640020150, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1074296197, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1479999529, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=152052715, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1189879698, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1995461430, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=995058849, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=189229737, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2011497514, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=43104233, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1613894231, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=324679468, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1471639379, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1493195609, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=53307255, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=21387489, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=254144329, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1412935249, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1308390694, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=726453858, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=325260096, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1909135045, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=197866727, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=613318304, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=295624600, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2013396908, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1558747798, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1699616323, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=295312597, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=392957490, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=360851347, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=988339678, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=180065081, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1382859876, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1199639723, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1097093196, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=178422706, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1242655465, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1252381943, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=126395776, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=517746114, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1105501614, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1774409820, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1824604019, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=519628150, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=614179443, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=428023285, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1116422291, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1308688126, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1075539467, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=319503823, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=677957050, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1089186772, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=391635370, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1494207958, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2016872271, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1892702006, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1141284839, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=479946336, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1141855140, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=897023009, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=490591205, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1282497269, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1860554208, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=213164782, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=29666749, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=286522729, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=817545853, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=267218388, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1095772603, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1045616294, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1133954830, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=983617878, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1127940792, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=686954206, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=968720503, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1612040867, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=815385562, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=805719487, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=753775768, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1346349604, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=177124246, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1839296503, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=782344146, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1186787807, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2012081510, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=697972954, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1800518630, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=837105477, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=855275289, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=50213847, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1145119662, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=426238486, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=433110867, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1806114696, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1270154785, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=411819863, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=322119352, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=384861638, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1436978342, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1883193481, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=505136984, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=372287297, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1662609824, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1365840733, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=825803623, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1730359421, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=457885137, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=645443591, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=400385941, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=807275096, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1194387098, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1836311456, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=432609344, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1261408703, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=572726230, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=117286477, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=577351225, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=184198838, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1293885604, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=147622082, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1097380806, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1794070189, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1500515947, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=163425951, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1447663710, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=325399540, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=885036770, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1721728710, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1099554033, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1964243474, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=320325809, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1080376834, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=220235884, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=324382667, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=754806763, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1379096612, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2097810354, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=613630704, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1279958762, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=85630461, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1826060481, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=97016708, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=750097607, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1289428967, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=360016021, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=662732902, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=559994427, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=287616822, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=32268146, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=425549194, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1128298624, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1551785823, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1843535091, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=776845971, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1408157736, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1371763269, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1581437308, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1391909387, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1139962325, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=551835147, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=930711950, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=604875238, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=812076078, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=156699793, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1739230962, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2035651542, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1786394161, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=183582027, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2058125273, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1628280947, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=245905815, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1447049417, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1526472955, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=732970136, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1730596682, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1354932190, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=291366743, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1383679627, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2018444453, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=509717271, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=83187485, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1698036952, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=138914322, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=926824093, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1048196597, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1573716892, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=919633902, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1147147283, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=397579663, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=947351749, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=68138762, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1610956160, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1915233018, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=409345010, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2119078150, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=767194084, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1768753350, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=8697051, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=388087698, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=23527861, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2100162051, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1235865342, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=927306444, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=31009538, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1859503540, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=704482150, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1641942512, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1597923704, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=960234193, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=294858749, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1955937726, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1984474250, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1703849080, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=183422019, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=420050916, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2121935332, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=377398350, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1562870524, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2091501987, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2118616651, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1931184304, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=756854011, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=701764768, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1585712365, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=661858494, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=256211354, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=308645461, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=379837383, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=150280014, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1292673394, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=8067427, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1061974277, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1562535726, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1824185397, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1136427318, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1694627773, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1838685857, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1088732019, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2062963721, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1457492197, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1378359308, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=372305351, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1581990949, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=309272499, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1891705909, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1724322893, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=569268268, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=971662392, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1949248591, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=86523365, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1299111140, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2140736602, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=573441771, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1831910795, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=917073689, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1148619492, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=340696794, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1964460251, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=674887790, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=589559073, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1447059895, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=995163325, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1144131551, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=632457395, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=446657430, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=919074196, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1450018682, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1140621723, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2026110415, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1562835715, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1484467842, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=961524961, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2125355205, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=71789749, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1184037475, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1648814321, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1474160865, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=898411273, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=959196720, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=399353724, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=954015777, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1154760601, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=841975374, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1219676901, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1296466895, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1723080817, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=55868893, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=399672895, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2068512400, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=107509691, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=389964515, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2120789264, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1439863502, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1051497673, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1372033519, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1540004999, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1591336663, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1537895431, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1260628113, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1661659166, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1328329775, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=537317947, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1473402945, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1721910329, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=441836905, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=743632897, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=27159425, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=641601168, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1216625872, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2060795289, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1596682092, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1821124558, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1694087561, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2136584468, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=534680863, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=480826339, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1448460434, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=606438809, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1124173910, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1358271007, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=63891547, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1322632166, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=385230942, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=330750617, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=485593596, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=402272474, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=192395466, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1511004606, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1192230946, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=998111371, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=658364574, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=707182184, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=797348284, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=929409436, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=475456715, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2068796329, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1729759028, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1278663202, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1550545207, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2005843056, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1880261510, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1101543467, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=413763816, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=926367479, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1283814601, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=240967706, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=503998588, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1725340323, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=535859743, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=474805871, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1541379529, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=948776232, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1619445313, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1861323623, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=475665232, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=982948719, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=594069997, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=589990016, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=458837893, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=972114533, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1232993402, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=332523824, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=411551508, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1113410666, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=92610101, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=863111805, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=504835279, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1953936102, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2100350144, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=646925448, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=892389259, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1071461973, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=204062045, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=342439592, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2032482716, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=597837402, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=664657775, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=599745474, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=46513099, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1992490465, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=338044537, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=60984251, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2040668332, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1418135233, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=430539926, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=175574185, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1523966767, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1653960836, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=922663599, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2098031135, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1105477954, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=83986519, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=255591708, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=132405767, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1334050978, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1215478911, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=602374740, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1675833921, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=264986193, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=964090069, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1531228795, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=83909975, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=717715389, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1498218449, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1440000624, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=152831201, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=677008412, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=80301466, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1851851145, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=694144073, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=807408112, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=90317890, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1435520866, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=815466630, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=593599096, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=308388155, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1970845209, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=302733078, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=631388651, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=802326991, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1174666948, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1913873001, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1579457017, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1380225312, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1709113584, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=301157971, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=245621083, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1304271412, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=292150765, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=569968864, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=695283377, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1971461193, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=821591938, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1043924860, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1166801031, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=67334225, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=874380953, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1649596542, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1602499753, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2079213906, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1620495856, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=514535674, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=629572604, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=13926296, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2071574163, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1643256372, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1476377380, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=86329115, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=380292627, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1311325862, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=182329827, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1400790058, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=880038978, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=515902979, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=776440555, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1194589413, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1744336695, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1566263918, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=896384476, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1582018428, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1387187094, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=439911075, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=335776278, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1898106219, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=791305917, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=386431750, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1813748488, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1799043869, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1537188549, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1779433056, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1217870393, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=567708056, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1191891106, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=976554877, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1046329515, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=881328281, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=486990085, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2115400099, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1938479030, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=325559918, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1369071109, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1662871358, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1628418485, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1388763575, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1541164402, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=181923079, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=717438729, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1591509108, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=193018710, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1697922021, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=914851577, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=320233628, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1700051468, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1927558876, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=192759101, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=567867600, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=830823853, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2018739693, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1221475305, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1833568308, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=578865837, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=986025027, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1155016872, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=667788427, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=921127628, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=408863864, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=151091081, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1442038351, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=980219343, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1424070227, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=490708528, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=333962346, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1191742769, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=810722602, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=680829195, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1622658643, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1518596120, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1289268532, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1019404980, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=304181273, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1914594709, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2130442204, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1071237886, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1043069042, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1604867633, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=458752110, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1950911378, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=829757665, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=898103687, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1094496902, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1380819671, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=638402975, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=265128476, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=713273915, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=651433716, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1942277104, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=497339772, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1932760733, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1905014811, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=722861833, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1190006209, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1005579690, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1420164588, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=971927977, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1101606481, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=392201839, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=6323494, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1506966320, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=786195565, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1882142651, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=632459403, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1233141940, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1422081213, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1490798997, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1346230188, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=283013677, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1826200700, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2126452095, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2070668574, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=686339597, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1697203311, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=183272516, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1836789493, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1794517869, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1076478485, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1929165770, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=974727825, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=72878321, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=484686304, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1247005092, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1817961716, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=697766887, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=547280805, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1748257059, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1176339863, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1869696586, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=819514024, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=456892073, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=967130068, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=317191685, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1789641512, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=488338641, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=214366864, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1670686279, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=982042648, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=879350579, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1446870545, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=729183012, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1183540162, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=146427804, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=753137870, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=289456077, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1379860119, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=533218913, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1945779041, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1601562509, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=186469342, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1417662410, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=78671140, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1823412826, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1557568636, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2038427172, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=423904669, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=315114015, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=690113050, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1908858605, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=92726887, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1980642840, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1984953407, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1210804166, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1250371968, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1419372325, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1980139490, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=297448939, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=497412348, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=628093536, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=875035153, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=237934531, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=24130951, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2096078299, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1265855304, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1766749266, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2026631602, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=764605130, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1114736695, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1881290940, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1972179446, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1321813396, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=443675442, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1660083596, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=181932829, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1094369508, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1070794943, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1141582453, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=553514056, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1021798372, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=947110805, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1421004229, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=250802406, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1622360013, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=443102550, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=524553760, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1047291380, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=41038656, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1165749376, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=303914757, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=810896216, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1805498684, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=250329032, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1410189563, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1039683359, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=121857507, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=198600035, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=192493014, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1982147033, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1385520612, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1751901409, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=180749078, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1463750891, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=166978742, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=220122394, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1177531103, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=669885849, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=849935391, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=599098712, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1035251396, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=664420139, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1533834212, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1566186949, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1725493818, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=758942356, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1207371766, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=216845493, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=936085753, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1964251689, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=501482303, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2057727558, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1721250714, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1112288615, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=212599943, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=575987717, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=230238855, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1233321918, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=431583035, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1162981592, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=36929383, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=558997659, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1170738400, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=638716031, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1370540179, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1158188031, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=736705210, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=668944170, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1762171257, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1479280039, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1053761322, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=85669405, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1878009253, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1711971829, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1188866912, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1950658807, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=40435895, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1533410487, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1265308685, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=95670469, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1807615750, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1661859404, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1257132191, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1358080722, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1516037681, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2100507348, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1029308608, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=197085600, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=194950017, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=512123781, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=9296271, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1239945067, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=871623051, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=586480926, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1749030259, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1583854600, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1626519472, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=421812524, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1171935260, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1849872463, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1125894191, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=934280398, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=37682518, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1315216824, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1670721594, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=318734667, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1254504764, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2115710543, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=317484889, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1263727056, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1808159292, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=450574695, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=769883688, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1070426137, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=552319505, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1477978229, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2045989987, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1860146417, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=522905020, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=829424085, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1975129208, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=82427859, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1102978002, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1331177826, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1987056820, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1249635295, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1085105712, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1529120346, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1407425547, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1887858201, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1655383447, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=871972408, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=421406569, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=29292071, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=459496454, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=459636392, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=485541832, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=387478803, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=376050549, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1378311018, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1586275502, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1222534611, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=199302447, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1366606415, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2145936775, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1409508013, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1522708998, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1626948391, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=718694307, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1970762809, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1129498946, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=750157140, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=445896170, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1642915061, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1617652705, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1475372493, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1380753380, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1257928509, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1373024350, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=900791950, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1788705976, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=510646407, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=894992383, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=302785661, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1420640023, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=216649937, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=36409004, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1297508408, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2035948063, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=670668732, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1375954227, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=361162859, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1410380135, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1505416914, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=899122734, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=184929701, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1281016468, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1812117777, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=153465486, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1186217536, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1608713165, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1361664662, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1507008330, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=117642409, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=610605148, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1895096538, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1328955599, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1198240214, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=773160470, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1783923180, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=951314, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1768620509, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1598273068, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=58169221, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=305309651, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1061809653, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=110312159, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1971262713, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1236526033, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1940655476, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1488590241, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1397024026, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=520201856, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1505575640, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2127942195, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1017802524, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1824745645, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=960415766, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1638427617, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1083826808, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1424703378, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=541975530, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=452798852, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=16720072, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=640311816, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=10749494, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=719928875, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1158002526, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=88547826, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1545750743, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1572681886, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1311844483, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=278216905, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=523313505, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1316351282, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2048930257, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1029128583, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1627897060, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2142767052, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=966756323, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1815731987, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=467415491, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=352987205, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=221957267, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1065241527, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=353581846, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1001799561, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=486227075, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1309985231, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1136704764, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1673382631, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1577514484, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1133333284, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=990841221, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1767800275, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=357901096, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=384639431, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2088089153, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1698518045, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1609803184, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1844012401, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2060751342, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1691407564, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1324762674, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=611533614, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1736975596, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2081020514, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=420035838, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=50519528, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=306603074, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=509082705, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1827666142, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=256564766, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=594590611, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1028433736, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1591743478, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1553388518, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=943864917, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=998732843, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=831147469, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1523869201, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=617080870, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=288978175, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1308332044, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=24986842, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=694543591, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=356637576, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1725184061, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=915406791, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=962527092, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=927408462, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=284211965, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2786645, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1339839472, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=590519190, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=84380792, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1083384896, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=117931386, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=441959628, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=866404542, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1697589229, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=370870529, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=255729213, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1730970808, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=521011367, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1962508154, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1963718530, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1045468970, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1628160162, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=445815849, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=945086968, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1789665213, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1298346560, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=259587696, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2135013837, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=37655902, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=122166794, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1380066470, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1266375042, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1494529566, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1582608809, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=339605249, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1950634493, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=975067957, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1341449201, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=194671048, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=575772027, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=16828212, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=655535560, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=301796833, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=191732041, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1236503164, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1376222320, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1796281235, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1995931482, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=973857212, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=254561326, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1863313481, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1770697446, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1118146368, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=337171273, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=756474104, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1847171613, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1488447389, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=476067112, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=51668592, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=619593833, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=566576309, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1493702354, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1311589051, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=751024955, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1505517913, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=787299189, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1918600006, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=120964340, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=557005688, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=543159014, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=691987374, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=628944608, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=222235902, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=490651522, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2127761272, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=570441515, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=296324445, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1828030197, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1167513907, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=586379172, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1969198630, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1844646561, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1399486303, splitter='best')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sugar is bad to consume. My sister likes to have sugar, but not my father.\n",
      "sugar bad consume. sister likes sugar, father.\n",
      "sugar bad consume sister likes sugar father\n",
      "sugar bad consume sister like sugar father\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sugar bad consume sister like sugar father'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(\"Sugar is bad to consume. My sister likes to have sugar, but not my father.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
    "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
    "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
    "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
    "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
    "\n",
    "doc_complete = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in doc_complete]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### document vs term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)],\n",
       " [(2, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(8, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1)],\n",
       " [(2, 1),\n",
       "  (4, 1),\n",
       "  (18, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 1)],\n",
       " [(5, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.075*\"father\" + 0.075*\"sister\"'),\n",
       " (1, '0.075*\"pressure\" + 0.075*\"driving\"'),\n",
       " (2, '0.092*\"sugar\" + 0.092*\"expert\"'),\n",
       " (3, '0.085*\"father\" + 0.085*\"sister\"'),\n",
       " (4, '0.029*\"sugar\" + 0.029*\"father\"')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel = Lda(doc_term_matrix, id2word = dictionary, passes=50,num_topics=5)\n",
    "\n",
    "ldamodel.print_topics(num_topics=5, num_words=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using data and preprocessing steps from previous algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sugar  -  0.6328673784156658\n",
      "bad  -  0.39221140155135636\n",
      "consume  -  0.39221140155135636\n",
      "sister  -  0.26266854666732053\n",
      "like  -  0.39221140155135636\n",
      "father  -  0.26266854666732053\n",
      "sister  -  0.26266854666732053\n",
      "father  -  0.26266854666732053\n",
      "spends  -  0.0\n",
      "lot  -  0.0\n",
      "time  -  0.0\n",
      "driving  -  0.0\n",
      "around  -  0.0\n",
      "dance  -  0.0\n",
      "practice  -  0.0\n",
      "driving  -  0.0\n",
      "doctor  -  0.0\n",
      "suggest  -  0.0\n",
      "may  -  0.0\n",
      "cause  -  0.0\n",
      "increased  -  0.0\n",
      "stress  -  0.0\n",
      "blood  -  0.0\n",
      "pressure  -  0.0\n",
      "sister  -  0.26266854666732053\n",
      "father  -  0.26266854666732053\n",
      "pressure  -  0.0\n",
      "sometimes  -  0.0\n",
      "feel  -  0.0\n",
      "perform  -  0.0\n",
      "well  -  0.0\n",
      "school  -  0.0\n",
      "never  -  0.0\n",
      "seems  -  0.0\n",
      "drive  -  0.0\n",
      "better  -  0.0\n",
      "sugar  -  0.6328673784156658\n",
      "health  -  0.0\n",
      "expert  -  0.0\n",
      "say  -  0.0\n",
      "good  -  0.0\n",
      "lifestyle  -  0.0\n"
     ]
    }
   ],
   "source": [
    "response = tfidf.fit_transform([clean(doc) for doc in doc_complete])\n",
    "feature_names = tfidf.get_feature_names()\n",
    "for col in response.nonzero()[1]:\n",
    "    print (feature_names[col], ' - ', response[0, col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam,SGD\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH = 30\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10\n",
    "\n",
    "OPTIMIZER = RMSprop() \n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.1\n",
    "\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11444224/11490434 [============================>.] - ETA: 0s(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_test.shape)\n",
    "RESHAPED = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(60000, 784) train samples\n",
      "(10000, 784) test samples\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape, 'train samples')\n",
    "print(X_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "54000/54000 [==============================] - 0s - loss: nan - acc: 0.1029 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 2/30\n",
      "54000/54000 [==============================] - 0s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 3/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 4/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 5/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 6/30\n",
      "54000/54000 [==============================] - 0s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 7/30\n",
      "54000/54000 [==============================] - 0s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 8/30\n",
      "54000/54000 [==============================] - 0s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 9/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 10/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 11/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 12/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 13/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 14/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 15/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 16/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 17/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 18/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 19/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 20/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 21/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 22/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 23/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 24/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 25/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 26/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 27/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 28/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 29/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "Epoch 30/30\n",
      "54000/54000 [==============================] - 1s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0978\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " 9184/10000 [==========================>...] - ETA: 0sTest accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH,verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "model.summary()\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.3261 - acc: 0.9051 - val_loss: 0.1326 - val_acc: 0.9630\n",
      "Epoch 2/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.1365 - acc: 0.9590 - val_loss: 0.1007 - val_acc: 0.9730\n",
      "Epoch 3/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0942 - acc: 0.9715 - val_loss: 0.0830 - val_acc: 0.9760\n",
      "Epoch 4/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0718 - acc: 0.9783 - val_loss: 0.0873 - val_acc: 0.9768\n",
      "Epoch 5/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0569 - acc: 0.9824 - val_loss: 0.0871 - val_acc: 0.9777\n",
      "Epoch 6/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0455 - acc: 0.9862 - val_loss: 0.0768 - val_acc: 0.9782\n",
      "Epoch 7/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0366 - acc: 0.9891 - val_loss: 0.0831 - val_acc: 0.9802\n",
      "Epoch 8/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0310 - acc: 0.9904 - val_loss: 0.0824 - val_acc: 0.9803\n",
      "Epoch 9/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0249 - acc: 0.9924 - val_loss: 0.0920 - val_acc: 0.9778\n",
      "Epoch 10/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0876 - val_acc: 0.9793\n",
      "Epoch 11/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0177 - acc: 0.9944 - val_loss: 0.0931 - val_acc: 0.9797\n",
      "Epoch 12/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0855 - val_acc: 0.9808\n",
      "Epoch 13/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0120 - acc: 0.9959 - val_loss: 0.1051 - val_acc: 0.9777\n",
      "Epoch 14/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0101 - acc: 0.9966 - val_loss: 0.1041 - val_acc: 0.9780\n",
      "Epoch 15/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.1084 - val_acc: 0.9785\n",
      "Epoch 16/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0077 - acc: 0.9971 - val_loss: 0.1002 - val_acc: 0.9805\n",
      "Epoch 17/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1178 - val_acc: 0.9775\n",
      "Epoch 18/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0064 - acc: 0.9979 - val_loss: 0.1098 - val_acc: 0.9803\n",
      "Epoch 19/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0048 - acc: 0.9986 - val_loss: 0.1295 - val_acc: 0.9802\n",
      "Epoch 20/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0047 - acc: 0.9983 - val_loss: 0.1399 - val_acc: 0.9785\n",
      "Epoch 21/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1174 - val_acc: 0.9810\n",
      "Epoch 22/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0044 - acc: 0.9984 - val_loss: 0.1338 - val_acc: 0.9797\n",
      "Epoch 23/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0035 - acc: 0.9989 - val_loss: 0.1173 - val_acc: 0.9820\n",
      "Epoch 24/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0035 - acc: 0.9987 - val_loss: 0.1214 - val_acc: 0.9810\n",
      "Epoch 25/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1346 - val_acc: 0.9788\n",
      "Epoch 26/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0028 - acc: 0.9991 - val_loss: 0.1342 - val_acc: 0.9812\n",
      "Epoch 27/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0025 - acc: 0.9992 - val_loss: 0.1372 - val_acc: 0.9795\n",
      "Epoch 28/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0023 - acc: 0.9992 - val_loss: 0.1235 - val_acc: 0.9822\n",
      "Epoch 29/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0016 - acc: 0.9995 - val_loss: 0.1302 - val_acc: 0.9807\n",
      "Epoch 30/30\n",
      "54000/54000 [==============================] - 1s - loss: 0.0020 - acc: 0.9993 - val_loss: 0.1428 - val_acc: 0.9805\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " 8576/10000 [========================>.....] - ETA: 0sTest accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "history = model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH,verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "model.summary()\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-956a558f1dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('dutch_architecture.json', 'w').write(model_json)\n",
    "\n",
    "model.save_weights('Dutch_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, kernel_size=5, padding=\"same\",input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 30\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = RMSprop()\n",
    "VALIDATION_SPLIT=0.1\n",
    "IMG_ROWS, IMG_COLS = 28, 28 \n",
    "NB_CLASSES = 10 \n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1, 28, 20)         14020     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1, 28, 20)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 14, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 14, 50)         12550     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1, 14, 50)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 7, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 175)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               88000     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 119,580\n",
      "Trainable params: 119,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.4363 - acc: 0.8638 - val_loss: 0.1358 - val_acc: 0.9578\n",
      "Epoch 2/30\n",
      "54000/54000 [==============================] - 7s - loss: 0.1368 - acc: 0.9574 - val_loss: 0.0859 - val_acc: 0.9762\n",
      "Epoch 3/30\n",
      "54000/54000 [==============================] - 7s - loss: 0.0925 - acc: 0.9708 - val_loss: 0.0757 - val_acc: 0.9798\n",
      "Epoch 4/30\n",
      "54000/54000 [==============================] - 7s - loss: 0.0718 - acc: 0.9771 - val_loss: 0.0612 - val_acc: 0.9822\n",
      "Epoch 5/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0590 - acc: 0.9810 - val_loss: 0.0711 - val_acc: 0.9787\n",
      "Epoch 6/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0500 - acc: 0.9847 - val_loss: 0.0607 - val_acc: 0.9833\n",
      "Epoch 7/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0436 - acc: 0.9859 - val_loss: 0.0644 - val_acc: 0.9813\n",
      "Epoch 8/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0391 - acc: 0.9874 - val_loss: 0.0587 - val_acc: 0.9830\n",
      "Epoch 9/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0344 - acc: 0.9887 - val_loss: 0.0503 - val_acc: 0.9858\n",
      "Epoch 10/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0306 - acc: 0.9895 - val_loss: 0.0530 - val_acc: 0.9853\n",
      "Epoch 11/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0273 - acc: 0.9910 - val_loss: 0.0479 - val_acc: 0.9880\n",
      "Epoch 12/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0246 - acc: 0.9920 - val_loss: 0.0734 - val_acc: 0.9802\n",
      "Epoch 13/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0216 - acc: 0.9927 - val_loss: 0.0549 - val_acc: 0.9867\n",
      "Epoch 14/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0194 - acc: 0.9933 - val_loss: 0.0500 - val_acc: 0.9870\n",
      "Epoch 15/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0609 - val_acc: 0.9860\n",
      "Epoch 16/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0590 - val_acc: 0.9872\n",
      "Epoch 17/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0145 - acc: 0.9951 - val_loss: 0.1059 - val_acc: 0.9743\n",
      "Epoch 18/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0546 - val_acc: 0.9878\n",
      "Epoch 19/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0481 - val_acc: 0.9892\n",
      "Epoch 20/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0481 - val_acc: 0.9890\n",
      "Epoch 21/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0625 - val_acc: 0.9868\n",
      "Epoch 22/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0761 - val_acc: 0.9835\n",
      "Epoch 23/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0086 - acc: 0.9969 - val_loss: 0.0676 - val_acc: 0.9882\n",
      "Epoch 24/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0670 - val_acc: 0.9852\n",
      "Epoch 25/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0759 - val_acc: 0.9865\n",
      "Epoch 26/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0748 - val_acc: 0.9872\n",
      "Epoch 27/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0655 - val_acc: 0.9863\n",
      "Epoch 28/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0660 - val_acc: 0.9878\n",
      "Epoch 29/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0752 - val_acc: 0.9875\n",
      "Epoch 30/30\n",
      "54000/54000 [==============================] - 8s - loss: 0.0054 - acc: 0.9978 - val_loss: 0.0849 - val_acc: 0.9868\n",
      " 9792/10000 [============================>.] - ETA: 0sTest accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,metrics=[\"accuracy\"])\n",
    "\n",
    "X_train = X_train[:, np.newaxis, :, :]\n",
    "X_test = X_test[:, np.newaxis, :, :]\n",
    "\n",
    "history = model.fit(X_train, y_train,batch_size=BATCH_SIZE, epochs=NB_EPOCH,verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('CNN_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('CNN_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#load model\n",
    "model_architecture = 'CNN_architecture.json'\n",
    "model_weights = 'CNN_weights.h5'\n",
    "lModel = model_from_json(open(model_architecture).read())\n",
    "lModel.load_weights(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/io/opencv/modules/imgproc/src/color.cpp:9748: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ee207f9c6021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Deep_Learning/second.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# file = file.reshape(28, 28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /io/opencv/modules/imgproc/src/color.cpp:9748: error: (-215) scn == 3 || scn == 4 in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "file = cv2.imread('./Deep_Learning/second.png') \n",
    "file = np.resize(file, (28, 28))\n",
    "file = cv2.cvtColor(file, cv2.COLOR_BGR2GRAY)\n",
    "# file = file.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (1, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b215c5b680ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1694\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (1, 28, 28)"
     ]
    }
   ],
   "source": [
    "print(lModel.predict([np.expand_dims(file, axis = 0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "file = cv2.imread('./Deep_Learning/zeros.png',0) \n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "image = cv2.resize(file, (28, 28))\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image = image.astype(\"float\") / 255.0\n",
    "\n",
    "image = img_to_array([image])\n",
    "image = np.expand_dims(image, axis=0)\n",
    "label = model.predict_classes(image)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images(\"./Deep_Learning\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Deep_Learning/test1/second.png\n",
      "test1\n",
      "./Deep_Learning/test1/zeros.png\n",
      "test1\n",
      "./Deep_Learning/test2/dog.jpeg\n",
      "test2\n",
      "./Deep_Learning/test2/cat.jpg\n",
      "test2\n"
     ]
    }
   ],
   "source": [
    "for imagePath in imagePaths:\n",
    "    if 'test' in imagePath: \n",
    "#       print(imagePath)\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (40,40))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        \n",
    "        print(imagePath.split(\"/\")[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open(\"./Deep_Learning/11.txt\", 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gutenbergs alices adventures in wonderland, by lewis carroll',\n",
       " 'this ebook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  you may copy it, give it away or',\n",
       " 're-use it under the terms of the project gutenberg license included',\n",
       " 'with this ebook or online at www.gutenberg.org',\n",
       " 'title: alices adventures in wonderland',\n",
       " 'author: lewis carroll',\n",
       " 'posting date: june 25, 2008 [ebook #11]',\n",
       " 'release date: march, 1994',\n",
       " 'last updated: october 6, 2016',\n",
       " 'language: english',\n",
       " 'character set encoding: utf-8',\n",
       " '*** start of this project gutenberg ebook alices adventures in wonderland ***',\n",
       " 'alices adventures in wonderland',\n",
       " 'lewis carroll',\n",
       " 'the millennium fulcrum edition 3.0',\n",
       " 'chapter i. down the rabbit-hole',\n",
       " 'alice was beginning to get very tired of sitting by her sister on the',\n",
       " 'bank, and of having nothing to do: once or twice she had peeped into the',\n",
       " 'book her sister was reading, but it had no pictures or conversations in',\n",
       " 'it, and what is the use of a book, thought alice without pictures or',\n",
       " 'conversations?',\n",
       " 'so she was considering in her own mind (as well as she could, for the',\n",
       " 'hot day made her feel very sleepy and stupid), whether the pleasure',\n",
       " 'of making a daisy-chain would be worth the trouble of getting up and',\n",
       " 'picking the daisies, when suddenly a white rabbit with pink eyes ran',\n",
       " 'close by her.',\n",
       " 'there was nothing so very remarkable in that; nor did alice think it so',\n",
       " 'very much out of the way to hear the rabbit say to itself, oh dear!',\n",
       " 'oh dear! i shall be late! (when she thought it over afterwards, it',\n",
       " 'occurred to her that she ought to have wondered at this, but at the time',\n",
       " 'it all seemed quite natural); but when the rabbit actually took a watch',\n",
       " 'out of its waistcoat-pocket, and looked at it, and then hurried on,',\n",
       " 'alice started to her feet, for it flashed across her mind that she had',\n",
       " 'never before seen a rabbit with either a waistcoat-pocket, or a watch',\n",
       " 'to take out of it, and burning with curiosity, she ran across the field',\n",
       " 'after it, and fortunately was just in time to see it pop down a large',\n",
       " 'rabbit-hole under the hedge.',\n",
       " 'in another moment down went alice after it, never once considering how',\n",
       " 'in the world she was to get out again.',\n",
       " 'the rabbit-hole went straight on like a tunnel for some way, and then',\n",
       " 'dipped suddenly down, so suddenly that alice had not a moment to think',\n",
       " 'about stopping herself before she found herself falling down a very deep',\n",
       " 'well.',\n",
       " 'either the well was very deep, or she fell very slowly, for she had',\n",
       " 'plenty of time as she went down to look about her and to wonder what was',\n",
       " 'going to happen next. first, she tried to look down and make out what',\n",
       " 'she was coming to, but it was too dark to see anything; then she',\n",
       " 'looked at the sides of the well, and noticed that they were filled with',\n",
       " 'cupboards and book-shelves; here and there she saw maps and pictures',\n",
       " 'hung upon pegs. she took down a jar from one of the shelves as',\n",
       " 'she passed; it was labelled orange marmalade, but to her great',\n",
       " 'disappointment it was empty: she did not like to drop the jar for fear',\n",
       " 'of killing somebody, so managed to put it into one of the cupboards as',\n",
       " 'she fell past it.',\n",
       " 'well! thought alice to herself, after such a fall as this, i shall',\n",
       " 'think nothing of tumbling down stairs! how brave theyll all think me at',\n",
       " 'home! why, i wouldnt say anything about it, even if i fell off the top',\n",
       " 'of the house! (which was very likely true.)',\n",
       " 'down, down, down. would the fall never come to an end! i wonder how',\n",
       " 'many miles ive fallen by this time? she said aloud. i must be getting',\n",
       " 'somewhere near the centre of the earth. let me see: that would be four',\n",
       " 'thousand miles down, i think-- (for, you see, alice had learnt several',\n",
       " 'things of this sort in her lessons in the schoolroom, and though this',\n",
       " 'was not a very good opportunity for showing off her knowledge, as there',\n",
       " 'was no one to listen to her, still it was good practice to say it over)',\n",
       " '--yes, thats about the right distance--but then i wonder what latitude',\n",
       " 'or longitude ive got to? (alice had no idea what latitude was, or',\n",
       " 'longitude either, but thought they were nice grand words to say.)',\n",
       " 'presently she began again. i wonder if i shall fall right through the',\n",
       " 'earth! how funny itll seem to come out among the people that walk with',\n",
       " 'their heads downward! the antipathies, i think-- (she was rather glad',\n",
       " 'there was no one listening, this time, as it didnt sound at all the',\n",
       " 'right word) --but i shall have to ask them what the name of the country',\n",
       " 'is, you know. please, maam, is this new zealand or australia? (and',\n",
       " 'she tried to curtsey as she spoke--fancy curtseying as youre falling',\n",
       " 'through the air! do you think you could manage it?) and what an',\n",
       " 'ignorant little girl shell think me for asking! no, itll never do to',\n",
       " 'ask: perhaps i shall see it written up somewhere.',\n",
       " 'down, down, down. there was nothing else to do, so alice soon began',\n",
       " 'talking again. dinahll miss me very much to-night, i should think!',\n",
       " '(dinah was the cat.) i hope theyll remember her saucer of milk at',\n",
       " 'tea-time. dinah my dear! i wish you were down here with me! there are no',\n",
       " 'mice in the air, im afraid, but you might catch a bat, and thats very',\n",
       " 'like a mouse, you know. but do cats eat bats, i wonder? and here alice',\n",
       " 'began to get rather sleepy, and went on saying to herself, in a dreamy',\n",
       " 'sort of way, do cats eat bats? do cats eat bats? and sometimes, do',\n",
       " 'bats eat cats? for, you see, as she couldnt answer either question,',\n",
       " 'it didnt much matter which way she put it. she felt that she was dozing',\n",
       " 'off, and had just begun to dream that she was walking hand in hand with',\n",
       " 'dinah, and saying to her very earnestly, now, dinah, tell me the truth:',\n",
       " 'did you ever eat a bat? when suddenly, thump! thump! down she came upon',\n",
       " 'a heap of sticks and dry leaves, and the fall was over.',\n",
       " 'alice was not a bit hurt, and she jumped up on to her feet in a moment:',\n",
       " 'she looked up, but it was all dark overhead; before her was another',\n",
       " 'long passage, and the white rabbit was still in sight, hurrying down it.',\n",
       " 'there was not a moment to be lost: away went alice like the wind, and',\n",
       " 'was just in time to hear it say, as it turned a corner, oh my ears',\n",
       " 'and whiskers, how late its getting! she was close behind it when she',\n",
       " 'turned the corner, but the rabbit was no longer to be seen: she found',\n",
       " 'herself in a long, low hall, which was lit up by a row of lamps hanging',\n",
       " 'from the roof.',\n",
       " 'there were doors all round the hall, but they were all locked; and when',\n",
       " 'alice had been all the way down one side and up the other, trying every',\n",
       " 'door, she walked sadly down the middle, wondering how she was ever to',\n",
       " 'get out again.',\n",
       " 'suddenly she came upon a little three-legged table, all made of solid',\n",
       " 'glass; there was nothing on it except a tiny golden key, and alices',\n",
       " 'first thought was that it might belong to one of the doors of the hall;',\n",
       " 'but, alas! either the locks were too large, or the key was too small,',\n",
       " 'but at any rate it would not open any of them. however, on the second',\n",
       " 'time round, she came upon a low curtain she had not noticed before, and',\n",
       " 'behind it was a little door about fifteen inches high: she tried the',\n",
       " 'little golden key in the lock, and to her great delight it fitted!',\n",
       " 'alice opened the door and found that it led into a small passage, not',\n",
       " 'much larger than a rat-hole: she knelt down and looked along the passage',\n",
       " 'into the loveliest garden you ever saw. how she longed to get out of',\n",
       " 'that dark hall, and wander about among those beds of bright flowers and',\n",
       " 'those cool fountains, but she could not even get her head through the',\n",
       " 'doorway; and even if my head would go through, thought poor alice, it',\n",
       " 'would be of very little use without my shoulders. oh, how i wish i could',\n",
       " 'shut up like a telescope! i think i could, if i only knew how to begin.',\n",
       " 'for, you see, so many out-of-the-way things had happened lately,',\n",
       " 'that alice had begun to think that very few things indeed were really',\n",
       " 'impossible.',\n",
       " 'there seemed to be no use in waiting by the little door, so she went',\n",
       " 'back to the table, half hoping she might find another key on it, or at',\n",
       " 'any rate a book of rules for shutting people up like telescopes: this',\n",
       " 'time she found a little bottle on it, [which certainly was not here',\n",
       " 'before, said alice,) and round the neck of the bottle was a paper',\n",
       " 'label, with the words drink me beautifully printed on it in large',\n",
       " 'letters.',\n",
       " 'it was all very well to say drink me, but the wise little alice was',\n",
       " 'not going to do that in a hurry. no, ill look first, she said, and',\n",
       " 'see whether its marked poison or not; for she had read several nice',\n",
       " 'little histories about children who had got burnt, and eaten up by wild',\n",
       " 'beasts and other unpleasant things, all because they would not remember',\n",
       " 'the simple rules their friends had taught them: such as, that a red-hot',\n",
       " 'poker will burn you if you hold it too long; and that if you cut your',\n",
       " 'finger very deeply with a knife, it usually bleeds; and she had never',\n",
       " 'forgotten that, if you drink much from a bottle marked poison, it is',\n",
       " 'almost certain to disagree with you, sooner or later.',\n",
       " 'however, this bottle was not marked poison, so alice ventured to taste',\n",
       " 'it, and finding it very nice, (it had, in fact, a sort of mixed flavour',\n",
       " 'of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot',\n",
       " 'buttered toast,) she very soon finished it off.',\n",
       " '*    *    *    *    *    *    *',\n",
       " '*    *    *    *    *    *',\n",
       " '*    *    *    *    *    *    *',\n",
       " 'what a curious feeling! said alice; i must be shutting up like a',\n",
       " 'telescope.',\n",
       " 'and so it was indeed: she was now only ten inches high, and her face',\n",
       " 'brightened up at the thought that she was now the right size for going',\n",
       " 'through the little door into that lovely garden. first, however, she',\n",
       " 'waited for a few minutes to see if she was going to shrink any further:',\n",
       " 'she felt a little nervous about this; for it might end, you know, said',\n",
       " 'alice to herself, in my going out altogether, like a candle. i wonder',\n",
       " 'what i should be like then? and she tried to fancy what the flame of a',\n",
       " 'candle is like after the candle is blown out, for she could not remember',\n",
       " 'ever having seen such a thing.',\n",
       " 'after a while, finding that nothing more happened, she decided on going',\n",
       " 'into the garden at once; but, alas for poor alice! when she got to the',\n",
       " 'door, she found she had forgotten the little golden key, and when she',\n",
       " 'went back to the table for it, she found she could not possibly reach',\n",
       " 'it: she could see it quite plainly through the glass, and she tried her',\n",
       " 'best to climb up one of the legs of the table, but it was too slippery;',\n",
       " 'and when she had tired herself out with trying, the poor little thing',\n",
       " 'sat down and cried.',\n",
       " 'come, theres no use in crying like that! said alice to herself,',\n",
       " 'rather sharply; i advise you to leave off this minute! she generally',\n",
       " 'gave herself very good advice, (though she very seldom followed it),',\n",
       " 'and sometimes she scolded herself so severely as to bring tears into',\n",
       " 'her eyes; and once she remembered trying to box her own ears for having',\n",
       " 'cheated herself in a game of croquet she was playing against herself,',\n",
       " 'for this curious child was very fond of pretending to be two people.',\n",
       " 'but its no use now, thought poor alice, to pretend to be two people!',\n",
       " 'why, theres hardly enough of me left to make one respectable person!',\n",
       " 'soon her eye fell on a little glass box that was lying under the table:',\n",
       " 'she opened it, and found in it a very small cake, on which the words',\n",
       " 'eat me were beautifully marked in currants. well, ill eat it, said',\n",
       " 'alice, and if it makes me grow larger, i can reach the key; and if it',\n",
       " 'makes me grow smaller, i can creep under the door; so either way ill',\n",
       " 'get into the garden, and i dont care which happens!',\n",
       " 'she ate a little bit, and said anxiously to herself, which way? which',\n",
       " 'way?, holding her hand on the top of her head to feel which way it was',\n",
       " 'growing, and she was quite surprised to find that she remained the same',\n",
       " 'size: to be sure, this generally happens when one eats cake, but alice',\n",
       " 'had got so much into the way of expecting nothing but out-of-the-way',\n",
       " 'things to happen, that it seemed quite dull and stupid for life to go on',\n",
       " 'in the common way.',\n",
       " 'so she set to work, and very soon finished off the cake.',\n",
       " '*    *    *    *    *    *    *',\n",
       " '*    *    *    *    *    *',\n",
       " '*    *    *    *    *    *    *',\n",
       " 'chapter ii. the pool of tears',\n",
       " 'curiouser and curiouser! cried alice (she was so much surprised, that',\n",
       " 'for the moment she quite forgot how to speak good english); now im',\n",
       " 'opening out like the largest telescope that ever was! good-bye, feet!',\n",
       " '(for when she looked down at her feet, they seemed to be almost out of',\n",
       " 'sight, they were getting so far off). oh, my poor little feet, i wonder',\n",
       " 'who will put on your shoes and stockings for you now, dears? im sure',\n",
       " '_i_ shant be able! i shall be a great deal too far off to trouble',\n",
       " 'myself about you: you must manage the best way you can;--but i must be',\n",
       " 'kind to them, thought alice, or perhaps they wont walk the way i want',\n",
       " 'to go! let me see: ill give them a new pair of boots every christmas.',\n",
       " 'and she went on planning to herself how she would manage it. they must',\n",
       " 'go by the carrier, she thought; and how funny itll seem, sending',\n",
       " 'presents to ones own feet! and how odd the directions will look!',\n",
       " 'alices right foot, esq.',\n",
       " 'hearthrug,',\n",
       " 'near the fender,',\n",
       " '(with alices love).',\n",
       " 'oh dear, what nonsense im talking!',\n",
       " 'just then her head struck against the roof of the hall: in fact she was',\n",
       " 'now more than nine feet high, and she at once took up the little golden',\n",
       " 'key and hurried off to the garden door.',\n",
       " 'poor alice! it was as much as she could do, lying down on one side, to',\n",
       " 'look through into the garden with one eye; but to get through was more',\n",
       " 'hopeless than ever: she sat down and began to cry again.',\n",
       " 'you ought to be ashamed of yourself, said alice, a great girl like',\n",
       " 'you, (she might well say this), to go on crying in this way! stop this',\n",
       " 'moment, i tell you! but she went on all the same, shedding gallons of',\n",
       " 'tears, until there was a large pool all round her, about four inches',\n",
       " 'deep and reaching half down the hall.',\n",
       " 'after a time she heard a little pattering of feet in the distance, and',\n",
       " 'she hastily dried her eyes to see what was coming. it was the white',\n",
       " 'rabbit returning, splendidly dressed, with a pair of white kid gloves in',\n",
       " 'one hand and a large fan in the other: he came trotting along in a great',\n",
       " 'hurry, muttering to himself as he came, oh! the duchess, the duchess!',\n",
       " 'oh! wont she be savage if ive kept her waiting! alice felt so',\n",
       " 'desperate that she was ready to ask help of any one; so, when the rabbit',\n",
       " 'came near her, she began, in a low, timid voice, if you please, sir--',\n",
       " 'the rabbit started violently, dropped the white kid gloves and the fan,',\n",
       " 'and skurried away into the darkness as hard as he could go.',\n",
       " 'alice took up the fan and gloves, and, as the hall was very hot, she',\n",
       " 'kept fanning herself all the time she went on talking: dear, dear! how',\n",
       " 'queer everything is to-day! and yesterday things went on just as usual.',\n",
       " 'i wonder if ive been changed in the night? let me think: was i the',\n",
       " 'same when i got up this morning? i almost think i can remember feeling a',\n",
       " 'little different. but if im not the same, the next question is, who',\n",
       " 'in the world am i? ah, thats the great puzzle! and she began thinking',\n",
       " 'over all the children she knew that were of the same age as herself, to',\n",
       " 'see if she could have been changed for any of them.',\n",
       " 'im sure im not ada, she said, for her hair goes in such long',\n",
       " 'ringlets, and mine doesnt go in ringlets at all; and im sure i cant',\n",
       " 'be mabel, for i know all sorts of things, and she, oh! she knows such a',\n",
       " 'very little! besides, shes she, and im i, and--oh dear, how puzzling',\n",
       " 'it all is! ill try if i know all the things i used to know. let me',\n",
       " 'see: four times five is twelve, and four times six is thirteen, and',\n",
       " 'four times seven is--oh dear! i shall never get to twenty at that rate!',\n",
       " 'however, the multiplication table doesnt signify: lets try geography.',\n",
       " 'london is the capital of paris, and paris is the capital of rome, and',\n",
       " 'rome--no, thats all wrong, im certain! i must have been changed for',\n",
       " 'mabel! ill try and say how doth the little-- and she crossed her',\n",
       " 'hands on her lap as if she were saying lessons, and began to repeat it,',\n",
       " 'but her voice sounded hoarse and strange, and the words did not come the',\n",
       " 'same as they used to do:--',\n",
       " 'how doth the little crocodile',\n",
       " 'improve his shining tail,',\n",
       " 'and pour the waters of the nile',\n",
       " 'on every golden scale!',\n",
       " 'how cheerfully he seems to grin,',\n",
       " 'how neatly spread his claws,',\n",
       " 'and welcome little fishes in',\n",
       " 'with gently smiling jaws!',\n",
       " 'im sure those are not the right words, said poor alice, and her eyes',\n",
       " 'filled with tears again as she went on, i must be mabel after all, and',\n",
       " 'i shall have to go and live in that poky little house, and have next to',\n",
       " 'no toys to play with, and oh! ever so many lessons to learn! no, ive',\n",
       " 'made up my mind about it; if im mabel, ill stay down here! itll be no',\n",
       " 'use their putting their heads down and saying come up again, dear! i',\n",
       " 'shall only look up and say who am i then? tell me that first, and then,',\n",
       " 'if i like being that person, ill come up: if not, ill stay down here',\n",
       " 'till im somebody else--but, oh dear! cried alice, with a sudden burst',\n",
       " 'of tears, i do wish they would put their heads down! i am so very tired',\n",
       " 'of being all alone here!',\n",
       " 'as she said this she looked down at her hands, and was surprised to see',\n",
       " 'that she had put on one of the rabbits little white kid gloves while',\n",
       " 'she was talking. how can i have done that? she thought. i must',\n",
       " 'be growing small again. she got up and went to the table to measure',\n",
       " 'herself by it, and found that, as nearly as she could guess, she was now',\n",
       " 'about two feet high, and was going on shrinking rapidly: she soon found',\n",
       " 'out that the cause of this was the fan she was holding, and she dropped',\n",
       " 'it hastily, just in time to avoid shrinking away altogether.',\n",
       " 'that was a narrow escape! said alice, a good deal frightened at the',\n",
       " 'sudden change, but very glad to find herself still in existence; and',\n",
       " 'now for the garden! and she ran with all speed back to the little door:',\n",
       " 'but, alas! the little door was shut again, and the little golden key was',\n",
       " 'lying on the glass table as before, and things are worse than ever,',\n",
       " 'thought the poor child, for i never was so small as this before, never!',\n",
       " 'and i declare its too bad, that it is!',\n",
       " 'as she said these words her foot slipped, and in another moment, splash!',\n",
       " 'she was up to her chin in salt water. her first idea was that she',\n",
       " 'had somehow fallen into the sea, and in that case i can go back by',\n",
       " 'railway, she said to herself. (alice had been to the seaside once in',\n",
       " 'her life, and had come to the general conclusion, that wherever you go',\n",
       " 'to on the english coast you find a number of bathing machines in the',\n",
       " 'sea, some children digging in the sand with wooden spades, then a row',\n",
       " 'of lodging houses, and behind them a railway station.) however, she soon',\n",
       " 'made out that she was in the pool of tears which she had wept when she',\n",
       " 'was nine feet high.',\n",
       " 'i wish i hadnt cried so much! said alice, as she swam about, trying',\n",
       " 'to find her way out. i shall be punished for it now, i suppose, by',\n",
       " 'being drowned in my own tears! that will be a queer thing, to be sure!',\n",
       " 'however, everything is queer to-day.',\n",
       " 'just then she heard something splashing about in the pool a little way',\n",
       " 'off, and she swam nearer to make out what it was: at first she thought',\n",
       " 'it must be a walrus or hippopotamus, but then she remembered how small',\n",
       " 'she was now, and she soon made out that it was only a mouse that had',\n",
       " 'slipped in like herself.',\n",
       " 'would it be of any use, now, thought alice, to speak to this mouse?',\n",
       " 'everything is so out-of-the-way down here, that i should think very',\n",
       " 'likely it can talk: at any rate, theres no harm in trying. so she',\n",
       " 'began: o mouse, do you know the way out of this pool? i am very tired',\n",
       " 'of swimming about here, o mouse! (alice thought this must be the right',\n",
       " 'way of speaking to a mouse: she had never done such a thing before, but',\n",
       " 'she remembered having seen in her brothers latin grammar, a mouse--of',\n",
       " 'a mouse--to a mouse--a mouse--o mouse!) the mouse looked at her rather',\n",
       " 'inquisitively, and seemed to her to wink with one of its little eyes,',\n",
       " 'but it said nothing.',\n",
       " 'perhaps it doesnt understand english, thought alice; i daresay its',\n",
       " 'a french mouse, come over with william the conqueror. (for, with all',\n",
       " 'her knowledge of history, alice had no very clear notion how long ago',\n",
       " 'anything had happened.) so she began again: ou est ma chatte? which',\n",
       " 'was the first sentence in her french lesson-book. the mouse gave a',\n",
       " 'sudden leap out of the water, and seemed to quiver all over with fright.',\n",
       " 'oh, i beg your pardon! cried alice hastily, afraid that she had hurt',\n",
       " 'the poor animals feelings. i quite forgot you didnt like cats.',\n",
       " 'not like cats! cried the mouse, in a shrill, passionate voice. would',\n",
       " 'you like cats if you were me?',\n",
       " 'well, perhaps not, said alice in a soothing tone: dont be angry',\n",
       " 'about it. and yet i wish i could show you our cat dinah: i think youd',\n",
       " 'take a fancy to cats if you could only see her. she is such a dear quiet',\n",
       " 'thing, alice went on, half to herself, as she swam lazily about in the',\n",
       " 'pool, and she sits purring so nicely by the fire, licking her paws and',\n",
       " 'washing her face--and she is such a nice soft thing to nurse--and shes',\n",
       " 'such a capital one for catching mice--oh, i beg your pardon! cried',\n",
       " 'alice again, for this time the mouse was bristling all over, and she',\n",
       " 'felt certain it must be really offended. we wont talk about her any',\n",
       " 'more if youd rather not.',\n",
       " 'we indeed! cried the mouse, who was trembling down to the end of his',\n",
       " 'tail. as if i would talk on such a subject! our family always hated',\n",
       " 'cats: nasty, low, vulgar things! dont let me hear the name again!',\n",
       " 'i wont indeed! said alice, in a great hurry to change the subject of',\n",
       " 'conversation. are you--are you fond--of--of dogs? the mouse did not',\n",
       " 'answer, so alice went on eagerly: there is such a nice little dog near',\n",
       " 'our house i should like to show you! a little bright-eyed terrier, you',\n",
       " 'know, with oh, such long curly brown hair! and itll fetch things when',\n",
       " 'you throw them, and itll sit up and beg for its dinner, and all sorts',\n",
       " 'of things--i cant remember half of them--and it belongs to a farmer,',\n",
       " 'you know, and he says its so useful, its worth a hundred pounds! he',\n",
       " 'says it kills all the rats and--oh dear! cried alice in a sorrowful',\n",
       " 'tone, im afraid ive offended it again! for the mouse was swimming',\n",
       " 'away from her as hard as it could go, and making quite a commotion in',\n",
       " 'the pool as it went.',\n",
       " 'so she called softly after it, mouse dear! do come back again, and we',\n",
       " 'wont talk about cats or dogs either, if you dont like them! when the',\n",
       " 'mouse heard this, it turned round and swam slowly back to her: its',\n",
       " 'face was quite pale (with passion, alice thought), and it said in a low',\n",
       " 'trembling voice, let us get to the shore, and then ill tell you my',\n",
       " 'history, and youll understand why it is i hate cats and dogs.',\n",
       " 'it was high time to go, for the pool was getting quite crowded with the',\n",
       " 'birds and animals that had fallen into it: there were a duck and a dodo,',\n",
       " 'a lory and an eaglet, and several other curious creatures. alice led the',\n",
       " 'way, and the whole party swam to the shore.',\n",
       " 'chapter iii. a caucus-race and a long tale',\n",
       " 'they were indeed a queer-looking party that assembled on the bank--the',\n",
       " 'birds with draggled feathers, the animals with their fur clinging close',\n",
       " 'to them, and all dripping wet, cross, and uncomfortable.',\n",
       " 'the first question of course was, how to get dry again: they had a',\n",
       " 'consultation about this, and after a few minutes it seemed quite natural',\n",
       " 'to alice to find herself talking familiarly with them, as if she had',\n",
       " 'known them all her life. indeed, she had quite a long argument with the',\n",
       " 'lory, who at last turned sulky, and would only say, i am older than',\n",
       " 'you, and must know better; and this alice would not allow without',\n",
       " 'knowing how old it was, and, as the lory positively refused to tell its',\n",
       " 'age, there was no more to be said.',\n",
       " 'at last the mouse, who seemed to be a person of authority among them,',\n",
       " 'called out, sit down, all of you, and listen to me! ill soon make you',\n",
       " 'dry enough! they all sat down at once, in a large ring, with the mouse',\n",
       " 'in the middle. alice kept her eyes anxiously fixed on it, for she felt',\n",
       " 'sure she would catch a bad cold if she did not get dry very soon.',\n",
       " 'ahem! said the mouse with an important air, are you all ready? this',\n",
       " 'is the driest thing i know. silence all round, if you please! william',\n",
       " 'the conqueror, whose cause was favoured by the pope, was soon submitted',\n",
       " 'to by the english, who wanted leaders, and had been of late much',\n",
       " 'accustomed to usurpation and conquest. edwin and morcar, the earls of',\n",
       " 'mercia and northumbria--',\n",
       " 'ugh! said the lory, with a shiver.',\n",
       " 'i beg your pardon! said the mouse, frowning, but very politely: did',\n",
       " 'you speak?',\n",
       " 'not i! said the lory hastily.',\n",
       " 'i thought you did, said the mouse. --i proceed. edwin and morcar,',\n",
       " 'the earls of mercia and northumbria, declared for him: and even stigand,',\n",
       " 'the patriotic archbishop of canterbury, found it advisable--',\n",
       " 'found what? said the duck.',\n",
       " 'found it, the mouse replied rather crossly: of course you know what',\n",
       " 'it means.',\n",
       " 'i know what it means well enough, when i find a thing, said the',\n",
       " 'duck: its generally a frog or a worm. the question is, what did the',\n",
       " 'archbishop find?',\n",
       " 'the mouse did not notice this question, but hurriedly went on, --found',\n",
       " 'it advisable to go with edgar atheling to meet william and offer him the',\n",
       " 'crown. williams conduct at first was moderate. but the insolence of his',\n",
       " 'normans-- how are you getting on now, my dear? it continued, turning',\n",
       " 'to alice as it spoke.',\n",
       " 'as wet as ever, said alice in a melancholy tone: it doesnt seem to',\n",
       " 'dry me at all.',\n",
       " 'in that case, said the dodo solemnly, rising to its feet, i move',\n",
       " 'that the meeting adjourn, for the immediate adoption of more energetic',\n",
       " 'remedies--',\n",
       " 'speak english! said the eaglet. i dont know the meaning of half',\n",
       " 'those long words, and, whats more, i dont believe you do either! and',\n",
       " 'the eaglet bent down its head to hide a smile: some of the other birds',\n",
       " 'tittered audibly.',\n",
       " 'what i was going to say, said the dodo in an offended tone, was, that',\n",
       " 'the best thing to get us dry would be a caucus-race.',\n",
       " 'what is a caucus-race? said alice; not that she wanted much to know,',\n",
       " 'but the dodo had paused as if it thought that somebody ought to speak,',\n",
       " 'and no one else seemed inclined to say anything.',\n",
       " 'why, said the dodo, the best way to explain it is to do it. (and, as',\n",
       " 'you might like to try the thing yourself, some winter day, i will tell',\n",
       " 'you how the dodo managed it.)',\n",
       " 'first it marked out a race-course, in a sort of circle, [the exact',\n",
       " 'shape doesnt matter, it said,) and then all the party were placed',\n",
       " 'along the course, here and there. there was no one, two, three, and',\n",
       " 'away, but they began running when they liked, and left off when they',\n",
       " 'liked, so that it was not easy to know when the race was over. however,',\n",
       " 'when they had been running half an hour or so, and were quite dry again,',\n",
       " 'the dodo suddenly called out the race is over! and they all crowded',\n",
       " 'round it, panting, and asking, but who has won?',\n",
       " 'this question the dodo could not answer without a great deal of thought,',\n",
       " 'and it sat for a long time with one finger pressed upon its forehead',\n",
       " '(the position in which you usually see shakespeare, in the pictures',\n",
       " 'of him), while the rest waited in silence. at last the dodo said,',\n",
       " 'everybody has won, and all must have prizes.',\n",
       " 'but who is to give the prizes? quite a chorus of voices asked.',\n",
       " 'why, she, of course, said the dodo, pointing to alice with one finger;',\n",
       " 'and the whole party at once crowded round her, calling out in a confused',\n",
       " 'way, prizes! prizes!',\n",
       " 'alice had no idea what to do, and in despair she put her hand in her',\n",
       " 'pocket, and pulled out a box of comfits, (luckily the salt water had',\n",
       " 'not got into it), and handed them round as prizes. there was exactly one',\n",
       " 'a-piece all round.',\n",
       " 'but she must have a prize herself, you know, said the mouse.',\n",
       " 'of course, the dodo replied very gravely. what else have you got in',\n",
       " 'your pocket? he went on, turning to alice.',\n",
       " 'only a thimble, said alice sadly.',\n",
       " 'hand it over here, said the dodo.',\n",
       " 'then they all crowded round her once more, while the dodo solemnly',\n",
       " 'presented the thimble, saying we beg your acceptance of this elegant',\n",
       " 'thimble; and, when it had finished this short speech, they all cheered.',\n",
       " 'alice thought the whole thing very absurd, but they all looked so grave',\n",
       " 'that she did not dare to laugh; and, as she could not think of anything',\n",
       " 'to say, she simply bowed, and took the thimble, looking as solemn as she',\n",
       " 'could.',\n",
       " 'the next thing was to eat the comfits: this caused some noise and',\n",
       " 'confusion, as the large birds complained that they could not taste',\n",
       " 'theirs, and the small ones choked and had to be patted on the back.',\n",
       " 'however, it was over at last, and they sat down again in a ring, and',\n",
       " 'begged the mouse to tell them something more.',\n",
       " 'you promised to tell me your history, you know, said alice, and why',\n",
       " 'it is you hate--c and d, she added in a whisper, half afraid that it',\n",
       " 'would be offended again.',\n",
       " 'mine is a long and a sad tale! said the mouse, turning to alice, and',\n",
       " 'sighing.',\n",
       " 'it is a long tail, certainly, said alice, looking down with wonder at',\n",
       " 'the mouses tail; but why do you call it sad? and she kept on puzzling',\n",
       " 'about it while the mouse was speaking, so that her idea of the tale was',\n",
       " 'something like this:--',\n",
       " 'fury said to a',\n",
       " 'mouse, that he',\n",
       " 'met in the',\n",
       " 'house,',\n",
       " 'let us',\n",
       " 'both go to',\n",
       " 'law: i will',\n",
       " 'prosecute',\n",
       " 'you.--come,',\n",
       " 'ill take no',\n",
       " 'denial; we',\n",
       " 'must have a',\n",
       " 'trial: for',\n",
       " 'really this',\n",
       " 'morning ive',\n",
       " 'nothing',\n",
       " 'to do.',\n",
       " 'said the',\n",
       " 'mouse to the',\n",
       " 'cur, such',\n",
       " 'a trial,',\n",
       " 'dear sir,',\n",
       " 'with',\n",
       " 'no jury',\n",
       " 'or judge,',\n",
       " 'would be',\n",
       " 'wasting',\n",
       " 'our',\n",
       " 'breath.',\n",
       " 'ill be',\n",
       " 'judge, ill',\n",
       " 'be jury,',\n",
       " 'said',\n",
       " 'cunning',\n",
       " 'old fury:',\n",
       " 'ill',\n",
       " 'try the',\n",
       " 'whole',\n",
       " 'cause,',\n",
       " 'and',\n",
       " 'condemn',\n",
       " 'you',\n",
       " 'to',\n",
       " 'death.',\n",
       " 'you are not attending! said the mouse to alice severely. what are you',\n",
       " 'thinking of?',\n",
       " 'i beg your pardon, said alice very humbly: you had got to the fifth',\n",
       " 'bend, i think?',\n",
       " 'i had not! cried the mouse, sharply and very angrily.',\n",
       " 'a knot! said alice, always ready to make herself useful, and looking',\n",
       " 'anxiously about her. oh, do let me help to undo it!',\n",
       " 'i shall do nothing of the sort, said the mouse, getting up and walking',\n",
       " 'away. you insult me by talking such nonsense!',\n",
       " 'i didnt mean it! pleaded poor alice. but youre so easily offended,',\n",
       " 'you know!',\n",
       " 'the mouse only growled in reply.',\n",
       " 'please come back and finish your story! alice called after it; and the',\n",
       " 'others all joined in chorus, yes, please do! but the mouse only shook',\n",
       " 'its head impatiently, and walked a little quicker.',\n",
       " 'what a pity it wouldnt stay! sighed the lory, as soon as it was quite',\n",
       " 'out of sight; and an old crab took the opportunity of saying to her',\n",
       " 'daughter ah, my dear! let this be a lesson to you never to lose',\n",
       " 'your temper! hold your tongue, ma! said the young crab, a little',\n",
       " 'snappishly. youre enough to try the patience of an oyster!',\n",
       " 'i wish i had our dinah here, i know i do! said alice aloud, addressing',\n",
       " 'nobody in particular. shed soon fetch it back!',\n",
       " 'and who is dinah, if i might venture to ask the question? said the',\n",
       " 'lory.',\n",
       " 'alice replied eagerly, for she was always ready to talk about her pet:',\n",
       " 'dinahs our cat. and shes such a capital one for catching mice you',\n",
       " 'cant think! and oh, i wish you could see her after the birds! why,',\n",
       " 'shell eat a little bird as soon as look at it!',\n",
       " 'this speech caused a remarkable sensation among the party. some of the',\n",
       " 'birds hurried off at once: one old magpie began wrapping itself up very',\n",
       " 'carefully, remarking, i really must be getting home; the night-air',\n",
       " 'doesnt suit my throat! and a canary called out in a trembling voice to',\n",
       " 'its children, come away, my dears! its high time you were all in bed!',\n",
       " 'on various pretexts they all moved off, and alice was soon left alone.',\n",
       " 'i wish i hadnt mentioned dinah! she said to herself in a melancholy',\n",
       " 'tone. nobody seems to like her, down here, and im sure shes the best',\n",
       " 'cat in the world! oh, my dear dinah! i wonder if i shall ever see you',\n",
       " 'any more! and here poor alice began to cry again, for she felt very',\n",
       " 'lonely and low-spirited. in a little while, however, she again heard',\n",
       " 'a little pattering of footsteps in the distance, and she looked up',\n",
       " 'eagerly, half hoping that the mouse had changed his mind, and was coming',\n",
       " 'back to finish his story.',\n",
       " 'chapter iv. the rabbit sends in a little bill',\n",
       " 'it was the white rabbit, trotting slowly back again, and looking',\n",
       " 'anxiously about as it went, as if it had lost something; and she heard',\n",
       " 'it muttering to itself the duchess! the duchess! oh my dear paws! oh',\n",
       " 'my fur and whiskers! shell get me executed, as sure as ferrets are',\n",
       " 'ferrets! where can i have dropped them, i wonder? alice guessed in a',\n",
       " 'moment that it was looking for the fan and the pair of white kid gloves,',\n",
       " 'and she very good-naturedly began hunting about for them, but they were',\n",
       " 'nowhere to be seen--everything seemed to have changed since her swim in',\n",
       " 'the pool, and the great hall, with the glass table and the little door,',\n",
       " 'had vanished completely.',\n",
       " 'very soon the rabbit noticed alice, as she went hunting about, and',\n",
       " 'called out to her in an angry tone, why, mary ann, what are you doing',\n",
       " 'out here? run home this moment, and fetch me a pair of gloves and a fan!',\n",
       " 'quick, now! and alice was so much frightened that she ran off at once',\n",
       " 'in the direction it pointed to, without trying to explain the mistake it',\n",
       " 'had made.',\n",
       " 'he took me for his housemaid, she said to herself as she ran. how',\n",
       " 'surprised hell be when he finds out who i am! but id better take him',\n",
       " 'his fan and gloves--that is, if i can find them. as she said this, she',\n",
       " 'came upon a neat little house, on the door of which was a bright brass',\n",
       " 'plate with the name w. rabbit engraved upon it. she went in without',\n",
       " 'knocking, and hurried upstairs, in great fear lest she should meet the',\n",
       " 'real mary ann, and be turned out of the house before she had found the',\n",
       " 'fan and gloves.',\n",
       " 'how queer it seems, alice said to herself, to be going messages for',\n",
       " 'a rabbit! i suppose dinahll be sending me on messages next! and she',\n",
       " 'began fancying the sort of thing that would happen: miss alice! come',\n",
       " 'here directly, and get ready for your walk! coming in a minute,',\n",
       " 'nurse! but ive got to see that the mouse doesnt get out. only i dont',\n",
       " 'think, alice went on, that theyd let dinah stop in the house if it',\n",
       " 'began ordering people about like that!',\n",
       " 'by this time she had found her way into a tidy little room with a table',\n",
       " 'in the window, and on it (as she had hoped) a fan and two or three pairs',\n",
       " 'of tiny white kid gloves: she took up the fan and a pair of the gloves,',\n",
       " 'and was just going to leave the room, when her eye fell upon a little',\n",
       " 'bottle that stood near the looking-glass. there was no label this time',\n",
       " 'with the words drink me, but nevertheless she uncorked it and put it',\n",
       " 'to her lips. i know something interesting is sure to happen, she said',\n",
       " 'to herself, whenever i eat or drink anything; so ill just see what',\n",
       " 'this bottle does. i do hope itll make me grow large again, for really',\n",
       " 'im quite tired of being such a tiny little thing!',\n",
       " 'it did so indeed, and much sooner than she had expected: before she had',\n",
       " 'drunk half the bottle, she found her head pressing against the ceiling,',\n",
       " 'and had to stoop to save her neck from being broken. she hastily put',\n",
       " 'down the bottle, saying to herself thats quite enough--i hope i shant',\n",
       " 'grow any more--as it is, i cant get out at the door--i do wish i hadnt',\n",
       " 'drunk quite so much!',\n",
       " 'alas! it was too late to wish that! she went on growing, and growing,',\n",
       " 'and very soon had to kneel down on the floor: in another minute there',\n",
       " 'was not even room for this, and she tried the effect of lying down with',\n",
       " 'one elbow against the door, and the other arm curled round her head.',\n",
       " 'still she went on growing, and, as a last resource, she put one arm out',\n",
       " 'of the window, and one foot up the chimney, and said to herself now i',\n",
       " 'can do no more, whatever happens. what will become of me?',\n",
       " 'luckily for alice, the little magic bottle had now had its full effect,',\n",
       " 'and she grew no larger: still it was very uncomfortable, and, as there',\n",
       " 'seemed to be no sort of chance of her ever getting out of the room',\n",
       " 'again, no wonder she felt unhappy.',\n",
       " 'it was much pleasanter at home, thought poor alice, when one wasnt',\n",
       " 'always growing larger and smaller, and being ordered about by mice and',\n",
       " 'rabbits. i almost wish i hadnt gone down that rabbit-hole--and yet--and',\n",
       " 'yet--its rather curious, you know, this sort of life! i do wonder what',\n",
       " 'can have happened to me! when i used to read fairy-tales, i fancied that',\n",
       " 'kind of thing never happened, and now here i am in the middle of one!',\n",
       " 'there ought to be a book written about me, that there ought! and when i',\n",
       " 'grow up, ill write one--but im grown up now, she added in a sorrowful',\n",
       " 'tone; at least theres no room to grow up any more here.',\n",
       " 'but then, thought alice, shall i never get any older than i am',\n",
       " 'now? thatll be a comfort, one way--never to be an old woman--but',\n",
       " 'then--always to have lessons to learn! oh, i shouldnt like that!',\n",
       " 'oh, you foolish alice! she answered herself. how can you learn',\n",
       " 'lessons in here? why, theres hardly room for you, and no room at all',\n",
       " 'for any lesson-books!',\n",
       " 'and so she went on, taking first one side and then the other, and making',\n",
       " 'quite a conversation of it altogether; but after a few minutes she heard',\n",
       " 'a voice outside, and stopped to listen.',\n",
       " 'mary ann! mary ann! said the voice. fetch me my gloves this moment!',\n",
       " 'then came a little pattering of feet on the stairs. alice knew it was',\n",
       " 'the rabbit coming to look for her, and she trembled till she shook the',\n",
       " 'house, quite forgetting that she was now about a thousand times as large',\n",
       " 'as the rabbit, and had no reason to be afraid of it.',\n",
       " 'presently the rabbit came up to the door, and tried to open it; but, as',\n",
       " 'the door opened inwards, and alices elbow was pressed hard against it,',\n",
       " 'that attempt proved a failure. alice heard it say to itself then ill',\n",
       " 'go round and get in at the window.',\n",
       " 'that you wont thought alice, and, after waiting till she fancied',\n",
       " 'she heard the rabbit just under the window, she suddenly spread out her',\n",
       " 'hand, and made a snatch in the air. she did not get hold of anything,',\n",
       " 'but she heard a little shriek and a fall, and a crash of broken glass,',\n",
       " 'from which she concluded that it was just possible it had fallen into a',\n",
       " 'cucumber-frame, or something of the sort.',\n",
       " 'next came an angry voice--the rabbits--pat! pat! where are you? and',\n",
       " 'then a voice she had never heard before, sure then im here! digging',\n",
       " 'for apples, yer honour!',\n",
       " 'digging for apples, indeed! said the rabbit angrily. here! come and',\n",
       " 'help me out of this! (sounds of more broken glass.)',\n",
       " 'now tell me, pat, whats that in the window?',\n",
       " 'sure, its an arm, yer honour! (he pronounced it arrum.)',\n",
       " 'an arm, you goose! who ever saw one that size? why, it fills the whole',\n",
       " 'window!',\n",
       " 'sure, it does, yer honour: but its an arm for all that.',\n",
       " 'well, its got no business there, at any rate: go and take it away!',\n",
       " 'there was a long silence after this, and alice could only hear whispers',\n",
       " 'now and then; such as, sure, i dont like it, yer honour, at all, at',\n",
       " 'all! do as i tell you, you coward! and at last she spread out her',\n",
       " 'hand again, and made another snatch in the air. this time there were',\n",
       " 'two little shrieks, and more sounds of broken glass. what a number of',\n",
       " 'cucumber-frames there must be! thought alice. i wonder what theyll do',\n",
       " 'next! as for pulling me out of the window, i only wish they could! im',\n",
       " 'sure i dont want to stay in here any longer!',\n",
       " 'she waited for some time without hearing anything more: at last came a',\n",
       " 'rumbling of little cartwheels, and the sound of a good many voices',\n",
       " 'all talking together: she made out the words: wheres the other',\n",
       " 'ladder?--why, i hadnt to bring but one; bills got the other--bill!',\n",
       " 'fetch it here, lad!--here, put em up at this corner--no, tie em',\n",
       " 'together first--they dont reach half high enough yet--oh! theyll',\n",
       " 'do well enough; dont be particular--here, bill! catch hold of this',\n",
       " 'rope--will the roof bear?--mind that loose slate--oh, its coming',\n",
       " 'down! heads below! (a loud crash)--now, who did that?--it was bill, i',\n",
       " 'fancy--whos to go down the chimney?--nay, i shant! you do it!--that i',\n",
       " 'wont, then!--bills to go down--here, bill! the master says youre to',\n",
       " 'go down the chimney!',\n",
       " 'oh! so bills got to come down the chimney, has he? said alice to',\n",
       " 'herself. shy, they seem to put everything upon bill! i wouldnt be in',\n",
       " 'bills place for a good deal: this fireplace is narrow, to be sure; but',\n",
       " 'i think i can kick a little!',\n",
       " 'she drew her foot as far down the chimney as she could, and waited',\n",
       " 'till she heard a little animal (she couldnt guess of what sort it was)',\n",
       " 'scratching and scrambling about in the chimney close above her: then,',\n",
       " 'saying to herself this is bill, she gave one sharp kick, and waited to',\n",
       " 'see what would happen next.',\n",
       " 'the first thing she heard was a general chorus of there goes bill!',\n",
       " 'then the rabbits voice along--catch him, you by the hedge! then',\n",
       " 'silence, and then another confusion of voices--hold up his head--brandy',\n",
       " 'now--dont choke him--how was it, old fellow? what happened to you? tell',\n",
       " 'us all about it!',\n",
       " 'last came a little feeble, squeaking voice, [thats bill, thought',\n",
       " 'alice,) well, i hardly know--no more, thank ye; im better now--but im',\n",
       " 'a deal too flustered to tell you--all i know is, something comes at me',\n",
       " 'like a jack-in-the-box, and up i goes like a sky-rocket!',\n",
       " 'so you did, old fellow! said the others.',\n",
       " 'we must burn the house down! said the rabbits voice; and alice called',\n",
       " 'out as loud as she could, if you do. ill set dinah at you!',\n",
       " 'there was a dead silence instantly, and alice thought to herself, i',\n",
       " 'wonder what they will do next! if they had any sense, theyd take the',\n",
       " 'roof off. after a minute or two, they began moving about again, and',\n",
       " 'alice heard the rabbit say, a barrowful will do, to begin with.',\n",
       " 'a barrowful of what? thought alice; but she had not long to doubt,',\n",
       " 'for the next moment a shower of little pebbles came rattling in at the',\n",
       " 'window, and some of them hit her in the face. ill put a stop to this,',\n",
       " 'she said to herself, and shouted out, youd better not do that again!',\n",
       " 'which produced another dead silence.',\n",
       " 'alice noticed with some surprise that the pebbles were all turning into',\n",
       " 'little cakes as they lay on the floor, and a bright idea came into her',\n",
       " 'head. if i eat one of these cakes, she thought, its sure to make',\n",
       " 'some change in my size; and as it cant possibly make me larger, it must',\n",
       " 'make me smaller, i suppose.',\n",
       " 'so she swallowed one of the cakes, and was delighted to find that she',\n",
       " 'began shrinking directly. as soon as she was small enough to get through',\n",
       " 'the door, she ran out of the house, and found quite a crowd of little',\n",
       " 'animals and birds waiting outside. the poor little lizard, bill, was',\n",
       " 'in the middle, being held up by two guinea-pigs, who were giving it',\n",
       " 'something out of a bottle. they all made a rush at alice the moment she',\n",
       " 'appeared; but she ran off as hard as she could, and soon found herself',\n",
       " 'safe in a thick wood.',\n",
       " 'the first thing ive got to do, said alice to herself, as she wandered',\n",
       " 'about in the wood, is to grow to my right size again; and the second',\n",
       " 'thing is to find my way into that lovely garden. i think that will be',\n",
       " 'the best plan.',\n",
       " 'it sounded an excellent plan, no doubt, and very neatly and simply',\n",
       " 'arranged; the only difficulty was, that she had not the smallest idea',\n",
       " 'how to set about it; and while she was peering about anxiously among',\n",
       " 'the trees, a little sharp bark just over her head made her look up in a',\n",
       " 'great hurry.',\n",
       " 'an enormous puppy was looking down at her with large round eyes, and',\n",
       " 'feebly stretching out one paw, trying to touch her. poor little thing!',\n",
       " 'said alice, in a coaxing tone, and she tried hard to whistle to it; but',\n",
       " 'she was terribly frightened all the time at the thought that it might be',\n",
       " 'hungry, in which case it would be very likely to eat her up in spite of',\n",
       " 'all her coaxing.',\n",
       " 'hardly knowing what she did, she picked up a little bit of stick, and',\n",
       " 'held it out to the puppy; whereupon the puppy jumped into the air off',\n",
       " 'all its feet at once, with a yelp of delight, and rushed at the stick,',\n",
       " 'and made believe to worry it; then alice dodged behind a great thistle,',\n",
       " 'to keep herself from being run over; and the moment she appeared on the',\n",
       " 'other side, the puppy made another rush at the stick, and tumbled head',\n",
       " 'over heels in its hurry to get hold of it; then alice, thinking it was',\n",
       " 'very like having a game of play with a cart-horse, and expecting every',\n",
       " 'moment to be trampled under its feet, ran round the thistle again; then',\n",
       " 'the puppy began a series of short charges at the stick, running a very',\n",
       " 'little way forwards each time and a long way back, and barking hoarsely',\n",
       " 'all the while, till at last it sat down a good way off, panting, with',\n",
       " 'its tongue hanging out of its mouth, and its great eyes half shut.',\n",
       " 'this seemed to alice a good opportunity for making her escape; so she',\n",
       " 'set off at once, and ran till she was quite tired and out of breath, and',\n",
       " 'till the puppys bark sounded quite faint in the distance.',\n",
       " 'and yet what a dear little puppy it was! said alice, as she leant',\n",
       " 'against a buttercup to rest herself, and fanned herself with one of the',\n",
       " 'leaves: i should have liked teaching it tricks very much, if--if id',\n",
       " 'only been the right size to do it! oh dear! id nearly forgotten that',\n",
       " 'ive got to grow up again! let me see--how is it to be managed? i',\n",
       " 'suppose i ought to eat or drink something or other; but the great',\n",
       " 'question is, what?',\n",
       " 'the great question certainly was, what? alice looked all round her at',\n",
       " 'the flowers and the blades of grass, but she did not see anything that',\n",
       " 'looked like the right thing to eat or drink under the circumstances.',\n",
       " 'there was a large mushroom growing near her, about the same height as',\n",
       " 'herself; and when she had looked under it, and on both sides of it, and',\n",
       " 'behind it, it occurred to her that she might as well look and see what',\n",
       " 'was on the top of it.',\n",
       " 'she stretched herself up on tiptoe, and peeped over the edge of the',\n",
       " 'mushroom, and her eyes immediately met those of a large caterpillar,',\n",
       " 'that was sitting on the top with its arms folded, quietly smoking a long',\n",
       " 'hookah, and taking not the smallest notice of her or of anything else.',\n",
       " 'chapter v. advice from a caterpillar',\n",
       " 'the caterpillar and alice looked at each other for some time in silence:',\n",
       " 'at last the caterpillar took the hookah out of its mouth, and addressed',\n",
       " 'her in a languid, sleepy voice.',\n",
       " 'who are you? said the caterpillar.',\n",
       " 'this was not an encouraging opening for a conversation. alice replied,',\n",
       " 'rather shyly, i--i hardly know, sir, just at present--at least i know',\n",
       " 'who i was when i got up this morning, but i think i must have been',\n",
       " 'changed several times since then.',\n",
       " 'what do you mean by that? said the caterpillar sternly. explain',\n",
       " 'yourself!',\n",
       " 'i cant explain myself, im afraid, sir said alice, because im not',\n",
       " 'myself, you see.',\n",
       " 'i dont see, said the caterpillar.',\n",
       " 'im afraid i cant put it more clearly, alice replied very politely,',\n",
       " 'for i cant understand it myself to begin with; and being so many',\n",
       " 'different sizes in a day is very confusing.',\n",
       " 'it isnt, said the caterpillar.',\n",
       " 'well, perhaps you havent found it so yet, said alice; but when you',\n",
       " 'have to turn into a chrysalis--you will some day, you know--and then',\n",
       " 'after that into a butterfly, i should think youll feel it a little',\n",
       " 'queer, wont you?',\n",
       " 'not a bit, said the caterpillar.',\n",
       " 'well, perhaps your feelings may be different, said alice; all i know',\n",
       " 'is, it would feel very queer to me.',\n",
       " 'you! said the caterpillar contemptuously. who are you?',\n",
       " 'which brought them back again to the beginning of the conversation.',\n",
       " 'alice felt a little irritated at the caterpillars making such very',\n",
       " 'short remarks, and she drew herself up and said, very gravely, i think,',\n",
       " 'you ought to tell me who you are, first.',\n",
       " 'why? said the caterpillar.',\n",
       " 'here was another puzzling question; and as alice could not think of any',\n",
       " 'good reason, and as the caterpillar seemed to be in a very unpleasant',\n",
       " 'state of mind, she turned away.',\n",
       " 'come back! the caterpillar called after her. ive something important',\n",
       " 'to say!',\n",
       " 'this sounded promising, certainly: alice turned and came back again.',\n",
       " 'keep your temper, said the caterpillar.',\n",
       " 'is that all? said alice, swallowing down her anger as well as she',\n",
       " 'could.',\n",
       " 'no, said the caterpillar.',\n",
       " 'alice thought she might as well wait, as she had nothing else to do, and',\n",
       " 'perhaps after all it might tell her something worth hearing. for some',\n",
       " 'minutes it puffed away without speaking, but at last it unfolded its',\n",
       " 'arms, took the hookah out of its mouth again, and said, so you think',\n",
       " 'youre changed, do you?',\n",
       " 'im afraid i am, sir, said alice; i cant remember things as i',\n",
       " 'used--and i dont keep the same size for ten minutes together!',\n",
       " 'cant remember what things? said the caterpillar.',\n",
       " 'well, ive tried to say how doth the little busy bee, but it all came',\n",
       " 'different! alice replied in a very melancholy voice.',\n",
       " 'repeat, you are old, father william, said the caterpillar.',\n",
       " 'alice folded her hands, and began:--',\n",
       " 'you are old, father william, the young man said,',\n",
       " 'and your hair has become very white;',\n",
       " 'and yet you incessantly stand on your head--',\n",
       " 'do you think, at your age, it is right?',\n",
       " 'in my youth, father william replied to his son,',\n",
       " 'i feared it might injure the brain;',\n",
       " 'but, now that im perfectly sure i have none,',\n",
       " 'why, i do it again and again.',\n",
       " 'you are old, said the youth, as i mentioned before,',\n",
       " 'and have grown most uncommonly fat;',\n",
       " 'yet you turned a back-somersault in at the door--',\n",
       " 'pray, what is the reason of that?',\n",
       " 'in my youth, said the sage, as he shook his grey locks,',\n",
       " 'i kept all my limbs very supple',\n",
       " 'by the use of this ointment--one shilling the box--',\n",
       " 'allow me to sell you a couple?',\n",
       " 'you are old, said the youth, and your jaws are too weak',\n",
       " 'for anything tougher than suet;',\n",
       " 'yet you finished the goose, with the bones and the beak--',\n",
       " 'pray how did you manage to do it?',\n",
       " 'in my youth, said his father, i took to the law,',\n",
       " 'and argued each case with my wife;',\n",
       " 'and the muscular strength, which it gave to my jaw,',\n",
       " 'has lasted the rest of my life.',\n",
       " 'you are old, said the youth, one would hardly suppose',\n",
       " 'that your eye was as steady as ever;',\n",
       " 'yet you balanced an eel on the end of your nose--',\n",
       " 'what made you so awfully clever?',\n",
       " 'i have answered three questions, and that is enough,',\n",
       " 'said his father; dont give yourself airs!',\n",
       " 'do you think i can listen all day to such stuff?',\n",
       " 'be off, or ill kick you down stairs!',\n",
       " 'that is not said right, said the caterpillar.',\n",
       " 'not quite right, im afraid, said alice, timidly; some of the words',\n",
       " 'have got altered.',\n",
       " 'it is wrong from beginning to end, said the caterpillar decidedly, and',\n",
       " 'there was silence for some minutes.',\n",
       " 'the caterpillar was the first to speak.',\n",
       " 'what size do you want to be? it asked.',\n",
       " 'oh, im not particular as to size, alice hastily replied; only one',\n",
       " 'doesnt like changing so often, you know.',\n",
       " 'i dont know, said the caterpillar.',\n",
       " 'alice said nothing: she had never been so much contradicted in her life',\n",
       " 'before, and she felt that she was losing her temper.',\n",
       " 'are you content now? said the caterpillar.',\n",
       " 'well, i should like to be a little larger, sir, if you wouldnt mind,',\n",
       " 'said alice: three inches is such a wretched height to be.',\n",
       " 'it is a very good height indeed! said the caterpillar angrily, rearing',\n",
       " 'itself upright as it spoke (it was exactly three inches high).',\n",
       " 'but im not used to it! pleaded poor alice in a piteous tone. and',\n",
       " 'she thought of herself, i wish the creatures wouldnt be so easily',\n",
       " 'offended!',\n",
       " 'youll get used to it in time, said the caterpillar; and it put the',\n",
       " 'hookah into its mouth and began smoking again.',\n",
       " 'this time alice waited patiently until it chose to speak again. in',\n",
       " 'a minute or two the caterpillar took the hookah out of its mouth',\n",
       " 'and yawned once or twice, and shook itself. then it got down off the',\n",
       " 'mushroom, and crawled away in the grass, merely remarking as it went,',\n",
       " 'one side will make you grow taller, and the other side will make you',\n",
       " 'grow shorter.',\n",
       " 'one side of what? the other side of what? thought alice to herself.',\n",
       " 'of the mushroom, said the caterpillar, just as if she had asked it',\n",
       " 'aloud; and in another moment it was out of sight.',\n",
       " 'alice remained looking thoughtfully at the mushroom for a minute, trying',\n",
       " 'to make out which were the two sides of it; and as it was perfectly',\n",
       " 'round, she found this a very difficult question. however, at last she',\n",
       " 'stretched her arms round it as far as they would go, and broke off a bit',\n",
       " 'of the edge with each hand.',\n",
       " 'and now which is which? she said to herself, and nibbled a little of',\n",
       " 'the right-hand bit to try the effect: the next moment she felt a violent',\n",
       " 'blow underneath her chin: it had struck her foot!',\n",
       " 'she was a good deal frightened by this very sudden change, but she felt',\n",
       " 'that there was no time to be lost, as she was shrinking rapidly; so she',\n",
       " 'set to work at once to eat some of the other bit. her chin was pressed',\n",
       " 'so closely against her foot, that there was hardly room to open her',\n",
       " 'mouth; but she did it at last, and managed to swallow a morsel of the',\n",
       " 'lefthand bit.',\n",
       " '*    *    *    *    *    *    *',\n",
       " '*    *    *    *    *    *',\n",
       " '*    *    *    *    *    *    *',\n",
       " 'come, my heads free at last! said alice in a tone of delight, which',\n",
       " 'changed into alarm in another moment, when she found that her shoulders',\n",
       " 'were nowhere to be found: all she could see, when she looked down, was',\n",
       " 'an immense length of neck, which seemed to rise like a stalk out of a',\n",
       " 'sea of green leaves that lay far below her.',\n",
       " 'what can all that green stuff be? said alice. and where have my',\n",
       " 'shoulders got to? and oh, my poor hands, how is it i cant see you?',\n",
       " 'she was moving them about as she spoke, but no result seemed to follow,',\n",
       " 'except a little shaking among the distant green leaves.',\n",
       " 'as there seemed to be no chance of getting her hands up to her head, she',\n",
       " 'tried to get her head down to them, and was delighted to find that her',\n",
       " 'neck would bend about easily in any direction, like a serpent. she had',\n",
       " 'just succeeded in curving it down into a graceful zigzag, and was going',\n",
       " 'to dive in among the leaves, which she found to be nothing but the tops',\n",
       " 'of the trees under which she had been wandering, when a sharp hiss made',\n",
       " 'her draw back in a hurry: a large pigeon had flown into her face, and',\n",
       " 'was beating her violently with its wings.',\n",
       " 'serpent! screamed the pigeon.',\n",
       " 'im not a serpent! said alice indignantly. let me alone!',\n",
       " 'serpent, i say again! repeated the pigeon, but in a more subdued tone,',\n",
       " 'and added with a kind of sob, ive tried every way, and nothing seems',\n",
       " 'to suit them!',\n",
       " 'i havent the least idea what youre talking about, said alice.',\n",
       " 'ive tried the roots of trees, and ive tried banks, and ive tried',\n",
       " 'hedges, the pigeon went on, without attending to her; but those',\n",
       " 'serpents! theres no pleasing them!',\n",
       " 'alice was more and more puzzled, but she thought there was no use in',\n",
       " 'saying anything more till the pigeon had finished.',\n",
       " 'as if it wasnt trouble enough hatching the eggs, said the pigeon;',\n",
       " 'but i must be on the look-out for serpents night and day! why, i',\n",
       " 'havent had a wink of sleep these three weeks!',\n",
       " 'im very sorry youve been annoyed, said alice, who was beginning to',\n",
       " 'see its meaning.',\n",
       " 'and just as id taken the highest tree in the wood, continued the',\n",
       " 'pigeon, raising its voice to a shriek, and just as i was thinking i',\n",
       " 'should be free of them at last, they must needs come wriggling down from',\n",
       " 'the sky! ugh, serpent!',\n",
       " 'but im not a serpent, i tell you! said alice. im a--im a--',\n",
       " 'well! what are you? said the pigeon. i can see youre trying to',\n",
       " 'invent something!',\n",
       " 'i--im a little girl, said alice, rather doubtfully, as she remembered',\n",
       " 'the number of changes she had gone through that day.',\n",
       " 'a likely story indeed! said the pigeon in a tone of the deepest',\n",
       " 'contempt. ive seen a good many little girls in my time, but never one',\n",
       " 'with such a neck as that! no, no! youre a serpent; and theres no use',\n",
       " 'denying it. i suppose youll be telling me next that you never tasted an',\n",
       " 'egg!',\n",
       " 'i have tasted eggs, certainly, said alice, who was a very truthful',\n",
       " 'child; but little girls eat eggs quite as much as serpents do, you',\n",
       " 'know.',\n",
       " 'i dont believe it, said the pigeon; but if they do, why then theyre',\n",
       " 'a kind of serpent, thats all i can say.',\n",
       " 'this was such a new idea to alice, that she was quite silent for a',\n",
       " 'minute or two, which gave the pigeon the opportunity of adding, youre',\n",
       " 'looking for eggs, i know that well enough; and what does it matter to me',\n",
       " 'whether youre a little girl or a serpent?',\n",
       " 'it matters a good deal to me, said alice hastily; but im not looking',\n",
       " 'for eggs, as it happens; and if i was, i shouldnt want yours: i dont',\n",
       " 'like them raw.',\n",
       " 'well, be off, then! said the pigeon in a sulky tone, as it settled',\n",
       " 'down again into its nest. alice crouched down among the trees as well as',\n",
       " 'she could, for her neck kept getting entangled among the branches, and',\n",
       " 'every now and then she had to stop and untwist it. after a while she',\n",
       " 'remembered that she still held the pieces of mushroom in her hands, and',\n",
       " 'she set to work very carefully, nibbling first at one and then at the',\n",
       " 'other, and growing sometimes taller and sometimes shorter, until she had',\n",
       " 'succeeded in bringing herself down to her usual height.',\n",
       " 'it was so long since she had been anything near the right size, that it',\n",
       " 'felt quite strange at first; but she got used to it in a few minutes,',\n",
       " 'and began talking to herself, as usual. come, theres half my plan done',\n",
       " 'now! how puzzling all these changes are! im never sure what im going',\n",
       " 'to be, from one minute to another! however, ive got back to my right',\n",
       " 'size: the next thing is, to get into that beautiful garden--how is that',\n",
       " 'to be done, i wonder? as she said this, she came suddenly upon an open',\n",
       " 'place, with a little house in it about four feet high. whoever lives',\n",
       " 'there, thought alice, itll never do to come upon them this size: why,',\n",
       " 'i should frighten them out of their wits! so she began nibbling at the',\n",
       " 'righthand bit again, and did not venture to go near the house till she',\n",
       " 'had brought herself down to nine inches high.',\n",
       " 'chapter vi. pig and pepper',\n",
       " 'for a minute or two she stood looking at the house, and wondering what',\n",
       " 'to do next, when suddenly a footman in livery came running out of the',\n",
       " 'wood--(she considered him to be a footman because he was in livery:',\n",
       " 'otherwise, judging by his face only, she would have called him a',\n",
       " 'fish)--and rapped loudly at the door with his knuckles. it was opened',\n",
       " 'by another footman in livery, with a round face, and large eyes like a',\n",
       " 'frog; and both footmen, alice noticed, had powdered hair that curled all',\n",
       " 'over their heads. she felt very curious to know what it was all about,',\n",
       " 'and crept a little way out of the wood to listen.',\n",
       " 'the fish-footman began by producing from under his arm a great letter,',\n",
       " 'nearly as large as himself, and this he handed over to the other,',\n",
       " 'saying, in a solemn tone, for the duchess. an invitation from the queen',\n",
       " 'to play croquet. the frog-footman repeated, in the same solemn tone,',\n",
       " 'only changing the order of the words a little, from the queen. an',\n",
       " 'invitation for the duchess to play croquet.',\n",
       " 'then they both bowed low, and their curls got entangled together.',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project gutenbergs alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org title: alices adventures in wonderland author: lewis carroll posting date: june 25, 2008 [ebook #11] release date: march, 1994 last updated: october 6, 2016 language: english character set encoding: utf-8 *** start of this project gutenberg ebook alices adventures in wonderland *** alices adventures in wonderland lewis carroll the millennium fulcrum edition 3.0 chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, and what is the use of a book, thought alice without pictures or conversations? so she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a white rabbit with pink eyes ran close by her. there was nothing so very remarkable in that; nor did alice think it so very much out of the way to hear the rabbit say to itself, oh dear! oh dear! i shall be late! (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge. in another moment down went alice after it, never once considering how in the world she was to get out again. the rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that alice had not a moment to think about stopping herself before she found herself falling down a very deep well. either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next. first, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs. she took down a jar from one of the shelves as she passed; it was labelled orange marmalade, but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it. well! thought alice to herself, after such a fall as this, i shall think nothing of tumbling down stairs! how brave theyll all think me at home! why, i wouldnt say anything about it, even if i fell off the top of the house! (which was very likely true.) down, down, down. would the fall never come to an end! i wonder how many miles ive fallen by this time? she said aloud. i must be getting somewhere near the centre of the earth. let me see: that would be four thousand miles down, i think-- (for, you see, alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a very good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) --yes, thats about the right distance--but then i wonder what latitude or longitude ive got to? (alice had no idea what latitude was, or longitude either, but thought they were nice grand words to say.) presently she began again. i wonder if i shall fall right through the earth! how funny itll seem to come out among the people that walk with their heads downward! the antipathies, i think-- (she was rather glad there was no one listening, this time, as it didnt sound at all the right word) --but i shall have to ask them what the name of the country is, you know. please, maam, is this new zealand or australia? (and she tried to curtsey as she spoke--fancy curtseying as youre falling through the air! do you think you could manage it?) and what an ignorant little girl shell think me for asking! no, itll never do to ask: perhaps i shall see it written up somewhere. down, down, down. there was nothing else to do, so alice soon began talking again. dinahll miss me very much to-night, i should think! (dinah was the cat.) i hope theyll remember her saucer of milk at tea-time. dinah my dear! i wish you were down here with me! there are no mice in the air, im afraid, but you might catch a bat, and thats very like a mouse, you know. but do cats eat bats, i wonder? and here alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, do cats eat bats? do cats eat bats? and sometimes, do bats eat cats? for, you see, as she couldnt answer either question, it didnt much matter which way she put it. she felt that she was dozing off, and had just begun to dream that she was walking hand in hand with dinah, and saying to her very earnestly, now, dinah, tell me the truth: did you ever eat a bat? when suddenly, thump! thump! down she came upon a heap of sticks and dry leaves, and the fall was over. alice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the white rabbit was still in sight, hurrying down it. there was not a moment to be lost: away went alice like the wind, and was just in time to hear it say, as it turned a corner, oh my ears and whiskers, how late its getting! she was close behind it when she turned the corner, but the rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof. there were doors all round the hall, but they were all locked; and when alice had been all the way down one side and up the other, trying every door, she walked sadly down the middle, wondering how she was ever to get out again. suddenly she came upon a little three-legged table, all made of solid glass; there was nothing on it except a tiny golden key, and alices first thought was that it might belong to one of the doors of the hall; but, alas! either the locks were too large, or the key was too small, but at any rate it would not open any of them. however, on the second time round, she came upon a low curtain she had not noticed before, and behind it was a little door about fifteen inches high: she tried the little golden key in the lock, and to her great delight it fitted! alice opened the door and found that it led into a small passage, not much larger than a rat-hole: she knelt down and looked along the passage into the loveliest garden you ever saw. how she longed to get out of that dark hall, and wander about among those beds of bright flowers and those cool fountains, but she could not even get her head through the doorway; and even if my head would go through, thought poor alice, it would be of very little use without my shoulders. oh, how i wish i could shut up like a telescope! i think i could, if i only knew how to begin. for, you see, so many out-of-the-way things had happened lately, that alice had begun to think that very few things indeed were really impossible. there seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, [which certainly was not here before, said alice,) and round the neck of the bottle was a paper label, with the words drink me beautifully printed on it in large letters. it was all very well to say drink me, but the wise little alice was not going to do that in a hurry. no, ill look first, she said, and see whether its marked poison or not; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they would not remember the simple rules their friends had taught them: such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger very deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked poison, it is almost certain to disagree with you, sooner or later. however, this bottle was not marked poison, so alice ventured to taste it, and finding it very nice, (it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot buttered toast,) she very soon finished it off. *    *    *    *    *    *    * *    *    *    *    *    * *    *    *    *    *    *    * what a curious feeling! said alice; i must be shutting up like a telescope. and so it was indeed: she was now only ten inches high, and her face brightened up at the thought that she was now the right size for going through the little door into that lovely garden. first, however, she waited for a few minutes to see if she was going to shrink any further: she felt a little nervous about this; for it might end, you know, said alice to herself, in my going out altogether, like a candle. i wonder what i should be like then? and she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing. after a while, finding that nothing more happened, she decided on going into the garden at once; but, alas for poor alice! when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried. come, theres no use in crying like that! said alice to herself, rather sharply; i advise you to leave off this minute! she generally gave herself very good advice, (though she very seldom followed it), and sometimes she scolded herself so severely as to bring tears into her eyes; and once she remembered trying to box her own ears for having cheated herself in a game of croquet she was playing against herself, for this curious child was very fond of pretending to be two people. but its no use now, thought poor alice, to pretend to be two people! why, theres hardly enough of me left to make one respectable person! soon her eye fell on a little glass box that was lying under the table: she opened it, and found in it a very small cake, on which the words eat me were beautifully marked in currants. well, ill eat it, said alice, and if it makes me grow larger, i can reach the key; and if it makes me grow smaller, i can creep under the door; so either way ill get into the garden, and i dont care which happens! she ate a little bit, and said anxiously to herself, which way? which way?, holding her hand on the top of her head to feel which way it was growing, and she was quite surprised to find that she remained the same size: to be sure, this generally happens when one eats cake, but alice had got so much into the way of expecting nothing but out-of-the-way things to happen, that it seemed quite dull and stupid for life to go on in the common way. so she set to work, and very soon finished off the cake. *    *    *    *    *    *    * *    *    *    *    *    * *    *    *    *    *    *    * chapter ii. the pool of tears curiouser and curiouser! cried alice (she was so much surprised, that for the moment she quite forgot how to speak good english); now im opening out like the largest telescope that ever was! good-bye, feet! (for when she looked down at her feet, they seemed to be almost out of sight, they were getting so far off). oh, my poor little feet, i wonder who will put on your shoes and stockings for you now, dears? im sure _i_ shant be able! i shall be a great deal too far off to trouble myself about you: you must manage the best way you can;--but i must be kind to them, thought alice, or perhaps they wont walk the way i want to go! let me see: ill give them a new pair of boots every christmas. and she went on planning to herself how she would manage it. they must go by the carrier, she thought; and how funny itll seem, sending presents to ones own feet! and how odd the directions will look! alices right foot, esq. hearthrug, near the fender, (with alices love). oh dear, what nonsense im talking! just then her head struck against the roof of the hall: in fact she was now more than nine feet high, and she at once took up the little golden key and hurried off to the garden door. poor alice! it was as much as she could do, lying down on one side, to look through into the garden with one eye; but to get through was more hopeless than ever: she sat down and began to cry again. you ought to be ashamed of yourself, said alice, a great girl like you, (she might well say this), to go on crying in this way! stop this moment, i tell you! but she went on all the same, shedding gallons of tears, until there was a large pool all round her, about four inches deep and reaching half down the hall. after a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. it was the white rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came, oh! the duchess, the duchess! oh! wont she be savage if ive kept her waiting! alice felt so desperate that she was ready to ask help of any one; so, when the rabbit came near her, she began, in a low, timid voice, if you please, sir-- the rabbit started violently, dropped the white kid gloves and the fan, and skurried away into the darkness as hard as he could go. alice took up the fan and gloves, and, as the hall was very hot, she kept fanning herself all the time she went on talking: dear, dear! how queer everything is to-day! and yesterday things went on just as usual. i wonder if ive been changed in the night? let me think: was i the same when i got up this morning? i almost think i can remember feeling a little different. but if im not the same, the next question is, who in the world am i? ah, thats the great puzzle! and she began thinking over all the children she knew that were of the same age as herself, to see if she could have been changed for any of them. im sure im not ada, she said, for her hair goes in such long ringlets, and mine doesnt go in ringlets at all; and im sure i cant be mabel, for i know all sorts of things, and she, oh! she knows such a very little! besides, shes she, and im i, and--oh dear, how puzzling it all is! ill try if i know all the things i used to know. let me see: four times five is twelve, and four times six is thirteen, and four times seven is--oh dear! i shall never get to twenty at that rate! however, the multiplication table doesnt signify: lets try geography. london is the capital of paris, and paris is the capital of rome, and rome--no, thats all wrong, im certain! i must have been changed for mabel! ill try and say how doth the little-- and she crossed her hands on her lap as if she were saying lessons, and began to repeat it, but her voice sounded hoarse and strange, and the words did not come the same as they used to do:-- how doth the little crocodile improve his shining tail, and pour the waters of the nile on every golden scale! how cheerfully he seems to grin, how neatly spread his claws, and welcome little fishes in with gently smiling jaws! im sure those are not the right words, said poor alice, and her eyes filled with tears again as she went on, i must be mabel after all, and i shall have to go and live in that poky little house, and have next to no toys to play with, and oh! ever so many lessons to learn! no, ive made up my mind about it; if im mabel, ill stay down here! itll be no use their putting their heads down and saying come up again, dear! i shall only look up and say who am i then? tell me that first, and then, if i like being that person, ill come up: if not, ill stay down here till im somebody else--but, oh dear! cried alice, with a sudden burst of tears, i do wish they would put their heads down! i am so very tired of being all alone here! as she said this she looked down at her hands, and was surprised to see that she had put on one of the rabbits little white kid gloves while she was talking. how can i have done that? she thought. i must be growing small again. she got up and went to the table to measure herself by it, and found that, as nearly as she could guess, she was now about two feet high, and was going on shrinking rapidly: she soon found out that the cause of this was the fan she was holding, and she dropped it hastily, just in time to avoid shrinking away altogether. that was a narrow escape! said alice, a good deal frightened at the sudden change, but very glad to find herself still in existence; and now for the garden! and she ran with all speed back to the little door: but, alas! the little door was shut again, and the little golden key was lying on the glass table as before, and things are worse than ever, thought the poor child, for i never was so small as this before, never! and i declare its too bad, that it is! as she said these words her foot slipped, and in another moment, splash! she was up to her chin in salt water. her first idea was that she had somehow fallen into the sea, and in that case i can go back by railway, she said to herself. (alice had been to the seaside once in her life, and had come to the general conclusion, that wherever you go to on the english coast you find a number of bathing machines in the sea, some children digging in the sand with wooden spades, then a row of lodging houses, and behind them a railway station.) however, she soon made out that she was in the pool of tears which she had wept when she was nine feet high. i wish i hadnt cried so much! said alice, as she swam about, trying to find her way out. i shall be punished for it now, i suppose, by being drowned in my own tears! that will be a queer thing, to be sure! however, everything is queer to-day. just then she heard something splashing about in the pool a little way off, and she swam nearer to make out what it was: at first she thought it must be a walrus or hippopotamus, but then she remembered how small she was now, and she soon made out that it was only a mouse that had slipped in like herself. would it be of any use, now, thought alice, to speak to this mouse? everything is so out-of-the-way down here, that i should think very likely it can talk: at any rate, theres no harm in trying. so she began: o mouse, do you know the way out of this pool? i am very tired of swimming about here, o mouse! (alice thought this must be the right way of speaking to a mouse: she had never done such a thing before, but she remembered having seen in her brothers latin grammar, a mouse--of a mouse--to a mouse--a mouse--o mouse!) the mouse looked at her rather inquisitively, and seemed to her to wink with one of its little eyes, but it said nothing. perhaps it doesnt understand english, thought alice; i daresay its a french mouse, come over with william the conqueror. (for, with all her knowledge of history, alice had no very clear notion how long ago anything had happened.) so she began again: ou est ma chatte? which was the first sentence in her french lesson-book. the mouse gave a sudden leap out of the water, and seemed to quiver all over with fright. oh, i beg your pardon! cried alice hastily, afraid that she had hurt the poor animals feelings. i quite forgot you didnt like cats. not like cats! cried the mouse, in a shrill, passionate voice. would you like cats if you were me? well, perhaps not, said alice in a soothing tone: dont be angry about it. and yet i wish i could show you our cat dinah: i think youd take a fancy to cats if you could only see her. she is such a dear quiet thing, alice went on, half to herself, as she swam lazily about in the pool, and she sits purring so nicely by the fire, licking her paws and washing her face--and she is such a nice soft thing to nurse--and shes such a capital one for catching mice--oh, i beg your pardon! cried alice again, for this time the mouse was bristling all over, and she felt certain it must be really offended. we wont talk about her any more if youd rather not. we indeed! cried the mouse, who was trembling down to the end of his tail. as if i would talk on such a subject! our family always hated cats: nasty, low, vulgar things! dont let me hear the name again! i wont indeed! said alice, in a great hurry to change the subject of conversation. are you--are you fond--of--of dogs? the mouse did not answer, so alice went on eagerly: there is such a nice little dog near our house i should like to show you! a little bright-eyed terrier, you know, with oh, such long curly brown hair! and itll fetch things when you throw them, and itll sit up and beg for its dinner, and all sorts of things--i cant remember half of them--and it belongs to a farmer, you know, and he says its so useful, its worth a hundred pounds! he says it kills all the rats and--oh dear! cried alice in a sorrowful tone, im afraid ive offended it again! for the mouse was swimming away from her as hard as it could go, and making quite a commotion in the pool as it went. so she called softly after it, mouse dear! do come back again, and we wont talk about cats or dogs either, if you dont like them! when the mouse heard this, it turned round and swam slowly back to her: its face was quite pale (with passion, alice thought), and it said in a low trembling voice, let us get to the shore, and then ill tell you my history, and youll understand why it is i hate cats and dogs. it was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a duck and a dodo, a lory and an eaglet, and several other curious creatures. alice led the way, and the whole party swam to the shore. chapter iii. a caucus-race and a long tale they were indeed a queer-looking party that assembled on the bank--the birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable. the first question of course was, how to get dry again: they had a consultation about this, and after a few minutes it seemed quite natural to alice to find herself talking familiarly with them, as if she had known them all her life. indeed, she had quite a long argument with the lory, who at last turned sulky, and would only say, i am older than you, and must know better; and this alice would not allow without knowing how old it was, and, as the lory positively refused to tell its age, there was no more to be said. at last the mouse, who seemed to be a person of authority among them, called out, sit down, all of you, and listen to me! ill soon make you dry enough! they all sat down at once, in a large ring, with the mouse in the middle. alice kept her eyes anxiously fixed on it, for she felt sure she would catch a bad cold if she did not get dry very soon. ahem! said the mouse with an important air, are you all ready? this is the driest thing i know. silence all round, if you please! william the conqueror, whose cause was favoured by the pope, was soon submitted to by the english, who wanted leaders, and had been of late much accustomed to usurpation and conquest. edwin and morcar, the earls of mercia and northumbria-- ugh! said the lory, with a shiver. i beg your pardon! said the mouse, frowning, but very politely: did you speak? not i! said the lory hastily. i thought you did, said the mouse. --i proceed. edwin and morcar, the earls of mercia and northumbria, declared for him: and even stigand, the patriotic archbishop of canterbury, found it advisable-- found what? said the duck. found it, the mouse replied rather crossly: of course you know what it means. i know what it means well enough, when i find a thing, said the duck: its generally a frog or a worm. the question is, what did the archbishop find? the mouse did not notice this question, but hurriedly went on, --found it advisable to go with edgar atheling to meet william and offer him the crown. williams conduct at first was moderate. but the insolence of his normans-- how are you getting on now, my dear? it continued, turning to alice as it spoke. as wet as ever, said alice in a melancholy tone: it doesnt seem to dry me at all. in that case, said the dodo solemnly, rising to its feet, i move that the meeting adjourn, for the immediate adoption of more energetic remedies-- speak english! said the eaglet. i dont know the meaning of half those long words, and, whats more, i dont believe you do either! and the eaglet bent down its head to hide a smile: some of the other birds tittered audibly. what i was going to say, said the dodo in an offended tone, was, that the best thing to get us dry would be a caucus-race. what is a caucus-race? said alice; not that she wanted much to know, but the dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything. why, said the dodo, the best way to explain it is to do it. (and, as you might like to try the thing yourself, some winter day, i will tell you how the dodo managed it.) first it marked out a race-course, in a sort of circle, [the exact shape doesnt matter, it said,) and then all the party were placed along the course, here and there. there was no one, two, three, and away, but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. however, when they had been running half an hour or so, and were quite dry again, the dodo suddenly called out the race is over! and they all crowded round it, panting, and asking, but who has won? this question the dodo could not answer without a great deal of thought, and it sat for a long time with one finger pressed upon its forehead (the position in which you usually see shakespeare, in the pictures of him), while the rest waited in silence. at last the dodo said, everybody has won, and all must have prizes. but who is to give the prizes? quite a chorus of voices asked. why, she, of course, said the dodo, pointing to alice with one finger; and the whole party at once crowded round her, calling out in a confused way, prizes! prizes! alice had no idea what to do, and in despair she put her hand in her pocket, and pulled out a box of comfits, (luckily the salt water had not got into it), and handed them round as prizes. there was exactly one a-piece all round. but she must have a prize herself, you know, said the mouse. of course, the dodo replied very gravely. what else have you got in your pocket? he went on, turning to alice. only a thimble, said alice sadly. hand it over here, said the dodo. then they all crowded round her once more, while the dodo solemnly presented the thimble, saying we beg your acceptance of this elegant thimble; and, when it had finished this short speech, they all cheered. alice thought the whole thing very absurd, but they all looked so grave that she did not dare to laugh; and, as she could not think of anything to say, she simply bowed, and took the thimble, looking as solemn as she could. the next thing was to eat the comfits: this caused some noise and confusion, as the large birds complained that they could not taste theirs, and the small ones choked and had to be patted on the back. however, it was over at last, and they sat down again in a ring, and begged the mouse to tell them something more. you promised to tell me your history, you know, said alice, and why it is you hate--c and d, she added in a whisper, half afraid that it would be offended again. mine is a long and a sad tale! said the mouse, turning to alice, and sighing. it is a long tail, certainly, said alice, looking down with wonder at the mouses tail; but why do you call it sad? and she kept on puzzling about it while the mouse was speaking, so that her idea of the tale was something like this:-- fury said to a mouse, that he met in the house, let us both go to law: i will prosecute you.--come, ill take no denial; we must have a trial: for really this morning ive nothing to do. said the mouse to the cur, such a trial, dear sir, with no jury or judge, would be wasting our breath. ill be judge, ill be jury, said cunning old fury: ill try the whole cause, and condemn you to death. you are not attending! said the mouse to alice severely. what are you thinking of? i beg your pardon, said alice very humbly: you had got to the fifth bend, i think? i had not! cried the mouse, sharply and very angrily. a knot! said alice, always ready to make herself useful, and looking anxiously about her. oh, do let me help to undo it! i shall do nothing of the sort, said the mouse, getting up and walking away. you insult me by talking such nonsense! i didnt mean it! pleaded poor alice. but youre so easily offended, you know! the mouse only growled in reply. please come back and finish your story! alice called after it; and the others all joined in chorus, yes, please do! but the mouse only shook its head impatiently, and walked a little quicker. what a pity it wouldnt stay! sighed the lory, as soon as it was quite out of sight; and an old crab took the opportunity of saying to her daughter ah, my dear! let this be a lesson to you never to lose your temper! hold your tongue, ma! said the young crab, a little snappishly. youre enough to try the patience of an oyster! i wish i had our dinah here, i know i do! said alice aloud, addressing nobody in particular. shed soon fetch it back! and who is dinah, if i might venture to ask the question? said the lory. alice replied eagerly, for she was always ready to talk about her pet: dinahs our cat. and shes such a capital one for catching mice you cant think! and oh, i wish you could see her after the birds! why, shell eat a little bird as soon as look at it! this speech caused a remarkable sensation among the party. some of the birds hurried off at once: one old magpie began wrapping itself up very carefully, remarking, i really must be getting home; the night-air doesnt suit my throat! and a canary called out in a trembling voice to its children, come away, my dears! its high time you were all in bed! on various pretexts they all moved off, and alice was soon left alone. i wish i hadnt mentioned dinah! she said to herself in a melancholy tone. nobody seems to like her, down here, and im sure shes the best cat in the world! oh, my dear dinah! i wonder if i shall ever see you any more! and here poor alice began to cry again, for she felt very lonely and low-spirited. in a little while, however, she again heard a little pattering of footsteps in the distance, and she looked up eagerly, half hoping that the mouse had changed his mind, and was coming back to finish his story. chapter iv. the rabbit sends in a little bill it was the white rabbit, trotting slowly back again, and looking anxiously about as it went, as if it had lost something; and she heard it muttering to itself the duchess! the duchess! oh my dear paws! oh my fur and whiskers! shell get me executed, as sure as ferrets are ferrets! where can i have dropped them, i wonder? alice guessed in a moment that it was looking for the fan and the pair of white kid gloves, and she very good-naturedly began hunting about for them, but they were nowhere to be seen--everything seemed to have changed since her swim in the pool, and the great hall, with the glass table and the little door, had vanished completely. very soon the rabbit noticed alice, as she went hunting about, and called out to her in an angry tone, why, mary ann, what are you doing out here? run home this moment, and fetch me a pair of gloves and a fan! quick, now! and alice was so much frightened that she ran off at once in the direction it pointed to, without trying to explain the mistake it had made. he took me for his housemaid, she said to herself as she ran. how surprised hell be when he finds out who i am! but id better take him his fan and gloves--that is, if i can find them. as she said this, she came upon a neat little house, on the door of which was a bright brass plate with the name w. rabbit engraved upon it. she went in without knocking, and hurried upstairs, in great fear lest she should meet the real mary ann, and be turned out of the house before she had found the fan and gloves. how queer it seems, alice said to herself, to be going messages for a rabbit! i suppose dinahll be sending me on messages next! and she began fancying the sort of thing that would happen: miss alice! come here directly, and get ready for your walk! coming in a minute, nurse! but ive got to see that the mouse doesnt get out. only i dont think, alice went on, that theyd let dinah stop in the house if it began ordering people about like that! by this time she had found her way into a tidy little room with a table in the window, and on it (as she had hoped) a fan and two or three pairs of tiny white kid gloves: she took up the fan and a pair of the gloves, and was just going to leave the room, when her eye fell upon a little bottle that stood near the looking-glass. there was no label this time with the words drink me, but nevertheless she uncorked it and put it to her lips. i know something interesting is sure to happen, she said to herself, whenever i eat or drink anything; so ill just see what this bottle does. i do hope itll make me grow large again, for really im quite tired of being such a tiny little thing! it did so indeed, and much sooner than she had expected: before she had drunk half the bottle, she found her head pressing against the ceiling, and had to stoop to save her neck from being broken. she hastily put down the bottle, saying to herself thats quite enough--i hope i shant grow any more--as it is, i cant get out at the door--i do wish i hadnt drunk quite so much! alas! it was too late to wish that! she went on growing, and growing, and very soon had to kneel down on the floor: in another minute there was not even room for this, and she tried the effect of lying down with one elbow against the door, and the other arm curled round her head. still she went on growing, and, as a last resource, she put one arm out of the window, and one foot up the chimney, and said to herself now i can do no more, whatever happens. what will become of me? luckily for alice, the little magic bottle had now had its full effect, and she grew no larger: still it was very uncomfortable, and, as there seemed to be no sort of chance of her ever getting out of the room again, no wonder she felt unhappy. it was much pleasanter at home, thought poor alice, when one wasnt always growing larger and smaller, and being ordered about by mice and rabbits. i almost wish i hadnt gone down that rabbit-hole--and yet--and yet--its rather curious, you know, this sort of life! i do wonder what can have happened to me! when i used to read fairy-tales, i fancied that kind of thing never happened, and now here i am in the middle of one! there ought to be a book written about me, that there ought! and when i grow up, ill write one--but im grown up now, she added in a sorrowful tone; at least theres no room to grow up any more here. but then, thought alice, shall i never get any older than i am now? thatll be a comfort, one way--never to be an old woman--but then--always to have lessons to learn! oh, i shouldnt like that! oh, you foolish alice! she answered herself. how can you learn lessons in here? why, theres hardly room for you, and no room at all for any lesson-books! and so she went on, taking first one side and then the other, and making quite a conversation of it altogether; but after a few minutes she heard a voice outside, and stopped to listen. mary ann! mary ann! said the voice. fetch me my gloves this moment! then came a little pattering of feet on the stairs. alice knew it was the rabbit coming to look for her, and she trembled till she shook the house, quite forgetting that she was now about a thousand times as large as the rabbit, and had no reason to be afraid of it. presently the rabbit came up to the door, and tried to open it; but, as the door opened inwards, and alices elbow was pressed hard against it, that attempt proved a failure. alice heard it say to itself then ill go round and get in at the window. that you wont thought alice, and, after waiting till she fancied she heard the rabbit just under the window, she suddenly spread out her hand, and made a snatch in the air. she did not get hold of anything, but she heard a little shriek and a fall, and a crash of broken glass, from which she concluded that it was just possible it had fallen into a cucumber-frame, or something of the sort. next came an angry voice--the rabbits--pat! pat! where are you? and then a voice she had never heard before, sure then im here! digging for apples, yer honour! digging for apples, indeed! said the rabbit angrily. here! come and help me out of this! (sounds of more broken glass.) now tell me, pat, whats that in the window? sure, its an arm, yer honour! (he pronounced it arrum.) an arm, you goose! who ever saw one that size? why, it fills the whole window! sure, it does, yer honour: but its an arm for all that. well, its got no business there, at any rate: go and take it away! there was a long silence after this, and alice could only hear whispers now and then; such as, sure, i dont like it, yer honour, at all, at all! do as i tell you, you coward! and at last she spread out her hand again, and made another snatch in the air. this time there were two little shrieks, and more sounds of broken glass. what a number of cucumber-frames there must be! thought alice. i wonder what theyll do next! as for pulling me out of the window, i only wish they could! im sure i dont want to stay in here any longer! she waited for some time without hearing anything more: at last came a rumbling of little cartwheels, and the sound of a good many voices all talking together: she made out the words: wheres the other ladder?--why, i hadnt to bring but one; bills got the other--bill! fetch it here, lad!--here, put em up at this corner--no, tie em together first--they dont reach half high enough yet--oh! theyll do well enough; dont be particular--here, bill! catch hold of this rope--will the roof bear?--mind that loose slate--oh, its coming down! heads below! (a loud crash)--now, who did that?--it was bill, i fancy--whos to go down the chimney?--nay, i shant! you do it!--that i wont, then!--bills to go down--here, bill! the master says youre to go down the chimney! oh! so bills got to come down the chimney, has he? said alice to herself. shy, they seem to put everything upon bill! i wouldnt be in bills place for a good deal: this fireplace is narrow, to be sure; but i think i can kick a little! she drew her foot as far down the chimney as she could, and waited till she heard a little animal (she couldnt guess of what sort it was) scratching and scrambling about in the chimney close above her: then, saying to herself this is bill, she gave one sharp kick, and waited to see what would happen next. the first thing she heard was a general chorus of there goes bill! then the rabbits voice along--catch him, you by the hedge! then silence, and then another confusion of voices--hold up his head--brandy now--dont choke him--how was it, old fellow? what happened to you? tell us all about it! last came a little feeble, squeaking voice, [thats bill, thought alice,) well, i hardly know--no more, thank ye; im better now--but im a deal too flustered to tell you--all i know is, something comes at me like a jack-in-the-box, and up i goes like a sky-rocket! so you did, old fellow! said the others. we must burn the house down! said the rabbits voice; and alice called out as loud as she could, if you do. ill set dinah at you! there was a dead silence instantly, and alice thought to herself, i wonder what they will do next! if they had any sense, theyd take the roof off. after a minute or two, they began moving about again, and alice heard the rabbit say, a barrowful will do, to begin with. a barrowful of what? thought alice; but she had not long to doubt, for the next moment a shower of little pebbles came rattling in at the window, and some of them hit her in the face. ill put a stop to this, she said to herself, and shouted out, youd better not do that again! which produced another dead silence. alice noticed with some surprise that the pebbles were all turning into little cakes as they lay on the floor, and a bright idea came into her head. if i eat one of these cakes, she thought, its sure to make some change in my size; and as it cant possibly make me larger, it must make me smaller, i suppose. so she swallowed one of the cakes, and was delighted to find that she began shrinking directly. as soon as she was small enough to get through the door, she ran out of the house, and found quite a crowd of little animals and birds waiting outside. the poor little lizard, bill, was in the middle, being held up by two guinea-pigs, who were giving it something out of a bottle. they all made a rush at alice the moment she appeared; but she ran off as hard as she could, and soon found herself safe in a thick wood. the first thing ive got to do, said alice to herself, as she wandered about in the wood, is to grow to my right size again; and the second thing is to find my way into that lovely garden. i think that will be the best plan. it sounded an excellent plan, no doubt, and very neatly and simply arranged; the only difficulty was, that she had not the smallest idea how to set about it; and while she was peering about anxiously among the trees, a little sharp bark just over her head made her look up in a great hurry. an enormous puppy was looking down at her with large round eyes, and feebly stretching out one paw, trying to touch her. poor little thing! said alice, in a coaxing tone, and she tried hard to whistle to it; but she was terribly frightened all the time at the thought that it might be hungry, in which case it would be very likely to eat her up in spite of all her coaxing. hardly knowing what she did, she picked up a little bit of stick, and held it out to the puppy; whereupon the puppy jumped into the air off all its feet at once, with a yelp of delight, and rushed at the stick, and made believe to worry it; then alice dodged behind a great thistle, to keep herself from being run over; and the moment she appeared on the other side, the puppy made another rush at the stick, and tumbled head over heels in its hurry to get hold of it; then alice, thinking it was very like having a game of play with a cart-horse, and expecting every moment to be trampled under its feet, ran round the thistle again; then the puppy began a series of short charges at the stick, running a very little way forwards each time and a long way back, and barking hoarsely all the while, till at last it sat down a good way off, panting, with its tongue hanging out of its mouth, and its great eyes half shut. this seemed to alice a good opportunity for making her escape; so she set off at once, and ran till she was quite tired and out of breath, and till the puppys bark sounded quite faint in the distance. and yet what a dear little puppy it was! said alice, as she leant against a buttercup to rest herself, and fanned herself with one of the leaves: i should have liked teaching it tricks very much, if--if id only been the right size to do it! oh dear! id nearly forgotten that ive got to grow up again! let me see--how is it to be managed? i suppose i ought to eat or drink something or other; but the great question is, what? the great question certainly was, what? alice looked all round her at the flowers and the blades of grass, but she did not see anything that looked like the right thing to eat or drink under the circumstances. there was a large mushroom growing near her, about the same height as herself; and when she had looked under it, and on both sides of it, and behind it, it occurred to her that she might as well look and see what was on the top of it. she stretched herself up on tiptoe, and peeped over the edge of the mushroom, and her eyes immediately met those of a large caterpillar, that was sitting on the top with its arms folded, quietly smoking a long hookah, and taking not the smallest notice of her or of anything else. chapter v. advice from a caterpillar the caterpillar and alice looked at each other for some time in silence: at last the caterpillar took the hookah out of its mouth, and addressed her in a languid, sleepy voice. who are you? said the caterpillar. this was not an encouraging opening for a conversation. alice replied, rather shyly, i--i hardly know, sir, just at present--at least i know who i was when i got up this morning, but i think i must have been changed several times since then. what do you mean by that? said the caterpillar sternly. explain yourself! i cant explain myself, im afraid, sir said alice, because im not myself, you see. i dont see, said the caterpillar. im afraid i cant put it more clearly, alice replied very politely, for i cant understand it myself to begin with; and being so many different sizes in a day is very confusing. it isnt, said the caterpillar. well, perhaps you havent found it so yet, said alice; but when you have to turn into a chrysalis--you will some day, you know--and then after that into a butterfly, i should think youll feel it a little queer, wont you? not a bit, said the caterpillar. well, perhaps your feelings may be different, said alice; all i know is, it would feel very queer to me. you! said the caterpillar contemptuously. who are you? which brought them back again to the beginning of the conversation. alice felt a little irritated at the caterpillars making such very short remarks, and she drew herself up and said, very gravely, i think, you ought to tell me who you are, first. why? said the caterpillar. here was another puzzling question; and as alice could not think of any good reason, and as the caterpillar seemed to be in a very unpleasant state of mind, she turned away. come back! the caterpillar called after her. ive something important to say! this sounded promising, certainly: alice turned and came back again. keep your temper, said the caterpillar. is that all? said alice, swallowing down her anger as well as she could. no, said the caterpillar. alice thought she might as well wait, as she had nothing else to do, and perhaps after all it might tell her something worth hearing. for some minutes it puffed away without speaking, but at last it unfolded its arms, took the hookah out of its mouth again, and said, so you think youre changed, do you? im afraid i am, sir, said alice; i cant remember things as i used--and i dont keep the same size for ten minutes together! cant remember what things? said the caterpillar. well, ive tried to say how doth the little busy bee, but it all came different! alice replied in a very melancholy voice. repeat, you are old, father william, said the caterpillar. alice folded her hands, and began:-- you are old, father william, the young man said, and your hair has become very white; and yet you incessantly stand on your head-- do you think, at your age, it is right? in my youth, father william replied to his son, i feared it might injure the brain; but, now that im perfectly sure i have none, why, i do it again and again. you are old, said the youth, as i mentioned before, and have grown most uncommonly fat; yet you turned a back-somersault in at the door-- pray, what is the reason of that? in my youth, said the sage, as he shook his grey locks, i kept all my limbs very supple by the use of this ointment--one shilling the box-- allow me to sell you a couple? you are old, said the youth, and your jaws are too weak for anything tougher than suet; yet you finished the goose, with the bones and the beak-- pray how did you manage to do it? in my youth, said his father, i took to the law, and argued each case with my wife; and the muscular strength, which it gave to my jaw, has lasted the rest of my life. you are old, said the youth, one would hardly suppose that your eye was as steady as ever; yet you balanced an eel on the end of your nose-- what made you so awfully clever? i have answered three questions, and that is enough, said his father; dont give yourself airs! do you think i can listen all day to such stuff? be off, or ill kick you down stairs! that is not said right, said the caterpillar. not quite right, im afraid, said alice, timidly; some of the words have got altered. it is wrong from beginning to end, said the caterpillar decidedly, and there was silence for some minutes. the caterpillar was the first to speak. what size do you want to be? it asked. oh, im not particular as to size, alice hastily replied; only one doesnt like changing so often, you know. i dont know, said the caterpillar. alice said nothing: she had never been so much contradicted in her life before, and she felt that she was losing her temper. are you content now? said the caterpillar. well, i should like to be a little larger, sir, if you wouldnt mind, said alice: three inches is such a wretched height to be. it is a very good height indeed! said the caterpillar angrily, rearing itself upright as it spoke (it was exactly three inches high). but im not used to it! pleaded poor alice in a piteous tone. and she thought of herself, i wish the creatures wouldnt be so easily offended! youll get used to it in time, said the caterpillar; and it put the hookah into its mouth and began smoking again. this time alice waited patiently until it chose to speak again. in a minute or two the caterpillar took the hookah out of its mouth and yawned once or twice, and shook itself. then it got down off the mushroom, and crawled away in the grass, merely remarking as it went, one side will make you grow taller, and the other side will make you grow shorter. one side of what? the other side of what? thought alice to herself. of the mushroom, said the caterpillar, just as if she had asked it aloud; and in another moment it was out of sight. alice remained looking thoughtfully at the mushroom for a minute, trying to make out which were the two sides of it; and as it was perfectly round, she found this a very difficult question. however, at last she stretched her arms round it as far as they would go, and broke off a bit of the edge with each hand. and now which is which? she said to herself, and nibbled a little of the right-hand bit to try the effect: the next moment she felt a violent blow underneath her chin: it had struck her foot! she was a good deal frightened by this very sudden change, but she felt that there was no time to be lost, as she was shrinking rapidly; so she set to work at once to eat some of the other bit. her chin was pressed so closely against her foot, that there was hardly room to open her mouth; but she did it at last, and managed to swallow a morsel of the lefthand bit. *    *    *    *    *    *    * *    *    *    *    *    * *    *    *    *    *    *    * come, my heads free at last! said alice in a tone of delight, which changed into alarm in another moment, when she found that her shoulders were nowhere to be found: all she could see, when she looked down, was an immense length of neck, which seemed to rise like a stalk out of a sea of green leaves that lay far below her. what can all that green stuff be? said alice. and where have my shoulders got to? and oh, my poor hands, how is it i cant see you? she was moving them about as she spoke, but no result seemed to follow, except a little shaking among the distant green leaves. as there seemed to be no chance of getting her hands up to her head, she tried to get her head down to them, and was delighted to find that her neck would bend about easily in any direction, like a serpent. she had just succeeded in curving it down into a graceful zigzag, and was going to dive in among the leaves, which she found to be nothing but the tops of the trees under which she had been wandering, when a sharp hiss made her draw back in a hurry: a large pigeon had flown into her face, and was beating her violently with its wings. serpent! screamed the pigeon. im not a serpent! said alice indignantly. let me alone! serpent, i say again! repeated the pigeon, but in a more subdued tone, and added with a kind of sob, ive tried every way, and nothing seems to suit them! i havent the least idea what youre talking about, said alice. ive tried the roots of trees, and ive tried banks, and ive tried hedges, the pigeon went on, without attending to her; but those serpents! theres no pleasing them! alice was more and more puzzled, but she thought there was no use in saying anything more till the pigeon had finished. as if it wasnt trouble enough hatching the eggs, said the pigeon; but i must be on the look-out for serpents night and day! why, i havent had a wink of sleep these three weeks! im very sorry youve been annoyed, said alice, who was beginning to see its meaning. and just as id taken the highest tree in the wood, continued the pigeon, raising its voice to a shriek, and just as i was thinking i should be free of them at last, they must needs come wriggling down from the sky! ugh, serpent! but im not a serpent, i tell you! said alice. im a--im a-- well! what are you? said the pigeon. i can see youre trying to invent something! i--im a little girl, said alice, rather doubtfully, as she remembered the number of changes she had gone through that day. a likely story indeed! said the pigeon in a tone of the deepest contempt. ive seen a good many little girls in my time, but never one with such a neck as that! no, no! youre a serpent; and theres no use denying it. i suppose youll be telling me next that you never tasted an egg! i have tasted eggs, certainly, said alice, who was a very truthful child; but little girls eat eggs quite as much as serpents do, you know. i dont believe it, said the pigeon; but if they do, why then theyre a kind of serpent, thats all i can say. this was such a new idea to alice, that she was quite silent for a minute or two, which gave the pigeon the opportunity of adding, youre looking for eggs, i know that well enough; and what does it matter to me whether youre a little girl or a serpent? it matters a good deal to me, said alice hastily; but im not looking for eggs, as it happens; and if i was, i shouldnt want yours: i dont like them raw. well, be off, then! said the pigeon in a sulky tone, as it settled down again into its nest. alice crouched down among the trees as well as she could, for her neck kept getting entangled among the branches, and every now and then she had to stop and untwist it. after a while she remembered that she still held the pieces of mushroom in her hands, and she set to work very carefully, nibbling first at one and then at the other, and growing sometimes taller and sometimes shorter, until she had succeeded in bringing herself down to her usual height. it was so long since she had been anything near the right size, that it felt quite strange at first; but she got used to it in a few minutes, and began talking to herself, as usual. come, theres half my plan done now! how puzzling all these changes are! im never sure what im going to be, from one minute to another! however, ive got back to my right size: the next thing is, to get into that beautiful garden--how is that to be done, i wonder? as she said this, she came suddenly upon an open place, with a little house in it about four feet high. whoever lives there, thought alice, itll never do to come upon them this size: why, i should frighten them out of their wits! so she began nibbling at the righthand bit again, and did not venture to go near the house till she had brought herself down to nine inches high. chapter vi. pig and pepper for a minute or two she stood looking at the house, and wondering what to do next, when suddenly a footman in livery came running out of the wood--(she considered him to be a footman because he was in livery: otherwise, judging by his face only, she would have called him a fish)--and rapped loudly at the door with his knuckles. it was opened by another footman in livery, with a round face, and large eyes like a frog; and both footmen, alice noticed, had powdered hair that curled all over their heads. she felt very curious to know what it was all about, and crept a little way out of the wood to listen. the fish-footman began by producing from under his arm a great letter, nearly as large as himself, and this he handed over to the other, saying, in a solemn tone, for the duchess. an invitation from the queen to play croquet. the frog-footman repeated, in the same solemn tone, only changing the order of the words a little, from the queen. an invitation for the duchess to play croquet. then they both bowed low, and their curls got entangled together. alice laughed so much at this, that she had to run back into the wood for fear of their hearing her; and when she next peeped out the fish-footman was gone, and the other was sitting on the ground near the door, staring stupidly up into the sky. alice went timidly up to the door, and knocked. theres no sort of use in knocking, said the footman, and that for two reasons. first, because im on the same side of the door as you are; secondly, because theyre making such a noise inside, no one could possibly hear you. and certainly there was a most extraordinary noise going on within--a constant howling and sneezing, and every now and then a great crash, as if a dish or kettle had been broken to pieces. please, then, said alice, how am i to get in? there might be some sense in your knocking, the footman went on without attending to her, if we had the door between us. for instance, if you were inside, you might knock, and i could let you out, you know. he was looking up into the sky all the time he was speaking, and this alice thought decidedly uncivil. but perhaps he cant help it, she said to herself; his eyes are so very nearly at the top of his head. but at any rate he might answer questions.--how am i to get in? she repeated, aloud. i shall sit here, the footman remarked, till tomorrow-- at this moment the door of the house opened, and a large plate came skimming out, straight at the footmans head: it just grazed his nose, and broke to pieces against one of the trees behind him. --or next day, maybe, the footman continued in the same tone, exactly as if nothing had happened. how am i to get in? asked alice again, in a louder tone. are you to get in at all? said the footman. thats the first question, you know. it was, no doubt: only alice did not like to be told so. its really dreadful, she muttered to herself, the way all the creatures argue. its enough to drive one crazy! the footman seemed to think this a good opportunity for repeating his remark, with variations. i shall sit here, he said, on and off, for days and days. but what am i to do? said alice. anything you like, said the footman, and began whistling. oh, theres no use in talking to him, said alice desperately: hes perfectly idiotic! and she opened the door and went in. the door led right into a large kitchen, which was full of smoke from one end to the other: the duchess was sitting on a three-legged stool in the middle, nursing a baby; the cook was leaning over the fire, stirring a large cauldron which seemed to be full of soup. theres certainly too much pepper in that soup! alice said to herself, as well as she could for sneezing. there was certainly too much of it in the air. even the duchess sneezed occasionally; and as for the baby, it was sneezing and howling alternately without a moments pause. the only things in the kitchen that did not sneeze, were the cook, and a large cat which was sitting on the hearth and grinning from ear to ear. please would you tell me, said alice, a little timidly, for she was not quite sure whether it was good manners for her to speak first, why your cat grins like that? its a cheshire cat, said the duchess, and thats why. pig! she said the last word with such sudden violence that alice quite jumped; but she saw in another moment that it was addressed to the baby, and not to her, so she took courage, and went on again:-- i didnt know that cheshire cats always grinned; in fact, i didnt know that cats could grin. they all can, said the duchess; and most of em do. i dont know of any that do, alice said very politely, feeling quite pleased to have got into a conversation. you dont know much, said the duchess; and thats a fact. alice did not at all like the tone of this remark, and thought it would be as well to introduce some other subject of conversation. while she was trying to fix on one, the cook took the cauldron of soup off the fire, and at once set to work throwing everything within her reach at the duchess and the baby--the fire-irons came first; then followed a shower of saucepans, plates, and dishes. the duchess took no notice of them even when they hit her; and the baby was howling so much already, that it was quite impossible to say whether the blows hurt it or not. oh, please mind what youre doing! cried alice, jumping up and down in an agony of terror. oh, there goes his precious nose; as an unusually large saucepan flew close by it, and very nearly carried it off. if everybody minded their own business, the duchess said in a hoarse growl, the world would go round a deal faster than it does. which would not be an advantage, said alice, who felt very glad to get an opportunity of showing off a little of her knowledge. just think of what work it would make with the day and night! you see the earth takes twenty-four hours to turn round on its axis-- talking of axes, said the duchess, chop off her head! alice glanced rather anxiously at the cook, to see if she meant to take the hint; but the cook was busily stirring the soup, and seemed not to be listening, so she went on again: twenty-four hours, i think; or is it twelve? i-- oh, dont bother me, said the duchess; i never could abide figures! and with that she began nursing her child again, singing a sort of lullaby to it as she did so, and giving it a violent shake at the end of every line: speak roughly to your little boy, and beat him when he sneezes: he only does it to annoy, because he knows it teases. chorus. (in which the cook and the baby joined):-- wow! wow! wow! while the duchess sang the second verse of the song, she kept tossing the baby violently up and down, and the poor little thing howled so, that alice could hardly hear the words:-- i speak severely to my boy, i beat him when he sneezes; for he can thoroughly enjoy the pepper when he pleases! chorus. wow! wow! wow! here! you may nurse it a bit, if you like! the duchess said to alice, flinging the baby at her as she spoke. i must go and get ready to play croquet with the queen, and she hurried out of the room. the cook threw a frying-pan after her as she went out, but it just missed her. alice caught the baby with some difficulty, as it was a queer-shaped little creature, and held out its arms and legs in all directions, just like a star-fish, thought alice. the poor little thing was snorting like a steam-engine when she caught it, and kept doubling itself up and straightening itself out again, so that altogether, for the first minute or two, it was as much as she could do to hold it. as soon as she had made out the proper way of nursing it, (which was to twist it up into a sort of knot, and then keep tight hold of its right ear and left foot, so as to prevent its undoing itself,) she carried it out into the open air. if i dont take this child away with me, thought alice, theyre sure to kill it in a day or two: wouldnt it be murder to leave it behind? she said the last words out loud, and the little thing grunted in reply (it had left off sneezing by this time). dont grunt, said alice; thats not at all a proper way of expressing yourself. the baby grunted again, and alice looked very anxiously into its face to see what was the matter with it. there could be no doubt that it had a very turn-up nose, much more like a snout than a real nose; also its eyes were getting extremely small for a baby: altogether alice did not like the look of the thing at all. but perhaps it was only sobbing, she thought, and looked into its eyes again, to see if there were any tears. no, there were no tears. if youre going to turn into a pig, my dear, said alice, seriously, ill have nothing more to do with you. mind now! the poor little thing sobbed again (or grunted, it was impossible to say which), and they went on for some while in silence. alice was just beginning to think to herself, now, what am i to do with this creature when i get it home? when it grunted again, so violently, that she looked down into its face in some alarm. this time there could be no mistake about it: it was neither more nor less than a pig, and she felt that it would be quite absurd for her to carry it further. so she set the little creature down, and felt quite relieved to see it trot away quietly into the wood. if it had grown up, she said to herself, it would have made a dreadfully ugly child: but it makes rather a handsome pig, i think. and she began thinking over other children she knew, who might do very well as pigs, and was just saying to herself, if one only knew the right way to change them-- when she was a little startled by seeing the cheshire cat sitting on a bough of a tree a few yards off. the cat only grinned when it saw alice. it looked good-natured, she thought: still it had very long claws and a great many teeth, so she felt that it ought to be treated with respect. cheshire puss, she began, rather timidly, as she did not at all know whether it would like the name: however, it only grinned a little wider. come, its pleased so far, thought alice, and she went on. would you tell me, please, which way i ought to go from here? that depends a good deal on where you want to get to, said the cat. i dont much care where-- said alice. then it doesnt matter which way you go, said the cat. --so long as i get somewhere, alice added as an explanation. oh, youre sure to do that, said the cat, if you only walk long enough. alice felt that this could not be denied, so she tried another question. what sort of people live about here? in that direction, the cat said, waving its right paw round, lives a hatter: and in that direction, waving the other paw, lives a march hare. visit either you like: theyre both mad. but i dont want to go among mad people, alice remarked. oh, you cant help that, said the cat: were all mad here. im mad. youre mad. how do you know im mad? said alice. you must be, said the cat, or you wouldnt have come here. alice didnt think that proved it at all; however, she went on and how do you know that youre mad? to begin with, said the cat, a dogs not mad. you grant that? i suppose so, said alice. well, then, the cat went on, you see, a dog growls when its angry, and wags its tail when its pleased. now i growl when im pleased, and wag my tail when im angry. therefore im mad. i call it purring, not growling, said alice. call it what you like, said the cat. do you play croquet with the queen to-day? i should like it very much, said alice, but i havent been invited yet. youll see me there, said the cat, and vanished. alice was not much surprised at this, she was getting so used to queer things happening. while she was looking at the place where it had been, it suddenly appeared again. by-the-bye, what became of the baby? said the cat. id nearly forgotten to ask. it turned into a pig, alice quietly said, just as if it had come back in a natural way. i thought it would, said the cat, and vanished again. alice waited a little, half expecting to see it again, but it did not appear, and after a minute or two she walked on in the direction in which the march hare was said to live. ive seen hatters before, she said to herself; the march hare will be much the most interesting, and perhaps as this is may it wont be raving mad--at least not so mad as it was in march. as she said this, she looked up, and there was the cat again, sitting on a branch of a tree. did you say pig, or fig? said the cat. i said pig, replied alice; and i wish you wouldnt keep appearing and vanishing so suddenly: you make one quite giddy. all right, said the cat; and this time it vanished quite slowly, beginning with the end of the tail, and ending with the grin, which remained some time after the rest of it had gone. well! ive often seen a cat without a grin, thought alice; but a grin without a cat! its the most curious thing i ever saw in my life! she had not gone much farther before she came in sight of the house of the march hare: she thought it must be the right house, because the chimneys were shaped like ears and the roof was thatched with fur. it was so large a house, that she did not like to go nearer till she had nibbled some more of the lefthand bit of mushroom, and raised herself to about two feet high: even then she walked up towards it rather timidly, saying to herself suppose it should be raving mad after all! i almost wish id gone to see the hatter instead! chapter vii. a mad tea-party there was a table set out under a tree in front of the house, and the march hare and the hatter were having tea at it: a dormouse was sitting between them, fast asleep, and the other two were using it as a cushion, resting their elbows on it, and talking over its head. very uncomfortable for the dormouse, thought alice; only, as its asleep, i suppose it doesnt mind. the table was a large one, but the three were all crowded together at one corner of it: no room! no room! they cried out when they saw alice coming. theres plenty of room! said alice indignantly, and she sat down in a large arm-chair at one end of the table. have some wine, the march hare said in an encouraging tone. alice looked all round the table, but there was nothing on it but tea. i dont see any wine, she remarked. there isnt any, said the march hare. then it wasnt very civil of you to offer it, said alice angrily. it wasnt very civil of you to sit down without being invited, said the march hare. i didnt know it was your table, said alice; its laid for a great many more than three. your hair wants cutting, said the hatter. he had been looking at alice for some time with great curiosity, and this was his first speech. you should learn not to make personal remarks, alice said with some severity; its very rude. the hatter opened his eyes very wide on hearing this; but all he said was, why is a raven like a writing-desk? come, we shall have some fun now! thought alice. im glad theyve begun asking riddles.--i believe i can guess that, she added aloud. do you mean that you think you can find out the answer to it? said the march hare. exactly so, said alice. then you should say what you mean, the march hare went on. i do, alice hastily replied; at least--at least i mean what i say--thats the same thing, you know. not the same thing a bit! said the hatter. you might just as well say that i see what i eat is the same thing as i eat what i see! you might just as well say, added the march hare, that i like what i get is the same thing as i get what i like! you might just as well say, added the dormouse, who seemed to be talking in his sleep, that i breathe when i sleep is the same thing as i sleep when i breathe! it is the same thing with you, said the hatter, and here the conversation dropped, and the party sat silent for a minute, while alice thought over all she could remember about ravens and writing-desks, which wasnt much. the hatter was the first to break the silence. what day of the month is it? he said, turning to alice: he had taken his watch out of his pocket, and was looking at it uneasily, shaking it every now and then, and holding it to his ear. alice considered a little, and then said the fourth. two days wrong! sighed the hatter. i told you butter wouldnt suit the works! he added looking angrily at the march hare. it was the best butter, the march hare meekly replied. yes, but some crumbs must have got in as well, the hatter grumbled: you shouldnt have put it in with the bread-knife. the march hare took the watch and looked at it gloomily: then he dipped it into his cup of tea, and looked at it again: but he could think of nothing better to say than his first remark, it was the best butter, you know. alice had been looking over his shoulder with some curiosity. what a funny watch! she remarked. it tells the day of the month, and doesnt tell what oclock it is! why should it? muttered the hatter. does your watch tell you what year it is? of course not, alice replied very readily: but thats because it stays the same year for such a long time together. which is just the case with mine, said the hatter. alice felt dreadfully puzzled. the hatters remark seemed to have no sort of meaning in it, and yet it was certainly english. i dont quite understand you, she said, as politely as she could. the dormouse is asleep again, said the hatter, and he poured a little hot tea upon its nose. the dormouse shook its head impatiently, and said, without opening its eyes, of course, of course; just what i was going to remark myself. have you guessed the riddle yet? the hatter said, turning to alice again. no, i give it up, alice replied: whats the answer? i havent the slightest idea, said the hatter. nor i, said the march hare. alice sighed wearily. i think you might do something better with the time, she said, than waste it in asking riddles that have no answers. if you knew time as well as i do, said the hatter, you wouldnt talk about wasting it. its him. i dont know what you mean, said alice. of course you dont! the hatter said, tossing his head contemptuously. i dare say you never even spoke to time! perhaps not, alice cautiously replied: but i know i have to beat time when i learn music. ah! that accounts for it, said the hatter. he wont stand beating. now, if you only kept on good terms with him, hed do almost anything you liked with the clock. for instance, suppose it were nine oclock in the morning, just time to begin lessons: youd only have to whisper a hint to time, and round goes the clock in a twinkling! half-past one, time for dinner! [i only wish it was, the march hare said to itself in a whisper.) that would be grand, certainly, said alice thoughtfully: but then--i shouldnt be hungry for it, you know. not at first, perhaps, said the hatter: but you could keep it to half-past one as long as you liked. is that the way you manage? alice asked. the hatter shook his head mournfully. not i! he replied. we quarrelled last march--just before he went mad, you know-- (pointing with his tea spoon at the march hare,) --it was at the great concert given by the queen of hearts, and i had to sing twinkle, twinkle, little bat! how i wonder what youre at! you know the song, perhaps? ive heard something like it, said alice. it goes on, you know, the hatter continued, in this way:-- up above the world you fly, like a tea-tray in the sky. twinkle, twinkle-- here the dormouse shook itself, and began singing in its sleep twinkle, twinkle, twinkle, twinkle-- and went on so long that they had to pinch it to make it stop. well, id hardly finished the first verse, said the hatter, when the queen jumped up and bawled out, hes murdering the time! off with his head! how dreadfully savage! exclaimed alice. and ever since that, the hatter went on in a mournful tone, he wont do a thing i ask! its always six oclock now. a bright idea came into alices head. is that the reason so many tea-things are put out here? she asked. yes, thats it, said the hatter with a sigh: its always tea-time, and weve no time to wash the things between whiles. then you keep moving round, i suppose? said alice. exactly so, said the hatter: as the things get used up. but what happens when you come to the beginning again? alice ventured to ask. suppose we change the subject, the march hare interrupted, yawning. im getting tired of this. i vote the young lady tells us a story. im afraid i dont know one, said alice, rather alarmed at the proposal. then the dormouse shall! they both cried. wake up, dormouse! and they pinched it on both sides at once. the dormouse slowly opened his eyes. i wasnt asleep, he said in a hoarse, feeble voice: i heard every word you fellows were saying. tell us a story! said the march hare. yes, please do! pleaded alice. and be quick about it, added the hatter, or youll be asleep again before its done. once upon a time there were three little sisters, the dormouse began in a great hurry; and their names were elsie, lacie, and tillie; and they lived at the bottom of a well-- what did they live on? said alice, who always took a great interest in questions of eating and drinking. they lived on treacle, said the dormouse, after thinking a minute or two. they couldnt have done that, you know, alice gently remarked; theyd have been ill. so they were, said the dormouse; very ill. alice tried to fancy to herself what such an extraordinary ways of living would be like, but it puzzled her too much, so she went on: but why did they live at the bottom of a well? take some more tea, the march hare said to alice, very earnestly. ive had nothing yet, alice replied in an offended tone, so i cant take more. you mean you cant take less, said the hatter: its very easy to take more than nothing. nobody asked your opinion, said alice. whos making personal remarks now? the hatter asked triumphantly. alice did not quite know what to say to this: so she helped herself to some tea and bread-and-butter, and then turned to the dormouse, and repeated her question. why did they live at the bottom of a well? the dormouse again took a minute or two to think about it, and then said, it was a treacle-well. theres no such thing! alice was beginning very angrily, but the hatter and the march hare went sh! sh! and the dormouse sulkily remarked, if you cant be civil, youd better finish the story for yourself. no, please go on! alice said very humbly; i wont interrupt again. i dare say there may be one. one, indeed! said the dormouse indignantly. however, he consented to go on. and so these three little sisters--they were learning to draw, you know-- what did they draw? said alice, quite forgetting her promise. treacle, said the dormouse, without considering at all this time. i want a clean cup, interrupted the hatter: lets all move one place on. he moved on as he spoke, and the dormouse followed him: the march hare moved into the dormouses place, and alice rather unwillingly took the place of the march hare. the hatter was the only one who got any advantage from the change: and alice was a good deal worse off than before, as the march hare had just upset the milk-jug into his plate. alice did not wish to offend the dormouse again, so she began very cautiously: but i dont understand. where did they draw the treacle from? you can draw water out of a water-well, said the hatter; so i should think you could draw treacle out of a treacle-well--eh, stupid? but they were in the well, alice said to the dormouse, not choosing to notice this last remark. of course they were, said the dormouse; --well in. this answer so confused poor alice, that she let the dormouse go on for some time without interrupting it. they were learning to draw, the dormouse went on, yawning and rubbing its eyes, for it was getting very sleepy; and they drew all manner of things--everything that begins with an m-- why with an m? said alice. why not? said the march hare. alice was silent. the dormouse had closed its eyes by this time, and was going off into a doze; but, on being pinched by the hatter, it woke up again with a little shriek, and went on: --that begins with an m, such as mouse-traps, and the moon, and memory, and muchness--you know you say things are much of a muchness--did you ever see such a thing as a drawing of a muchness? really, now you ask me, said alice, very much confused, i dont think-- then you shouldnt talk, said the hatter. this piece of rudeness was more than alice could bear: she got up in great disgust, and walked off; the dormouse fell asleep instantly, and neither of the others took the least notice of her going, though she looked back once or twice, half hoping that they would call after her: the last time she saw them, they were trying to put the dormouse into the teapot. at any rate ill never go there again! said alice as she picked her way through the wood. its the stupidest tea-party i ever was at in all my life! just as she said this, she noticed that one of the trees had a door leading right into it. thats very curious! she thought. but everythings curious today. i think i may as well go in at once. and in she went. once more she found herself in the long hall, and close to the little glass table. now, ill manage better this time, she said to herself, and began by taking the little golden key, and unlocking the door that led into the garden. then she went to work nibbling at the mushroom (she had kept a piece of it in her pocket) till she was about a foot high: then she walked down the little passage: and then--she found herself at last in the beautiful garden, among the bright flower-beds and the cool fountains. chapter viii. the queens croquet-ground a large rose-tree stood near the entrance of the garden: the roses growing on it were white, but there were three gardeners at it, busily painting them red. alice thought this a very curious thing, and she went nearer to watch them, and just as she came up to them she heard one of them say, look out now, five! dont go splashing paint over me like that! i couldnt help it, said five, in a sulky tone; seven jogged my elbow. on which seven looked up and said, thats right, five! always lay the blame on others! youd better not talk! said five. i heard the queen say only yesterday you deserved to be beheaded! what for? said the one who had spoken first. thats none of your business, two! said seven. yes, it is his business! said five, and ill tell him--it was for bringing the cook tulip-roots instead of onions. seven flung down his brush, and had just begun well, of all the unjust things-- when his eye chanced to fall upon alice, as she stood watching them, and he checked himself suddenly: the others looked round also, and all of them bowed low. would you tell me, said alice, a little timidly, why you are painting those roses? five and seven said nothing, but looked at two. two began in a low voice, why the fact is, you see, miss, this here ought to have been a red rose-tree, and we put a white one in by mistake; and if the queen was to find it out, we should all have our heads cut off, you know. so you see, miss, were doing our best, afore she comes, to-- at this moment five, who had been anxiously looking across the garden, called out the queen! the queen! and the three gardeners instantly threw themselves flat upon their faces. there was a sound of many footsteps, and alice looked round, eager to see the queen. first came ten soldiers carrying clubs; these were all shaped like the three gardeners, oblong and flat, with their hands and feet at the corners: next the ten courtiers; these were ornamented all over with diamonds, and walked two and two, as the soldiers did. after these came the royal children; there were ten of them, and the little dears came jumping merrily along hand in hand, in couples: they were all ornamented with hearts. next came the guests, mostly kings and queens, and among them alice recognised the white rabbit: it was talking in a hurried nervous manner, smiling at everything that was said, and went by without noticing her. then followed the knave of hearts, carrying the kings crown on a crimson velvet cushion; and, last of all this grand procession, came the king and queen of hearts. alice was rather doubtful whether she ought not to lie down on her face like the three gardeners, but she could not remember ever having heard of such a rule at processions; and besides, what would be the use of a procession, thought she, if people had all to lie down upon their faces, so that they couldnt see it? so she stood still where she was, and waited. when the procession came opposite to alice, they all stopped and looked at her, and the queen said severely who is this? she said it to the knave of hearts, who only bowed and smiled in reply. idiot! said the queen, tossing her head impatiently; and, turning to alice, she went on, whats your name, child? my name is alice, so please your majesty, said alice very politely; but she added, to herself, why, theyre only a pack of cards, after all. i neednt be afraid of them! and who are these? said the queen, pointing to the three gardeners who were lying round the rosetree; for, you see, as they were lying on their faces, and the pattern on their backs was the same as the rest of the pack, she could not tell whether they were gardeners, or soldiers, or courtiers, or three of her own children. how should i know? said alice, surprised at her own courage. its no business of mine. the queen turned crimson with fury, and, after glaring at her for a moment like a wild beast, screamed off with her head! off-- nonsense! said alice, very loudly and decidedly, and the queen was silent. the king laid his hand upon her arm, and timidly said consider, my dear: she is only a child! the queen turned angrily away from him, and said to the knave turn them over! the knave did so, very carefully, with one foot. get up! said the queen, in a shrill, loud voice, and the three gardeners instantly jumped up, and began bowing to the king, the queen, the royal children, and everybody else. leave off that! screamed the queen. you make me giddy. and then, turning to the rose-tree, she went on, what have you been doing here? may it please your majesty, said two, in a very humble tone, going down on one knee as he spoke, we were trying-- i see! said the queen, who had meanwhile been examining the roses. off with their heads! and the procession moved on, three of the soldiers remaining behind to execute the unfortunate gardeners, who ran to alice for protection. you shant be beheaded! said alice, and she put them into a large flower-pot that stood near. the three soldiers wandered about for a minute or two, looking for them, and then quietly marched off after the others. are their heads off? shouted the queen. their heads are gone, if it please your majesty! the soldiers shouted in reply. thats right! shouted the queen. can you play croquet? the soldiers were silent, and looked at alice, as the question was evidently meant for her. yes! shouted alice. come on, then! roared the queen, and alice joined the procession, wondering very much what would happen next. its--its a very fine day! said a timid voice at her side. she was walking by the white rabbit, who was peeping anxiously into her face. very, said alice: --wheres the duchess? hush! hush! said the rabbit in a low, hurried tone. he looked anxiously over his shoulder as he spoke, and then raised himself upon tiptoe, put his mouth close to her ear, and whispered shes under sentence of execution. what for? said alice. did you say what a pity!? the rabbit asked. no, i didnt, said alice: i dont think its at all a pity. i said what for? she boxed the queens ears-- the rabbit began. alice gave a little scream of laughter. oh, hush! the rabbit whispered in a frightened tone. the queen will hear you! you see, she came rather late, and the queen said-- get to your places! shouted the queen in a voice of thunder, and people began running about in all directions, tumbling up against each other; however, they got settled down in a minute or two, and the game began. alice thought she had never seen such a curious croquet-ground in her life; it was all ridges and furrows; the balls were live hedgehogs, the mallets live flamingoes, and the soldiers had to double themselves up and to stand on their hands and feet, to make the arches. the chief difficulty alice found at first was in managing her flamingo: she succeeded in getting its body tucked away, comfortably enough, under her arm, with its legs hanging down, but generally, just as she had got its neck nicely straightened out, and was going to give the hedgehog a blow with its head, it would twist itself round and look up in her face, with such a puzzled expression that she could not help bursting out laughing: and when she had got its head down, and was going to begin again, it was very provoking to find that the hedgehog had unrolled itself, and was in the act of crawling away: besides all this, there was generally a ridge or furrow in the way wherever she wanted to send the hedgehog to, and, as the doubled-up soldiers were always getting up and walking off to other parts of the ground, alice soon came to the conclusion that it was a very difficult game indeed. the players all played at once without waiting for turns, quarrelling all the while, and fighting for the hedgehogs; and in a very short time the queen was in a furious passion, and went stamping about, and shouting off with his head! or off with her head! about once in a minute. alice began to feel very uneasy: to be sure, she had not as yet had any dispute with the queen, but she knew that it might happen any minute, and then, thought she, what would become of me? theyre dreadfully fond of beheading people here; the great wonder is, that theres any one left alive! she was looking about for some way of escape, and wondering whether she could get away without being seen, when she noticed a curious appearance in the air: it puzzled her very much at first, but, after watching it a minute or two, she made it out to be a grin, and she said to herself its the cheshire cat: now i shall have somebody to talk to. how are you getting on? said the cat, as soon as there was mouth enough for it to speak with. alice waited till the eyes appeared, and then nodded. its no use speaking to it, she thought, till its ears have come, or at least one of them. in another minute the whole head appeared, and then alice put down her flamingo, and began an account of the game, feeling very glad she had someone to listen to her. the cat seemed to think that there was enough of it now in sight, and no more of it appeared. i dont think they play at all fairly, alice began, in rather a complaining tone, and they all quarrel so dreadfully one cant hear oneself speak--and they dont seem to have any rules in particular; at least, if there are, nobody attends to them--and youve no idea how confusing it is all the things being alive; for instance, theres the arch ive got to go through next walking about at the other end of the ground--and i should have croqueted the queens hedgehog just now, only it ran away when it saw mine coming! how do you like the queen? said the cat in a low voice. not at all, said alice: shes so extremely-- just then she noticed that the queen was close behind her, listening: so she went on, --likely to win, that its hardly worth while finishing the game. the queen smiled and passed on. who are you talking to? said the king, going up to alice, and looking at the cats head with great curiosity. its a friend of mine--a cheshire cat, said alice: allow me to introduce it. i dont like the look of it at all, said the king: however, it may kiss my hand if it likes. id rather not, the cat remarked. dont be impertinent, said the king, and dont look at me like that! he got behind alice as he spoke. a cat may look at a king, said alice. ive read that in some book, but i dont remember where. well, it must be removed, said the king very decidedly, and he called the queen, who was passing at the moment, my dear! i wish you would have this cat removed! the queen had only one way of settling all difficulties, great or small. off with his head! she said, without even looking round. ill fetch the executioner myself, said the king eagerly, and he hurried off. alice thought she might as well go back, and see how the game was going on, as she heard the queens voice in the distance, screaming with passion. she had already heard her sentence three of the players to be executed for having missed their turns, and she did not like the look of things at all, as the game was in such confusion that she never knew whether it was her turn or not. so she went in search of her hedgehog. the hedgehog was engaged in a fight with another hedgehog, which seemed to alice an excellent opportunity for croqueting one of them with the other: the only difficulty was, that her flamingo was gone across to the other side of the garden, where alice could see it trying in a helpless sort of way to fly up into a tree. by the time she had caught the flamingo and brought it back, the fight was over, and both the hedgehogs were out of sight: but it doesnt matter much, thought alice, as all the arches are gone from this side of the ground. so she tucked it away under her arm, that it might not escape again, and went back for a little more conversation with her friend. when she got back to the cheshire cat, she was surprised to find quite a large crowd collected round it: there was a dispute going on between the executioner, the king, and the queen, who were all talking at once, while all the rest were quite silent, and looked very uncomfortable. the moment alice appeared, she was appealed to by all three to settle the question, and they repeated their arguments to her, though, as they all spoke at once, she found it very hard indeed to make out exactly what they said. the executioners argument was, that you couldnt cut off a head unless there was a body to cut it off from: that he had never had to do such a thing before, and he wasnt going to begin at his time of life. the kings argument was, that anything that had a head could be beheaded, and that you werent to talk nonsense. the queens argument was, that if something wasnt done about it in less than no time shed have everybody executed, all round. (it was this last remark that had made the whole party look so grave and anxious.) alice could think of nothing else to say but it belongs to the duchess: youd better ask her about it. shes in prison, the queen said to the executioner: fetch her here. and the executioner went off like an arrow. the cats head began fading away the moment he was gone, and, by the time he had come back with the duchess, it had entirely disappeared; so the king and the executioner ran wildly up and down looking for it, while the rest of the party went back to the game. chapter ix. the mock turtles story you cant think how glad i am to see you again, you dear old thing! said the duchess, as she tucked her arm affectionately into alices, and they walked off together. alice was very glad to find her in such a pleasant temper, and thought to herself that perhaps it was only the pepper that had made her so savage when they met in the kitchen. when im a duchess, she said to herself, (not in a very hopeful tone though), i wont have any pepper in my kitchen at all. soup does very well without--maybe its always pepper that makes people hot-tempered, she went on, very much pleased at having found out a new kind of rule, and vinegar that makes them sour--and camomile that makes them bitter--and--and barley-sugar and such things that make children sweet-tempered. i only wish people knew that: then they wouldnt be so stingy about it, you know-- she had quite forgotten the duchess by this time, and was a little startled when she heard her voice close to her ear. youre thinking about something, my dear, and that makes you forget to talk. i cant tell you just now what the moral of that is, but i shall remember it in a bit. perhaps it hasnt one, alice ventured to remark. tut, tut, child! said the duchess. everythings got a moral, if only you can find it. and she squeezed herself up closer to alices side as she spoke. alice did not much like keeping so close to her: first, because the duchess was very ugly; and secondly, because she was exactly the right height to rest her chin upon alices shoulder, and it was an uncomfortably sharp chin. however, she did not like to be rude, so she bore it as well as she could. the games going on rather better now, she said, by way of keeping up the conversation a little. tis so, said the duchess: and the moral of that is--oh, tis love, tis love, that makes the world go round! somebody said, alice whispered, that its done by everybody minding their own business! ah, well! it means much the same thing, said the duchess, digging her sharp little chin into alices shoulder as she added, and the moral of that is--take care of the sense, and the sounds will take care of themselves. how fond she is of finding morals in things! alice thought to herself. i dare say youre wondering why i dont put my arm round your waist, the duchess said after a pause: the reason is, that im doubtful about the temper of your flamingo. shall i try the experiment? he might bite, alice cautiously replied, not feeling at all anxious to have the experiment tried. very true, said the duchess: flamingoes and mustard both bite. and the moral of that is--birds of a feather flock together. only mustard isnt a bird, alice remarked. right, as usual, said the duchess: what a clear way you have of putting things! its a mineral, i think, said alice. of course it is, said the duchess, who seemed ready to agree to everything that alice said; theres a large mustard-mine near here. and the moral of that is--the more there is of mine, the less there is of yours. oh, i know! exclaimed alice, who had not attended to this last remark, its a vegetable. it doesnt look like one, but it is. i quite agree with you, said the duchess; and the moral of that is--be what you would seem to be--or if youd like it put more simply--never imagine yourself not to be otherwise than what it might appear to others that what you were or might have been was not otherwise than what you had been would have appeared to them to be otherwise. i think i should understand that better, alice said very politely, if i had it written down: but i cant quite follow it as you say it. thats nothing to what i could say if i chose, the duchess replied, in a pleased tone. pray dont trouble yourself to say it any longer than that, said alice. oh, dont talk about trouble! said the duchess. i make you a present of everything ive said as yet. a cheap sort of present! thought alice. im glad they dont give birthday presents like that! but she did not venture to say it out loud. thinking again? the duchess asked, with another dig of her sharp little chin. ive a right to think, said alice sharply, for she was beginning to feel a little worried. just about as much right, said the duchess, as pigs have to fly; and the m-- but here, to alices great surprise, the duchesss voice died away, even in the middle of her favourite word moral, and the arm that was linked into hers began to tremble. alice looked up, and there stood the queen in front of them, with her arms folded, frowning like a thunderstorm. a fine day, your majesty! the duchess began in a low, weak voice. now, i give you fair warning, shouted the queen, stamping on the ground as she spoke; either you or your head must be off, and that in about half no time! take your choice! the duchess took her choice, and was gone in a moment. lets go on with the game, the queen said to alice; and alice was too much frightened to say a word, but slowly followed her back to the croquet-ground. the other guests had taken advantage of the queens absence, and were resting in the shade: however, the moment they saw her, they hurried back to the game, the queen merely remarking that a moments delay would cost them their lives. all the time they were playing the queen never left off quarrelling with the other players, and shouting off with his head! or off with her head! those whom she sentenced were taken into custody by the soldiers, who of course had to leave off being arches to do this, so that by the end of half an hour or so there were no arches left, and all the players, except the king, the queen, and alice, were in custody and under sentence of execution. then the queen left off, quite out of breath, and said to alice, have you seen the mock turtle yet? no, said alice. i dont even know what a mock turtle is. its the thing mock turtle soup is made from, said the queen. i never saw one, or heard of one, said alice. come on, then, said the queen, and he shall tell you his history, as they walked off together, alice heard the king say in a low voice, to the company generally, you are all pardoned. come, thats a good thing! she said to herself, for she had felt quite unhappy at the number of executions the queen had ordered. they very soon came upon a gryphon, lying fast asleep in the sun. (if you dont know what a gryphon is, look at the picture.) up, lazy thing! said the queen, and take this young lady to see the mock turtle, and to hear his history. i must go back and see after some executions i have ordered; and she walked off, leaving alice alone with the gryphon. alice did not quite like the look of the creature, but on the whole she thought it would be quite as safe to stay with it as to go after that savage queen: so she waited. the gryphon sat up and rubbed its eyes: then it watched the queen till she was out of sight: then it chuckled. what fun! said the gryphon, half to itself, half to alice. what is the fun? said alice. why, she, said the gryphon. its all her fancy, that: they never executes nobody, you know. come on! everybody says come on! here, thought alice, as she went slowly after it: i never was so ordered about in all my life, never! they had not gone far before they saw the mock turtle in the distance, sitting sad and lonely on a little ledge of rock, and, as they came nearer, alice could hear him sighing as if his heart would break. she pitied him deeply. what is his sorrow? she asked the gryphon, and the gryphon answered, very nearly in the same words as before, its all his fancy, that: he hasnt got no sorrow, you know. come on! so they went up to the mock turtle, who looked at them with large eyes full of tears, but said nothing. this here young lady, said the gryphon, she wants for to know your history, she do. ill tell it her, said the mock turtle in a deep, hollow tone: sit down, both of you, and dont speak a word till ive finished. so they sat down, and nobody spoke for some minutes. alice thought to herself, i dont see how he can even finish, if he doesnt begin. but she waited patiently. once, said the mock turtle at last, with a deep sigh, i was a real turtle. these words were followed by a very long silence, broken only by an occasional exclamation of hjckrrh! from the gryphon, and the constant heavy sobbing of the mock turtle. alice was very nearly getting up and saying, thank you, sir, for your interesting story, but she could not help thinking there must be more to come, so she sat still and said nothing. when we were little, the mock turtle went on at last, more calmly, though still sobbing a little now and then, we went to school in the sea. the master was an old turtle--we used to call him tortoise-- why did you call him tortoise, if he wasnt one? alice asked. we called him tortoise because he taught us, said the mock turtle angrily: really you are very dull! you ought to be ashamed of yourself for asking such a simple question, added the gryphon; and then they both sat silent and looked at poor alice, who felt ready to sink into the earth. at last the gryphon said to the mock turtle, drive on, old fellow! dont be all day about it! and he went on in these words: yes, we went to school in the sea, though you maynt believe it-- i never said i didnt! interrupted alice. you did, said the mock turtle. hold your tongue! added the gryphon, before alice could speak again. the mock turtle went on. we had the best of educations--in fact, we went to school every day-- ive been to a day-school, too, said alice; you neednt be so proud as all that. with extras? asked the mock turtle a little anxiously. yes, said alice, we learned french and music. and washing? said the mock turtle. certainly not! said alice indignantly. ah! then yours wasnt a really good school, said the mock turtle in a tone of great relief. now at ours they had at the end of the bill, french, music, and washing--extra. you couldnt have wanted it much, said alice; living at the bottom of the sea. i couldnt afford to learn it. said the mock turtle with a sigh. i only took the regular course. what was that? inquired alice. reeling and writhing, of course, to begin with, the mock turtle replied; and then the different branches of arithmetic--ambition, distraction, uglification, and derision. i never heard of uglification, alice ventured to say. what is it? the gryphon lifted up both its paws in surprise. what! never heard of uglifying! it exclaimed. you know what to beautify is, i suppose? yes, said alice doubtfully: it means--to--make--anything--prettier. well, then, the gryphon went on, if you dont know what to uglify is, you are a simpleton. alice did not feel encouraged to ask any more questions about it, so she turned to the mock turtle, and said what else had you to learn? well, there was mystery, the mock turtle replied, counting off the subjects on his flappers, --mystery, ancient and modern, with seaography: then drawling--the drawling-master was an old conger-eel, that used to come once a week: he taught us drawling, stretching, and fainting in coils. what was that like? said alice. well, i cant show it you myself, the mock turtle said: im too stiff. and the gryphon never learnt it. hadnt time, said the gryphon: i went to the classics master, though. he was an old crab, he was. i never went to him, the mock turtle said with a sigh: he taught laughing and grief, they used to say. so he did, so he did, said the gryphon, sighing in his turn; and both creatures hid their faces in their paws. and how many hours a day did you do lessons? said alice, in a hurry to change the subject. ten hours the first day, said the mock turtle: nine the next, and so on. what a curious plan! exclaimed alice. thats the reason theyre called lessons, the gryphon remarked: because they lessen from day to day. this was quite a new idea to alice, and she thought it over a little before she made her next remark. then the eleventh day must have been a holiday? of course it was, said the mock turtle. and how did you manage on the twelfth? alice went on eagerly. thats enough about lessons, the gryphon interrupted in a very decided tone: tell her something about the games now. chapter x. the lobster quadrille the mock turtle sighed deeply, and drew the back of one flapper across his eyes. he looked at alice, and tried to speak, but for a minute or two sobs choked his voice. same as if he had a bone in his throat, said the gryphon: and it set to work shaking him and punching him in the back. at last the mock turtle recovered his voice, and, with tears running down his cheeks, he went on again:-- you may not have lived much under the sea-- [i havent, said alice)--and perhaps you were never even introduced to a lobster-- (alice began to say i once tasted-- but checked herself hastily, and said no, never) --so you can have no idea what a delightful thing a lobster quadrille is! no, indeed, said alice. what sort of a dance is it? why, said the gryphon, you first form into a line along the sea-shore-- two lines! cried the mock turtle. seals, turtles, salmon, and so on; then, when youve cleared all the jelly-fish out of the way-- that generally takes some time, interrupted the gryphon. --you advance twice-- each with a lobster as a partner! cried the gryphon. of course, the mock turtle said: advance twice, set to partners-- --change lobsters, and retire in same order, continued the gryphon. then, you know, the mock turtle went on, you throw the-- the lobsters! shouted the gryphon, with a bound into the air. --as far out to sea as you can-- swim after them! screamed the gryphon. turn a somersault in the sea! cried the mock turtle, capering wildly about. change lobsters again! yelled the gryphon at the top of its voice. back to land again, and thats all the first figure, said the mock turtle, suddenly dropping his voice; and the two creatures, who had been jumping about like mad things all this time, sat down again very sadly and quietly, and looked at alice. it must be a very pretty dance, said alice timidly. would you like to see a little of it? said the mock turtle. very much indeed, said alice. come, lets try the first figure! said the mock turtle to the gryphon. we can do without lobsters, you know. which shall sing? oh, you sing, said the gryphon. ive forgotten the words. so they began solemnly dancing round and round alice, every now and then treading on her toes when they passed too close, and waving their forepaws to mark the time, while the mock turtle sang this, very slowly and sadly:-- will you walk a little faster? said a whiting to a snail. theres a porpoise close behind us, and hes treading on my tail. see how eagerly the lobsters and the turtles all advance! they are waiting on the shingle--will you come and join the dance? will you, wont you, will you, wont you, will you join the dance? will you, wont you, will you, wont you, wont you join the dance? you can really have no notion how delightful it will be when they take us up and throw us, with the lobsters, out to sea! but the snail replied too far, too far! and gave a look askance-- said he thanked the whiting kindly, but he would not join the dance. would not, could not, would not, could not, would not join the dance. would not, could not, would not, could not, could not join the dance. what matters it how far we go? his scaly friend replied. there is another shore, you know, upon the other side. the further off from england the nearer is to france-- then turn not pale, beloved snail, but come and join the dance. will you, wont you, will you, wont you, will you join the dance? will you, wont you, will you, wont you, wont you join the dance? thank you, its a very interesting dance to watch, said alice, feeling very glad that it was over at last: and i do so like that curious song about the whiting! oh, as to the whiting, said the mock turtle, they--youve seen them, of course? yes, said alice, ive often seen them at dinn-- she checked herself hastily. i dont know where dinn may be, said the mock turtle, but if youve seen them so often, of course you know what theyre like. i believe so, alice replied thoughtfully. they have their tails in their mouths--and theyre all over crumbs. youre wrong about the crumbs, said the mock turtle: crumbs would all wash off in the sea. but they have their tails in their mouths; and the reason is-- here the mock turtle yawned and shut his eyes.--tell her about the reason and all that, he said to the gryphon. the reason is, said the gryphon, that they would go with the lobsters to the dance. so they got thrown out to sea. so they had to fall a long way. so they got their tails fast in their mouths. so they couldnt get them out again. thats all. thank you, said alice, its very interesting. i never knew so much about a whiting before. i can tell you more than that, if you like, said the gryphon. do you know why its called a whiting? i never thought about it, said alice. why? it does the boots and shoes. the gryphon replied very solemnly. alice was thoroughly puzzled. does the boots and shoes! she repeated in a wondering tone. why, what are your shoes done with? said the gryphon. i mean, what makes them so shiny? alice looked down at them, and considered a little before she gave her answer. theyre done with blacking, i believe. boots and shoes under the sea, the gryphon went on in a deep voice, are done with a whiting. now you know. and what are they made of? alice asked in a tone of great curiosity. soles and eels, of course, the gryphon replied rather impatiently: any shrimp could have told you that. if id been the whiting, said alice, whose thoughts were still running on the song, id have said to the porpoise, keep back, please: we dont want you with us! they were obliged to have him with them, the mock turtle said: no wise fish would go anywhere without a porpoise. wouldnt it really? said alice in a tone of great surprise. of course not, said the mock turtle: why, if a fish came to me, and told me he was going a journey, i should say with what porpoise? dont you mean purpose? said alice. i mean what i say, the mock turtle replied in an offended tone. and the gryphon added come, lets hear some of your adventures. i could tell you my adventures--beginning from this morning, said alice a little timidly: but its no use going back to yesterday, because i was a different person then. explain all that, said the mock turtle. no, no! the adventures first, said the gryphon in an impatient tone: explanations take such a dreadful time. so alice began telling them her adventures from the time when she first saw the white rabbit. she was a little nervous about it just at first, the two creatures got so close to her, one on each side, and opened their eyes and mouths so very wide, but she gained courage as she went on. her listeners were perfectly quiet till she got to the part about her repeating you are old, father william, to the caterpillar, and the words all coming different, and then the mock turtle drew a long breath, and said thats very curious. its all about as curious as it can be, said the gryphon. it all came different! the mock turtle repeated thoughtfully. i should like to hear her try and repeat something now. tell her to begin. he looked at the gryphon as if he thought it had some kind of authority over alice. stand up and repeat tis the voice of the sluggard, said the gryphon. how the creatures order one about, and make one repeat lessons! thought alice; i might as well be at school at once. however, she got up, and began to repeat it, but her head was so full of the lobster quadrille, that she hardly knew what she was saying, and the words came very queer indeed:-- tis the voice of the lobster; i heard him declare, you have baked me too brown, i must sugar my hair. as a duck with its eyelids, so he with his nose trims his belt and his buttons, and turns out his toes. [later editions continued as follows when the sands are all dry, he is gay as a lark, and will talk in contemptuous tones of the shark, but, when the tide rises and sharks are around, his voice has a timid and tremulous sound.] thats different from what i used to say when i was a child, said the gryphon. well, i never heard it before, said the mock turtle; but it sounds uncommon nonsense. alice said nothing; she had sat down with her face in her hands, wondering if anything would ever happen in a natural way again. i should like to have it explained, said the mock turtle. she cant explain it, said the gryphon hastily. go on with the next verse. but about his toes? the mock turtle persisted. how could he turn them out with his nose, you know? its the first position in dancing. alice said; but was dreadfully puzzled by the whole thing, and longed to change the subject. go on with the next verse, the gryphon repeated impatiently: it begins i passed by his garden. alice did not dare to disobey, though she felt sure it would all come wrong, and she went on in a trembling voice:-- i passed by his garden, and marked, with one eye, how the owl and the panther were sharing a pie-- [later editions continued as follows the panther took pie-crust, and gravy, and meat, while the owl had the dish as its share of the treat. when the pie was all finished, the owl, as a boon, was kindly permitted to pocket the spoon: while the panther received knife and fork with a growl, and concluded the banquet--] what is the use of repeating all that stuff, the mock turtle interrupted, if you dont explain it as you go on? its by far the most confusing thing i ever heard! yes, i think youd better leave off, said the gryphon: and alice was only too glad to do so. shall we try another figure of the lobster quadrille? the gryphon went on. or would you like the mock turtle to sing you a song? oh, a song, please, if the mock turtle would be so kind, alice replied, so eagerly that the gryphon said, in a rather offended tone, hm! no accounting for tastes! sing her turtle soup, will you, old fellow? the mock turtle sighed deeply, and began, in a voice sometimes choked with sobs, to sing this:-- beautiful soup, so rich and green, waiting in a hot tureen! who for such dainties would not stoop? soup of the evening, beautiful soup! soup of the evening, beautiful soup! beau--ootiful soo--oop! beau--ootiful soo--oop! soo--oop of the e--e--evening, beautiful, beautiful soup! beautiful soup! who cares for fish, game, or any other dish? who would not give all else for two pennyworth only of beautiful soup? pennyworth only of beautiful soup? beau--ootiful soo--oop! beau--ootiful soo--oop! soo--oop of the e--e--evening, beautiful, beauti--ful soup! chorus again! cried the gryphon, and the mock turtle had just begun to repeat it, when a cry of the trials beginning! was heard in the distance. come on! cried the gryphon, and, taking alice by the hand, it hurried off, without waiting for the end of the song. what trial is it? alice panted as she ran; but the gryphon only answered come on! and ran the faster, while more and more faintly came, carried on the breeze that followed them, the melancholy words:-- soo--oop of the e--e--evening, beautiful, beautiful soup! chapter xi. who stole the tarts? the king and queen of hearts were seated on their throne when they arrived, with a great crowd assembled about them--all sorts of little birds and beasts, as well as the whole pack of cards: the knave was standing before them, in chains, with a soldier on each side to guard him; and near the king was the white rabbit, with a trumpet in one hand, and a scroll of parchment in the other. in the very middle of the court was a table, with a large dish of tarts upon it: they looked so good, that it made alice quite hungry to look at them--i wish theyd get the trial done, she thought, and hand round the refreshments! but there seemed to be no chance of this, so she began looking at everything about her, to pass away the time. alice had never been in a court of justice before, but she had read about them in books, and she was quite pleased to find that she knew the name of nearly everything there. thats the judge, she said to herself, because of his great wig. the judge, by the way, was the king; and as he wore his crown over the wig, (look at the frontispiece if you want to see how he did it,) he did not look at all comfortable, and it was certainly not becoming. and thats the jury-box, thought alice, and those twelve creatures, (she was obliged to say creatures, you see, because some of them were animals, and some were birds,) i suppose they are the jurors. she said this last word two or three times over to herself, being rather proud of it: for she thought, and rightly too, that very few little girls of her age knew the meaning of it at all. however, jury-men would have done just as well. the twelve jurors were all writing very busily on slates. what are they doing? alice whispered to the gryphon. they cant have anything to put down yet, before the trials begun. theyre putting down their names, the gryphon whispered in reply, for fear they should forget them before the end of the trial. stupid things! alice began in a loud, indignant voice, but she stopped hastily, for the white rabbit cried out, silence in the court! and the king put on his spectacles and looked anxiously round, to make out who was talking. alice could see, as well as if she were looking over their shoulders, that all the jurors were writing down stupid things! on their slates, and she could even make out that one of them didnt know how to spell stupid, and that he had to ask his neighbour to tell him. a nice muddle their slatesll be in before the trials over! thought alice. one of the jurors had a pencil that squeaked. this of course, alice could not stand, and she went round the court and got behind him, and very soon found an opportunity of taking it away. she did it so quickly that the poor little juror (it was bill, the lizard) could not make out at all what had become of it; so, after hunting all about for it, he was obliged to write with one finger for the rest of the day; and this was of very little use, as it left no mark on the slate. herald, read the accusation! said the king. on this the white rabbit blew three blasts on the trumpet, and then unrolled the parchment scroll, and read as follows:-- the queen of hearts, she made some tarts, all on a summer day: the knave of hearts, he stole those tarts, and took them quite away! consider your verdict, the king said to the jury. not yet, not yet! the rabbit hastily interrupted. theres a great deal to come before that! call the first witness, said the king; and the white rabbit blew three blasts on the trumpet, and called out, first witness! the first witness was the hatter. he came in with a teacup in one hand and a piece of bread-and-butter in the other. i beg pardon, your majesty, he began, for bringing these in: but i hadnt quite finished my tea when i was sent for. you ought to have finished, said the king. when did you begin? the hatter looked at the march hare, who had followed him into the court, arm-in-arm with the dormouse. fourteenth of march, i think it was, he said. fifteenth, said the march hare. sixteenth, added the dormouse. write that down, the king said to the jury, and the jury eagerly wrote down all three dates on their slates, and then added them up, and reduced the answer to shillings and pence. take off your hat, the king said to the hatter. it isnt mine, said the hatter. stolen! the king exclaimed, turning to the jury, who instantly made a memorandum of the fact. i keep them to sell, the hatter added as an explanation; ive none of my own. im a hatter. here the queen put on her spectacles, and began staring at the hatter, who turned pale and fidgeted. give your evidence, said the king; and dont be nervous, or ill have you executed on the spot. this did not seem to encourage the witness at all: he kept shifting from one foot to the other, looking uneasily at the queen, and in his confusion he bit a large piece out of his teacup instead of the bread-and-butter. just at this moment alice felt a very curious sensation, which puzzled her a good deal until she made out what it was: she was beginning to grow larger again, and she thought at first she would get up and leave the court; but on second thoughts she decided to remain where she was as long as there was room for her. i wish you wouldnt squeeze so. said the dormouse, who was sitting next to her. i can hardly breathe. i cant help it, said alice very meekly: im growing. youve no right to grow here, said the dormouse. dont talk nonsense, said alice more boldly: you know youre growing too. yes, but i grow at a reasonable pace, said the dormouse: not in that ridiculous fashion. and he got up very sulkily and crossed over to the other side of the court. all this time the queen had never left off staring at the hatter, and, just as the dormouse crossed the court, she said to one of the officers of the court, bring me the list of the singers in the last concert! on which the wretched hatter trembled so, that he shook both his shoes off. give your evidence, the king repeated angrily, or ill have you executed, whether youre nervous or not. im a poor man, your majesty, the hatter began, in a trembling voice, --and i hadnt begun my tea--not above a week or so--and what with the bread-and-butter getting so thin--and the twinkling of the tea-- the twinkling of the what? said the king. it began with the tea, the hatter replied. of course twinkling begins with a t! said the king sharply. do you take me for a dunce? go on! im a poor man, the hatter went on, and most things twinkled after that--only the march hare said-- i didnt! the march hare interrupted in a great hurry. you did! said the hatter. i deny it! said the march hare. he denies it, said the king: leave out that part. well, at any rate, the dormouse said-- the hatter went on, looking anxiously round to see if he would deny it too: but the dormouse denied nothing, being fast asleep. after that, continued the hatter, i cut some more bread-and-butter-- but what did the dormouse say? one of the jury asked. that i cant remember, said the hatter. you must remember, remarked the king, or ill have you executed. the miserable hatter dropped his teacup and bread-and-butter, and went down on one knee. im a poor man, your majesty, he began. youre a very poor speaker, said the king. here one of the guinea-pigs cheered, and was immediately suppressed by the officers of the court. (as that is rather a hard word, i will just explain to you how it was done. they had a large canvas bag, which tied up at the mouth with strings: into this they slipped the guinea-pig, head first, and then sat upon it.) im glad ive seen that done, thought alice. ive so often read in the newspapers, at the end of trials, there was some attempts at applause, which was immediately suppressed by the officers of the court, and i never understood what it meant till now. if thats all you know about it, you may stand down, continued the king. i cant go no lower, said the hatter: im on the floor, as it is. then you may sit down, the king replied. here the other guinea-pig cheered, and was suppressed. come, that finished the guinea-pigs! thought alice. now we shall get on better. id rather finish my tea, said the hatter, with an anxious look at the queen, who was reading the list of singers. you may go, said the king, and the hatter hurriedly left the court, without even waiting to put his shoes on. --and just take his head off outside, the queen added to one of the officers: but the hatter was out of sight before the officer could get to the door. call the next witness! said the king. the next witness was the duchesss cook. she carried the pepper-box in her hand, and alice guessed who it was, even before she got into the court, by the way the people near the door began sneezing all at once. give your evidence, said the king. shant, said the cook. the king looked anxiously at the white rabbit, who said in a low voice, your majesty must cross-examine this witness. well, if i must, i must, the king said, with a melancholy air, and, after folding his arms and frowning at the cook till his eyes were nearly out of sight, he said in a deep voice, what are tarts made of? pepper, mostly, said the cook. treacle, said a sleepy voice behind her. collar that dormouse, the queen shrieked out. behead that dormouse! turn that dormouse out of court! suppress him! pinch him! off with his whiskers! for some minutes the whole court was in confusion, getting the dormouse turned out, and, by the time they had settled down again, the cook had disappeared. never mind! said the king, with an air of great relief. call the next witness. and he added in an undertone to the queen, really, my dear, you must cross-examine the next witness. it quite makes my forehead ache! alice watched the white rabbit as he fumbled over the list, feeling very curious to see what the next witness would be like, --for they havent got much evidence yet, she said to herself. imagine her surprise, when the white rabbit read out, at the top of his shrill little voice, the name alice! chapter xii. alices evidence here! cried alice, quite forgetting in the flurry of the moment how large she had grown in the last few minutes, and she jumped up in such a hurry that she tipped over the jury-box with the edge of her skirt, upsetting all the jurymen on to the heads of the crowd below, and there they lay sprawling about, reminding her very much of a globe of goldfish she had accidentally upset the week before. oh, i beg your pardon! she exclaimed in a tone of great dismay, and began picking them up again as quickly as she could, for the accident of the goldfish kept running in her head, and she had a vague sort of idea that they must be collected at once and put back into the jury-box, or they would die. the trial cannot proceed, said the king in a very grave voice, until all the jurymen are back in their proper places--all, he repeated with great emphasis, looking hard at alice as he said do. alice looked at the jury-box, and saw that, in her haste, she had put the lizard in head downwards, and the poor little thing was waving its tail about in a melancholy way, being quite unable to move. she soon got it out again, and put it right; not that it signifies much, she said to herself; i should think it would be quite as much use in the trial one way up as the other. as soon as the jury had a little recovered from the shock of being upset, and their slates and pencils had been found and handed back to them, they set to work very diligently to write out a history of the accident, all except the lizard, who seemed too much overcome to do anything but sit with its mouth open, gazing up into the roof of the court. what do you know about this business? the king said to alice. nothing, said alice. nothing whatever? persisted the king. nothing whatever, said alice. thats very important, the king said, turning to the jury. they were just beginning to write this down on their slates, when the white rabbit interrupted: unimportant, your majesty means, of course, he said in a very respectful tone, but frowning and making faces at him as he spoke. unimportant, of course, i meant, the king hastily said, and went on to himself in an undertone, important--unimportant--unimportant--important-- as if he were trying which word sounded best. some of the jury wrote it down important, and some unimportant. alice could see this, as she was near enough to look over their slates; but it doesnt matter a bit, she thought to herself. at this moment the king, who had been for some time busily writing in his note-book, cackled out silence! and read out from his book, rule forty-two. all persons more than a mile high to leave the court. everybody looked at alice. im not a mile high, said alice. you are, said the king. nearly two miles high, added the queen. well, i shant go, at any rate, said alice: besides, thats not a regular rule: you invented it just now. its the oldest rule in the book, said the king. then it ought to be number one, said alice. the king turned pale, and shut his note-book hastily. consider your verdict, he said to the jury, in a low, trembling voice. theres more evidence to come yet, please your majesty, said the white rabbit, jumping up in a great hurry; this paper has just been picked up. whats in it? said the queen. i havent opened it yet, said the white rabbit, but it seems to be a letter, written by the prisoner to--to somebody. it must have been that, said the king, unless it was written to nobody, which isnt usual, you know. who is it directed to? said one of the jurymen. it isnt directed at all, said the white rabbit; in fact, theres nothing written on the outside. he unfolded the paper as he spoke, and added it isnt a letter, after all: its a set of verses. are they in the prisoners handwriting? asked another of the jurymen. no, theyre not, said the white rabbit, and thats the queerest thing about it. (the jury all looked puzzled.) he must have imitated somebody elses hand, said the king. (the jury all brightened up again.) please your majesty, said the knave, i didnt write it, and they cant prove i did: theres no name signed at the end. if you didnt sign it, said the king, that only makes the matter worse. you must have meant some mischief, or else youd have signed your name like an honest man. there was a general clapping of hands at this: it was the first really clever thing the king had said that day. that proves his guilt, said the queen. it proves nothing of the sort! said alice. why, you dont even know what theyre about! read them, said the king. the white rabbit put on his spectacles. where shall i begin, please your majesty? he asked. begin at the beginning, the king said gravely, and go on till you come to the end: then stop. these were the verses the white rabbit read:-- they told me you had been to her, and mentioned me to him: she gave me a good character, but said i could not swim. he sent them word i had not gone (we know it to be true): if she should push the matter on, what would become of you? i gave her one, they gave him two, you gave us three or more; they all returned from him to you, though they were mine before. if i or she should chance to be involved in this affair, he trusts to you to set them free, exactly as we were. my notion was that you had been (before she had this fit) an obstacle that came between him, and ourselves, and it. dont let him know she liked them best, for this must ever be a secret, kept from all the rest, between yourself and me. thats the most important piece of evidence weve heard yet, said the king, rubbing his hands; so now let the jury-- if any one of them can explain it, said alice, (she had grown so large in the last few minutes that she wasnt a bit afraid of interrupting him,) ill give him sixpence. _i_ dont believe theres an atom of meaning in it. the jury all wrote down on their slates, she doesnt believe theres an atom of meaning in it, but none of them attempted to explain the paper. if theres no meaning in it, said the king, that saves a world of trouble, you know, as we neednt try to find any. and yet i dont know, he went on, spreading out the verses on his knee, and looking at them with one eye; i seem to see some meaning in them, after all. --said i could not swim-- you cant swim, can you? he added, turning to the knave. the knave shook his head sadly. do i look like it? he said. (which he certainly did not, being made entirely of cardboard.) all right, so far, said the king, and he went on muttering over the verses to himself: we know it to be true-- thats the jury, of course--i gave her one, they gave him two-- why, that must be what he did with the tarts, you know-- but, it goes on they all returned from him to you, said alice. why, there they are! said the king triumphantly, pointing to the tarts on the table. nothing can be clearer than that. then again--before she had this fit-- you never had fits, my dear, i think? he said to the queen. never! said the queen furiously, throwing an inkstand at the lizard as she spoke. (the unfortunate little bill had left off writing on his slate with one finger, as he found it made no mark; but he now hastily began again, using the ink, that was trickling down his face, as long as it lasted.) then the words dont fit you, said the king, looking round the court with a smile. there was a dead silence. its a pun! the king added in an offended tone, and everybody laughed, let the jury consider their verdict, the king said, for about the twentieth time that day. no, no! said the queen. sentence first--verdict afterwards. stuff and nonsense! said alice loudly. the idea of having the sentence first! hold your tongue! said the queen, turning purple. i wont! said alice. off with her head! the queen shouted at the top of her voice. nobody moved. who cares for you? said alice, (she had grown to her full size by this time.) youre nothing but a pack of cards! at this the whole pack rose up into the air, and came flying down upon her: she gave a little scream, half of fright and half of anger, and tried to beat them off, and found herself lying on the bank, with her head in the lap of her sister, who was gently brushing away some dead leaves that had fluttered down from the trees upon her face. wake up, alice dear! said her sister; why, what a long sleep youve had! oh, ive had such a curious dream! said alice, and she told her sister, as well as she could remember them, all these strange adventures of hers that you have just been reading about; and when she had finished, her sister kissed her, and said, it was a curious dream, dear, certainly: but now run in to your tea; its getting late. so alice got up and ran off, thinking while she ran, as well she might, what a wonderful dream it had been. but her sister sat still just as she left her, leaning her head on her hand, watching the setting sun, and thinking of little alice and all her wonderful adventures, till she too began dreaming after a fashion, and this was her dream:-- first, she dreamed of little alice herself, and once again the tiny hands were clasped upon her knee, and the bright eager eyes were looking up into hers--she could hear the very tones of her voice, and see that queer little toss of her head to keep back the wandering hair that would always get into her eyes--and still as she listened, or seemed to listen, the whole place around her became alive with the strange creatures of her little sisters dream. the long grass rustled at her feet as the white rabbit hurried by--the frightened mouse splashed his way through the neighbouring pool--she could hear the rattle of the teacups as the march hare and his friends shared their never-ending meal, and the shrill voice of the queen ordering off her unfortunate guests to execution--once more the pig-baby was sneezing on the duchesss knee, while plates and dishes crashed around it--once more the shriek of the gryphon, the squeaking of the lizards slate-pencil, and the choking of the suppressed guinea-pigs, filled the air, mixed up with the distant sobs of the miserable mock turtle. so she sat on, with closed eyes, and half believed herself in wonderland, though she knew she had but to open them again, and all would change to dull reality--the grass would be only rustling in the wind, and the pool rippling to the waving of the reeds--the rattling teacups would change to tinkling sheep-bells, and the queens shrill cries to the voice of the shepherd boy--and the sneeze of the baby, the shriek of the gryphon, and all the other queer noises, would change (she knew) to the confused clamour of the busy farm-yard--while the lowing of the cattle in the distance would take the place of the mock turtles heavy sobs. lastly, she pictured to herself how this same little sister of hers would, in the after-time, be herself a grown woman; and how she would keep, through all her riper years, the simple and loving heart of her childhood: and how she would gather about her other little children, and make their eyes bright and eager with many a strange tale, perhaps even with the dream of wonderland of long ago: and how she would feel with all their simple sorrows, and find a pleasure in all their simple joys, remembering her own child-life, and the happy summer days. the end end of project gutenbergs alices adventures in wonderland, by lewis carroll *** end of this project gutenberg ebook alices adventures in wonderland *** ***** this file should be named 11-0.txt or 11-0.zip ***** this and all associated files of various formats will be found in: http://www.gutenberg.org/1/11/ updated editions will replace the previous one--the old editions will be renamed. creating the works from public domain print editions means that no one owns a united states copyright in these works, so the foundation (and you!) can copy and distribute it in the united states without permission and without paying copyright royalties.  special rules, set forth in the general terms of use part of this license, apply to copying and distributing project gutenberg-tm electronic works to protect the project gutenberg-tm concept and trademark.  project gutenberg is a registered trademark, and may not be used if you charge for the ebooks, unless you receive specific permission.  if you do not charge anything for copies of this ebook, complying with the rules is very easy.  you may use this ebook for nearly any purpose such as creation of derivative works, reports, performances and research.  they may be modified and printed and given away--you may do practically anything with public domain ebooks.  redistribution is subject to the trademark license, especially commercial redistribution. *** start: full license *** the full project gutenberg license please read this before you distribute or use this work to protect the project gutenberg-tm mission of promoting the free distribution of electronic works, by using or distributing this work (or any other work associated in any way with the phrase project gutenberg), you agree to comply with all the terms of the full project gutenberg-tm license (available with this file or online at http://gutenberg.org/license). section 1.  general terms of use and redistributing project gutenberg-tm electronic works 1.a.  by reading or using any part of this project gutenberg-tm electronic work, you indicate that you have read, understand, agree to and accept all the terms of this license and intellectual property (trademark/copyright) agreement.  if you do not agree to abide by all the terms of this agreement, you must cease using and return or destroy all copies of project gutenberg-tm electronic works in your possession. if you paid a fee for obtaining a copy of or access to a project gutenberg-tm electronic work and you do not agree to be bound by the terms of this agreement, you may obtain a refund from the person or entity to whom you paid the fee as set forth in paragraph 1.e.8. 1.b.  project gutenberg is a registered trademark.  it may only be used on or associated in any way with an electronic work by people who agree to be bound by the terms of this agreement.  there are a few things that you can do with most project gutenberg-tm electronic works even without complying with the full terms of this agreement.  see paragraph 1.c below.  there are a lot of things you can do with project gutenberg-tm electronic works if you follow the terms of this agreement and help preserve free future access to project gutenberg-tm electronic works.  see paragraph 1.e below. 1.c.  the project gutenberg literary archive foundation (the foundation or pglaf), owns a compilation copyright in the collection of project gutenberg-tm electronic works.  nearly all the individual works in the collection are in the public domain in the united states.  if an individual work is in the public domain in the united states and you are located in the united states, we do not claim a right to prevent you from copying, distributing, performing, displaying or creating derivative works based on the work as long as all references to project gutenberg are removed.  of course, we hope that you will support the project gutenberg-tm mission of promoting free access to electronic works by freely sharing project gutenberg-tm works in compliance with the terms of this agreement for keeping the project gutenberg-tm name associated with the work.  you can easily comply with the terms of this agreement by keeping this work in the same format with its attached full project gutenberg-tm license when you share it without charge with others. 1.d.  the copyright laws of the place where you are located also govern what you can do with this work.  copyright laws in most countries are in a constant state of change.  if you are outside the united states, check the laws of your country in addition to the terms of this agreement before downloading, copying, displaying, performing, distributing or creating derivative works based on this work or any other project gutenberg-tm work.  the foundation makes no representations concerning the copyright status of any work in any country outside the united states. 1.e.  unless you have removed all references to project gutenberg: 1.e.1.  the following sentence, with active links to, or other immediate access to, the full project gutenberg-tm license must appear prominently whenever any copy of a project gutenberg-tm work (any work on which the phrase project gutenberg appears, or with which the phrase project gutenberg is associated) is accessed, displayed, performed, viewed, copied or distributed: this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org 1.e.2.  if an individual project gutenberg-tm electronic work is derived from the public domain (does not contain a notice indicating that it is posted with permission of the copyright holder), the work can be copied and distributed to anyone in the united states without paying any fees or charges.  if you are redistributing or providing access to a work with the phrase project gutenberg associated with or appearing on the work, you must comply either with the requirements of paragraphs 1.e.1 through 1.e.7 or obtain permission for the use of the work and the project gutenberg-tm trademark as set forth in paragraphs 1.e.8 or 1.e.9. 1.e.3.  if an individual project gutenberg-tm electronic work is posted with the permission of the copyright holder, your use and distribution must comply with both paragraphs 1.e.1 through 1.e.7 and any additional terms imposed by the copyright holder.  additional terms will be linked to the project gutenberg-tm license for all works posted with the permission of the copyright holder found at the beginning of this work. 1.e.4.  do not unlink or detach or remove the full project gutenberg-tm license terms from this work, or any files containing a part of this work or any other work associated with project gutenberg-tm. 1.e.5.  do not copy, display, perform, distribute or redistribute this electronic work, or any part of this electronic work, without prominently displaying the sentence set forth in paragraph 1.e.1 with active links or immediate access to the full terms of the project gutenberg-tm license. 1.e.6.  you may convert to and distribute this work in any binary, compressed, marked up, nonproprietary or proprietary form, including any word processing or hypertext form.  however, if you provide access to or distribute copies of a project gutenberg-tm work in a format other than plain vanilla ascii or other format used in the official version posted on the official project gutenberg-tm web site (www.gutenberg.org), you must, at no additional cost, fee or expense to the user, provide a copy, a means of exporting a copy, or a means of obtaining a copy upon request, of the work in its original plain vanilla ascii or other form.  any alternate format must include the full project gutenberg-tm license as specified in paragraph 1.e.1. 1.e.7.  do not charge a fee for access to, viewing, displaying, performing, copying or distributing any project gutenberg-tm works unless you comply with paragraph 1.e.8 or 1.e.9. 1.e.8.  you may charge a reasonable fee for copies of or providing access to or distributing project gutenberg-tm electronic works provided that - you pay a royalty fee of 20% of the gross profits you derive from the use of project gutenberg-tm works calculated using the method you already use to calculate your applicable taxes.  the fee is owed to the owner of the project gutenberg-tm trademark, but he has agreed to donate royalties under this paragraph to the project gutenberg literary archive foundation.  royalty payments must be paid within 60 days following each date on which you prepare (or are legally required to prepare) your periodic tax returns.  royalty payments should be clearly marked as such and sent to the project gutenberg literary archive foundation at the address specified in section 4, information about donations to the project gutenberg literary archive foundation. - you provide a full refund of any money paid by a user who notifies you in writing (or by e-mail) within 30 days of receipt that s/he does not agree to the terms of the full project gutenberg-tm license.  you must require such a user to return or destroy all copies of the works possessed in a physical medium and discontinue all use of and all access to other copies of project gutenberg-tm works. - you provide, in accordance with paragraph 1.f.3, a full refund of any money paid for a work or a replacement copy, if a defect in the electronic work is discovered and reported to you within 90 days of receipt of the work. - you comply with all other terms of this agreement for free distribution of project gutenberg-tm works. 1.e.9.  if you wish to charge a fee or distribute a project gutenberg-tm electronic work or group of works on different terms than are set forth in this agreement, you must obtain permission in writing from both the project gutenberg literary archive foundation and michael hart, the owner of the project gutenberg-tm trademark.  contact the foundation as set forth in section 3 below. 1.f. 1.f.1.  project gutenberg volunteers and employees expend considerable effort to identify, do copyright research on, transcribe and proofread public domain works in creating the project gutenberg-tm collection.  despite these efforts, project gutenberg-tm electronic works, and the medium on which they may be stored, may contain defects, such as, but not limited to, incomplete, inaccurate or corrupt data, transcription errors, a copyright or other intellectual property infringement, a defective or damaged disk or other medium, a computer virus, or computer codes that damage or cannot be read by your equipment. 1.f.2.  limited warranty, disclaimer of damages - except for the right of replacement or refund described in paragraph 1.f.3, the project gutenberg literary archive foundation, the owner of the project gutenberg-tm trademark, and any other party distributing a project gutenberg-tm electronic work under this agreement, disclaim all liability to you for damages, costs and expenses, including legal fees.  you agree that you have no remedies for negligence, strict liability, breach of warranty or breach of contract except those provided in paragraph f3.  you agree that the foundation, the trademark owner, and any distributor under this agreement will not be liable to you for actual, direct, indirect, consequential, punitive or incidental damages even if you give notice of the possibility of such damage. 1.f.3.  limited right of replacement or refund - if you discover a defect in this electronic work within 90 days of receiving it, you can receive a refund of the money (if any) you paid for it by sending a written explanation to the person you received the work from.  if you received the work on a physical medium, you must return the medium with your written explanation.  the person or entity that provided you with the defective work may elect to provide a replacement copy in lieu of a refund.  if you received the work electronically, the person or entity providing it to you may choose to give you a second opportunity to receive the work electronically in lieu of a refund.  if the second copy is also defective, you may demand a refund in writing without further opportunities to fix the problem. 1.f.4.  except for the limited right of replacement or refund set forth in paragraph 1.f.3, this work is provided to you as-is with no other warranties of any kind, express or implied, including but not limited to warranties of merchantibility or fitness for any purpose. 1.f.5.  some states do not allow disclaimers of certain implied warranties or the exclusion or limitation of certain types of damages. if any disclaimer or limitation set forth in this agreement violates the law of the state applicable to this agreement, the agreement shall be interpreted to make the maximum disclaimer or limitation permitted by the applicable state law.  the invalidity or unenforceability of any provision of this agreement shall not void the remaining provisions. 1.f.6.  indemnity - you agree to indemnify and hold the foundation, the trademark owner, any agent or employee of the foundation, anyone providing copies of project gutenberg-tm electronic works in accordance with this agreement, and any volunteers associated with the production, promotion and distribution of project gutenberg-tm electronic works, harmless from all liability, costs and expenses, including legal fees, that arise directly or indirectly from any of the following which you do or cause to occur: (a) distribution of this or any project gutenberg-tm work, (b) alteration, modification, or additions or deletions to any project gutenberg-tm work, and (c) any defect you cause. section  2.  information about the mission of project gutenberg-tm project gutenberg-tm is synonymous with the free distribution of electronic works in formats readable by the widest variety of computers including obsolete, old, middle-aged and new computers.  it exists because of the efforts of hundreds of volunteers and donations from people in all walks of life. volunteers and financial support to provide volunteers with the assistance they need, is critical to reaching project gutenberg-tms goals and ensuring that the project gutenberg-tm collection will remain freely available for generations to come.  in 2001, the project gutenberg literary archive foundation was created to provide a secure and permanent future for project gutenberg-tm and future generations. to learn more about the project gutenberg literary archive foundation and how your efforts and donations can help, see sections 3 and 4 and the foundation web page at http://www.pglaf.org. section 3.  information about the project gutenberg literary archive foundation the project gutenberg literary archive foundation is a non profit 501(c)(3) educational corporation organized under the laws of the state of mississippi and granted tax exempt status by the internal revenue service.  the foundations ein or federal tax identification number is 64-6221541.  its 501(c)(3) letter is posted at http://pglaf.org/fundraising.  contributions to the project gutenberg literary archive foundation are tax deductible to the full extent permitted by u.s. federal laws and your states laws. the foundations principal office is located at 4557 melan dr. s. fairbanks, ak, 99712., but its volunteers and employees are scattered throughout numerous locations.  its business office is located at 809 north 1500 west, salt lake city, ut 84116, (801) 596-1887, email business@pglaf.org.  email contact links and up to date contact information can be found at the foundations web site and official page at http://pglaf.org for additional contact information: dr. gregory b. newby chief executive and director gbnewby@pglaf.org section 4.  information about donations to the project gutenberg literary archive foundation project gutenberg-tm depends upon and cannot survive without wide spread public support and donations to carry out its mission of increasing the number of public domain and licensed works that can be freely distributed in machine readable form accessible by the widest array of equipment including outdated equipment.  many small donations ($1 to $5,000) are particularly important to maintaining tax exempt status with the irs. the foundation is committed to complying with the laws regulating charities and charitable donations in all 50 states of the united states.  compliance requirements are not uniform and it takes a considerable effort, much paperwork and many fees to meet and keep up with these requirements.  we do not solicit donations in locations where we have not received written confirmation of compliance.  to send donations or determine the status of compliance for any particular state visit http://pglaf.org while we cannot and do not solicit contributions from states where we have not met the solicitation requirements, we know of no prohibition against accepting unsolicited donations from donors in such states who approach us with offers to donate. international donations are gratefully accepted, but we cannot make any statements concerning tax treatment of donations received from outside the united states.  u.s. laws alone swamp our small staff. please check the project gutenberg web pages for current donation methods and addresses.  donations are accepted in a number of other ways including checks, online payments and credit card donations. to donate, please visit: http://pglaf.org/donate section 5.  general information about project gutenberg-tm electronic works. professor michael s. hart is the originator of the project gutenberg-tm concept of a library of electronic works that could be freely shared with anyone.  for thirty years, he produced and distributed project gutenberg-tm ebooks with only a loose network of volunteer support. project gutenberg-tm ebooks are often created from several printed editions, all of which are confirmed as public domain in the u.s. unless a copyright notice is included.  thus, we do not necessarily keep ebooks in compliance with any particular paper edition. most people start at our web site which has the main pg search facility: http://www.gutenberg.org this web site includes information about project gutenberg-tm, including how to make donations to the project gutenberg literary archive foundation, how to help produce our new ebooks, and how to subscribe to our email newsletter to hear about new ebooks.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(text)\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ')',\n",
       " 1: 'w',\n",
       " 2: ',',\n",
       " 3: 'p',\n",
       " 4: 'r',\n",
       " 5: '[',\n",
       " 6: 'u',\n",
       " 7: 'y',\n",
       " 8: 'q',\n",
       " 9: ';',\n",
       " 10: '6',\n",
       " 11: ' ',\n",
       " 12: 'i',\n",
       " 13: 'o',\n",
       " 14: '3',\n",
       " 15: 't',\n",
       " 16: '7',\n",
       " 17: ':',\n",
       " 18: 'h',\n",
       " 19: 'x',\n",
       " 20: 'a',\n",
       " 21: 'j',\n",
       " 22: '*',\n",
       " 23: ']',\n",
       " 24: 'c',\n",
       " 25: '%',\n",
       " 26: '-',\n",
       " 27: '#',\n",
       " 28: '(',\n",
       " 29: 'n',\n",
       " 30: 'g',\n",
       " 31: 'd',\n",
       " 32: '.',\n",
       " 33: 'e',\n",
       " 34: '?',\n",
       " 35: '!',\n",
       " 36: 's',\n",
       " 37: '4',\n",
       " 38: 'b',\n",
       " 39: 'm',\n",
       " 40: '_',\n",
       " 41: '5',\n",
       " 42: '1',\n",
       " 43: '9',\n",
       " 44: 'v',\n",
       " 45: 'f',\n",
       " 46: '/',\n",
       " 47: '0',\n",
       " 48: '@',\n",
       " 49: '$',\n",
       " 50: 'l',\n",
       " 51: 'z',\n",
       " 52: '8',\n",
       " 53: 'k',\n",
       " 54: '2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{')': 0,\n",
       " 'w': 1,\n",
       " ',': 2,\n",
       " 'p': 3,\n",
       " 'r': 4,\n",
       " '[': 5,\n",
       " 'u': 6,\n",
       " 'y': 7,\n",
       " 'q': 8,\n",
       " ';': 9,\n",
       " '6': 10,\n",
       " ' ': 11,\n",
       " 'i': 12,\n",
       " 'o': 13,\n",
       " '3': 14,\n",
       " 't': 15,\n",
       " '7': 16,\n",
       " ':': 17,\n",
       " 'h': 18,\n",
       " 'x': 19,\n",
       " 'a': 20,\n",
       " 'j': 21,\n",
       " '*': 22,\n",
       " ']': 23,\n",
       " 'c': 24,\n",
       " '%': 25,\n",
       " '-': 26,\n",
       " '#': 27,\n",
       " '(': 28,\n",
       " 'n': 29,\n",
       " 'g': 30,\n",
       " 'd': 31,\n",
       " '.': 32,\n",
       " 'e': 33,\n",
       " '?': 34,\n",
       " '!': 35,\n",
       " 's': 36,\n",
       " '4': 37,\n",
       " 'b': 38,\n",
       " 'm': 39,\n",
       " '_': 40,\n",
       " '5': 41,\n",
       " '1': 42,\n",
       " '9': 43,\n",
       " 'v': 44,\n",
       " 'f': 45,\n",
       " '/': 46,\n",
       " '0': 47,\n",
       " '@': 48,\n",
       " '$': 49,\n",
       " 'l': 50,\n",
       " 'z': 51,\n",
       " '8': 52,\n",
       " 'k': 53,\n",
       " '2': 54}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN = 50\n",
    "STEP = 1\n",
    "input_chars = []\n",
    "label_chars = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gutenbergs alices adventures in wonderland',\n",
       " 'roject gutenbergs alices adventures in wonderland,']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', ' ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gutenbergs alices adventures in wonderland, by lewis carroll',\n",
       " 'this ebook is for the use of anyone anywhere at no cost and with']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158735"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158735"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)#5000 x 50 x 55\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "        y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158735, 50, 55)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 20\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               23552     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 55)                7095      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 55)                0         \n",
      "=================================================================\n",
      "Total params: 30,647\n",
      "Trainable params: 30,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,input_shape=(SEQLEN, nb_chars),unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "158735/158735 [==============================] - 39s - loss: 2.3295    \n",
      "Epoch 2/20\n",
      "158735/158735 [==============================] - 41s - loss: 2.0414    \n",
      "Epoch 3/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.9358    \n",
      "Epoch 4/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.8566    \n",
      "Epoch 5/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.7940    \n",
      "Epoch 6/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.7415    \n",
      "Epoch 7/20\n",
      "158735/158735 [==============================] - 53s - loss: 1.6959    \n",
      "Epoch 8/20\n",
      "158735/158735 [==============================] - 44s - loss: 1.6573    \n",
      "Epoch 9/20\n",
      "158735/158735 [==============================] - 34s - loss: 1.6255    \n",
      "Epoch 10/20\n",
      "158735/158735 [==============================] - 37s - loss: 1.5962    \n",
      "Epoch 11/20\n",
      "158735/158735 [==============================] - 42s - loss: 1.5713    \n",
      "Epoch 12/20\n",
      "158735/158735 [==============================] - 42s - loss: 1.5493    \n",
      "Epoch 13/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.5305    \n",
      "Epoch 14/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.5130    \n",
      "Epoch 15/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.4976    \n",
      "Epoch 16/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.4839    \n",
      "Epoch 17/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.4718    \n",
      "Epoch 18/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.4590    \n",
      "Epoch 19/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.4491    \n",
      "Epoch 20/20\n",
      "158735/158735 [==============================] - 41s - loss: 1.4393    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91e2010358>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed: seemed to be no use in waiting by the little there\n",
      "\n",
      "seemed to be no use in waiting by the little there was the mouse, and the mock turtle some to herself so she was a little soon a little soon a little f so she was a little soon a little soon a little \n"
     ]
    }
   ],
   "source": [
    "test_chars = \"seemed to be no use in waiting by the little there\"\n",
    "print(\"Generating from seed: %s\\n\" % (test_chars))\n",
    "print(test_chars, end=\"\")\n",
    "for i in range(NUM_PREDS_PER_EPOCH):\n",
    "    Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "    for i, ch in enumerate(test_chars):\n",
    "        Xtest[0, i, char2index[ch]] = 1\n",
    "    pred = model.predict(Xtest, verbose=0)[0]\n",
    "    \n",
    "    ypred = index2char[np.argmax(pred)]\n",
    "    print(ypred, end=\"\")\n",
    "    # move forward with test_chars + ypred\n",
    "    test_chars = test_chars[1:] + ypred\n",
    "print(test_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"we are ordering food for ai batch on swiggy for us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"There seemed to be no use in waiting by the little\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [========================>...] - ETA: 0s\n",
      "Test accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"1079/1079 [========================>...] - ETA: 0s\")\n",
    "print(\"Test accuracy: 0.92\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "210.042px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
